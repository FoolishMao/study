{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积自编码器\n",
    "此notebook包括搭建卷积自编码器和通过卷积自编码器进行降噪处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#下载Mnist数据集\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', validation_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xfa09198>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#预览图片\n",
    "img = mnist.train.images[2]\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搭建自编码器\n",
    "编码器为正常的卷积神经网络，解码器使用上采样的方法（最近邻和双线性插值）来进行图像尺寸的扩大。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float32, (None, 28, 28, 1), name='inputs')\n",
    "targets = tf.placeholder(tf.float32, (None, 28, 28, 1), name='targets')\n",
    "lr = tf.placeholder(tf.float32, name = 'learn_rate')\n",
    "\n",
    "### Encoder\n",
    "conv1 = tf.layers.conv2d(inputs, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x16\n",
    "maxpool1 = tf.layers.max_pooling2d(conv1, (2,2), (2,2), padding='same')\n",
    "# Now 14x14x16\n",
    "conv2 = tf.layers.conv2d(maxpool1, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x8\n",
    "maxpool2 = tf.layers.max_pooling2d(conv2, (2,2), (2,2), padding='same')\n",
    "# Now 7x7x8\n",
    "conv3 = tf.layers.conv2d(maxpool2, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x8\n",
    "encoded = tf.layers.max_pooling2d(conv3, (2,2), (2,2), padding='same')\n",
    "# Now 4x4x8\n",
    "\n",
    "### Decoder\n",
    "upsample1 = tf.image.resize_nearest_neighbor(encoded, (7,7))\n",
    "# Now 7x7x8\n",
    "conv4 = tf.layers.conv2d(upsample1, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x8\n",
    "upsample2 = tf.image.resize_nearest_neighbor(conv4, (14,14))\n",
    "# Now 14x14x8\n",
    "conv5 = tf.layers.conv2d(upsample2, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x8\n",
    "upsample3 = tf.image.resize_nearest_neighbor(conv5, (28,28))\n",
    "# Now 28x28x8\n",
    "conv6 = tf.layers.conv2d(upsample3, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x16\n",
    "\n",
    "logits = tf.layers.conv2d(conv6, 1, (3,3), padding='same', activation=None)\n",
    "#Now 28x28x1\n",
    "\n",
    "decoded = tf.nn.sigmoid(logits, name='decoded')\n",
    "\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets, logits=logits)\n",
    "cost = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(lr).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define get batch function\n",
    "def get_batch(inputs, batch_size):\n",
    "    num = len(inputs) // batch_size\n",
    "    new_inputs = inputs[:num * batch_size]\n",
    "    #get batch\n",
    "    input_batch = np.array(np.split(new_inputs, num, 0))\n",
    "    return input_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#超参数\n",
    "epochs = 20\n",
    "batch_size = 200\n",
    "learn_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20... Training loss: 0.6851\n",
      "Epoch: 1/20... Training loss: 0.6788\n",
      "Epoch: 1/20... Training loss: 0.6705\n",
      "Epoch: 1/20... Training loss: 0.6619\n",
      "Epoch: 1/20... Training loss: 0.6499\n",
      "Epoch: 1/20... Training loss: 0.6332\n",
      "Epoch: 1/20... Training loss: 0.6287\n",
      "Epoch: 1/20... Training loss: 0.5986\n",
      "Epoch: 1/20... Training loss: 0.5744\n",
      "Epoch: 1/20... Training loss: 0.5619\n",
      "Epoch: 1/20... Training loss: 0.5452\n",
      "Epoch: 1/20... Training loss: 0.5238\n",
      "Epoch: 1/20... Training loss: 0.5279\n",
      "Epoch: 1/20... Training loss: 0.5224\n",
      "Epoch: 1/20... Training loss: 0.5251\n",
      "Epoch: 1/20... Training loss: 0.5001\n",
      "Epoch: 1/20... Training loss: 0.4952\n",
      "Epoch: 1/20... Training loss: 0.4805\n",
      "Epoch: 1/20... Training loss: 0.4983\n",
      "Epoch: 1/20... Training loss: 0.4639\n",
      "Epoch: 1/20... Training loss: 0.4593\n",
      "Epoch: 1/20... Training loss: 0.4517\n",
      "Epoch: 1/20... Training loss: 0.4508\n",
      "Epoch: 1/20... Training loss: 0.4619\n",
      "Epoch: 1/20... Training loss: 0.4380\n",
      "Epoch: 1/20... Training loss: 0.4372\n",
      "Epoch: 1/20... Training loss: 0.4369\n",
      "Epoch: 1/20... Training loss: 0.4268\n",
      "Epoch: 1/20... Training loss: 0.4080\n",
      "Epoch: 1/20... Training loss: 0.4040\n",
      "Epoch: 1/20... Training loss: 0.4241\n",
      "Epoch: 1/20... Training loss: 0.3952\n",
      "Epoch: 1/20... Training loss: 0.3684\n",
      "Epoch: 1/20... Training loss: 0.3409\n",
      "Epoch: 1/20... Training loss: 0.3512\n",
      "Epoch: 1/20... Training loss: 0.3319\n",
      "Epoch: 1/20... Training loss: 0.3097\n",
      "Epoch: 1/20... Training loss: 0.3111\n",
      "Epoch: 1/20... Training loss: 0.3169\n",
      "Epoch: 1/20... Training loss: 0.3409\n",
      "Epoch: 1/20... Training loss: 0.3148\n",
      "Epoch: 1/20... Training loss: 0.3098\n",
      "Epoch: 1/20... Training loss: 0.3260\n",
      "Epoch: 1/20... Training loss: 0.3109\n",
      "Epoch: 1/20... Training loss: 0.2860\n",
      "Epoch: 1/20... Training loss: 0.2785\n",
      "Epoch: 1/20... Training loss: 0.2794\n",
      "Epoch: 1/20... Training loss: 0.2851\n",
      "Epoch: 1/20... Training loss: 0.2812\n",
      "Epoch: 1/20... Training loss: 0.2712\n",
      "Epoch: 1/20... Training loss: 0.2605\n",
      "Epoch: 1/20... Training loss: 0.3006\n",
      "Epoch: 1/20... Training loss: 0.2753\n",
      "Epoch: 1/20... Training loss: 0.2506\n",
      "Epoch: 1/20... Training loss: 0.2611\n",
      "Epoch: 1/20... Training loss: 0.2611\n",
      "Epoch: 1/20... Training loss: 0.2484\n",
      "Epoch: 1/20... Training loss: 0.2446\n",
      "Epoch: 1/20... Training loss: 0.2389\n",
      "Epoch: 1/20... Training loss: 0.2385\n",
      "Epoch: 1/20... Training loss: 0.2469\n",
      "Epoch: 1/20... Training loss: 0.2484\n",
      "Epoch: 1/20... Training loss: 0.2518\n",
      "Epoch: 1/20... Training loss: 0.2485\n",
      "Epoch: 1/20... Training loss: 0.2393\n",
      "Epoch: 1/20... Training loss: 0.2478\n",
      "Epoch: 1/20... Training loss: 0.2426\n",
      "Epoch: 1/20... Training loss: 0.2499\n",
      "Epoch: 1/20... Training loss: 0.2209\n",
      "Epoch: 1/20... Training loss: 0.2318\n",
      "Epoch: 1/20... Training loss: 0.2483\n",
      "Epoch: 1/20... Training loss: 0.2376\n",
      "Epoch: 1/20... Training loss: 0.2227\n",
      "Epoch: 1/20... Training loss: 0.2264\n",
      "Epoch: 1/20... Training loss: 0.2184\n",
      "Epoch: 1/20... Training loss: 0.2170\n",
      "Epoch: 1/20... Training loss: 0.2146\n",
      "Epoch: 1/20... Training loss: 0.2149\n",
      "Epoch: 1/20... Training loss: 0.2216\n",
      "Epoch: 1/20... Training loss: 0.2140\n",
      "Epoch: 1/20... Training loss: 0.2195\n",
      "Epoch: 1/20... Training loss: 0.2127\n",
      "Epoch: 1/20... Training loss: 0.2146\n",
      "Epoch: 1/20... Training loss: 0.2101\n",
      "Epoch: 1/20... Training loss: 0.2086\n",
      "Epoch: 1/20... Training loss: 0.2168\n",
      "Epoch: 1/20... Training loss: 0.2216\n",
      "Epoch: 1/20... Training loss: 0.2129\n",
      "Epoch: 1/20... Training loss: 0.2021\n",
      "Epoch: 1/20... Training loss: 0.1979\n",
      "Epoch: 1/20... Training loss: 0.1990\n",
      "Epoch: 1/20... Training loss: 0.1990\n",
      "Epoch: 1/20... Training loss: 0.2062\n",
      "Epoch: 1/20... Training loss: 0.2093\n",
      "Epoch: 1/20... Training loss: 0.2039\n",
      "Epoch: 1/20... Training loss: 0.1984\n",
      "Epoch: 1/20... Training loss: 0.2232\n",
      "Epoch: 1/20... Training loss: 0.2109\n",
      "Epoch: 1/20... Training loss: 0.2138\n",
      "Epoch: 1/20... Training loss: 0.2176\n",
      "Epoch: 1/20... Training loss: 0.2097\n",
      "Epoch: 1/20... Training loss: 0.2042\n",
      "Epoch: 1/20... Training loss: 0.2045\n",
      "Epoch: 1/20... Training loss: 0.2008\n",
      "Epoch: 1/20... Training loss: 0.1983\n",
      "Epoch: 1/20... Training loss: 0.1986\n",
      "Epoch: 1/20... Training loss: 0.2075\n",
      "Epoch: 1/20... Training loss: 0.2032\n",
      "Epoch: 1/20... Training loss: 0.1949\n",
      "Epoch: 1/20... Training loss: 0.2097\n",
      "Epoch: 1/20... Training loss: 0.2088\n",
      "Epoch: 1/20... Training loss: 0.1987\n",
      "Epoch: 1/20... Training loss: 0.1961\n",
      "Epoch: 1/20... Training loss: 0.2034\n",
      "Epoch: 1/20... Training loss: 0.2023\n",
      "Epoch: 1/20... Training loss: 0.2056\n",
      "Epoch: 1/20... Training loss: 0.1957\n",
      "Epoch: 1/20... Training loss: 0.1944\n",
      "Epoch: 1/20... Training loss: 0.1980\n",
      "Epoch: 1/20... Training loss: 0.2034\n",
      "Epoch: 1/20... Training loss: 0.1846\n",
      "Epoch: 1/20... Training loss: 0.1887\n",
      "Epoch: 1/20... Training loss: 0.2024\n",
      "Epoch: 1/20... Training loss: 0.1890\n",
      "Epoch: 1/20... Training loss: 0.1780\n",
      "Epoch: 1/20... Training loss: 0.1959\n",
      "Epoch: 1/20... Training loss: 0.2036\n",
      "Epoch: 1/20... Training loss: 0.1901\n",
      "Epoch: 1/20... Training loss: 0.1929\n",
      "Epoch: 1/20... Training loss: 0.1831\n",
      "Epoch: 1/20... Training loss: 0.1879\n",
      "Epoch: 1/20... Training loss: 0.1852\n",
      "Epoch: 1/20... Training loss: 0.1846\n",
      "Epoch: 1/20... Training loss: 0.1915\n",
      "Epoch: 1/20... Training loss: 0.1842\n",
      "Epoch: 1/20... Training loss: 0.2039\n",
      "Epoch: 1/20... Training loss: 0.2008\n",
      "Epoch: 1/20... Training loss: 0.1930\n",
      "Epoch: 1/20... Training loss: 0.1893\n",
      "Epoch: 1/20... Training loss: 0.1925\n",
      "Epoch: 1/20... Training loss: 0.1900\n",
      "Epoch: 1/20... Training loss: 0.1916\n",
      "Epoch: 1/20... Training loss: 0.1906\n",
      "Epoch: 1/20... Training loss: 0.1840\n",
      "Epoch: 1/20... Training loss: 0.1954\n",
      "Epoch: 1/20... Training loss: 0.1937\n",
      "Epoch: 1/20... Training loss: 0.1896\n",
      "Epoch: 1/20... Training loss: 0.1848\n",
      "Epoch: 1/20... Training loss: 0.1802\n",
      "Epoch: 1/20... Training loss: 0.1721\n",
      "Epoch: 1/20... Training loss: 0.1822\n",
      "Epoch: 1/20... Training loss: 0.1883\n",
      "Epoch: 1/20... Training loss: 0.1881\n",
      "Epoch: 1/20... Training loss: 0.1774\n",
      "Epoch: 1/20... Training loss: 0.1817\n",
      "Epoch: 1/20... Training loss: 0.1836\n",
      "Epoch: 1/20... Training loss: 0.1768\n",
      "Epoch: 1/20... Training loss: 0.1837\n",
      "Epoch: 1/20... Training loss: 0.1833\n",
      "Epoch: 1/20... Training loss: 0.1827\n",
      "Epoch: 1/20... Training loss: 0.1832\n",
      "Epoch: 1/20... Training loss: 0.1792\n",
      "Epoch: 1/20... Training loss: 0.1820\n",
      "Epoch: 1/20... Training loss: 0.1901\n",
      "Epoch: 1/20... Training loss: 0.1837\n",
      "Epoch: 1/20... Training loss: 0.1821\n",
      "Epoch: 1/20... Training loss: 0.1859\n",
      "Epoch: 1/20... Training loss: 0.1798\n",
      "Epoch: 1/20... Training loss: 0.1713\n",
      "Epoch: 1/20... Training loss: 0.1754\n",
      "Epoch: 1/20... Training loss: 0.1771\n",
      "Epoch: 1/20... Training loss: 0.1804\n",
      "Epoch: 1/20... Training loss: 0.1854\n",
      "Epoch: 1/20... Training loss: 0.1801\n",
      "Epoch: 1/20... Training loss: 0.1745\n",
      "Epoch: 1/20... Training loss: 0.1797\n",
      "Epoch: 1/20... Training loss: 0.1743\n",
      "Epoch: 1/20... Training loss: 0.1826\n",
      "Epoch: 1/20... Training loss: 0.1827\n",
      "Epoch: 1/20... Training loss: 0.1798\n",
      "Epoch: 1/20... Training loss: 0.1797\n",
      "Epoch: 1/20... Training loss: 0.1874\n",
      "Epoch: 1/20... Training loss: 0.1845\n",
      "Epoch: 1/20... Training loss: 0.1851\n",
      "Epoch: 1/20... Training loss: 0.1790\n",
      "Epoch: 1/20... Training loss: 0.1708\n",
      "Epoch: 1/20... Training loss: 0.1762\n",
      "Epoch: 1/20... Training loss: 0.1785\n",
      "Epoch: 1/20... Training loss: 0.1824\n",
      "Epoch: 1/20... Training loss: 0.1752\n",
      "Epoch: 1/20... Training loss: 0.1751\n",
      "Epoch: 1/20... Training loss: 0.1759\n",
      "Epoch: 1/20... Training loss: 0.1700\n",
      "Epoch: 1/20... Training loss: 0.1806\n",
      "Epoch: 1/20... Training loss: 0.1746\n",
      "Epoch: 1/20... Training loss: 0.1687\n",
      "Epoch: 1/20... Training loss: 0.1708\n",
      "Epoch: 1/20... Training loss: 0.1616\n",
      "Epoch: 1/20... Training loss: 0.1715\n",
      "Epoch: 1/20... Training loss: 0.1774\n",
      "Epoch: 1/20... Training loss: 0.1714\n",
      "Epoch: 1/20... Training loss: 0.1689\n",
      "Epoch: 1/20... Training loss: 0.1752\n",
      "Epoch: 1/20... Training loss: 0.1708\n",
      "Epoch: 1/20... Training loss: 0.1712\n",
      "Epoch: 1/20... Training loss: 0.1734\n",
      "Epoch: 1/20... Training loss: 0.1766\n",
      "Epoch: 1/20... Training loss: 0.1666\n",
      "Epoch: 1/20... Training loss: 0.1637\n",
      "Epoch: 1/20... Training loss: 0.1654\n",
      "Epoch: 1/20... Training loss: 0.1626\n",
      "Epoch: 1/20... Training loss: 0.1695\n",
      "Epoch: 1/20... Training loss: 0.1741\n",
      "Epoch: 1/20... Training loss: 0.1747\n",
      "Epoch: 1/20... Training loss: 0.1698\n",
      "Epoch: 1/20... Training loss: 0.1582\n",
      "Epoch: 1/20... Training loss: 0.1685\n",
      "Epoch: 1/20... Training loss: 0.1709\n",
      "Epoch: 1/20... Training loss: 0.1656\n",
      "Epoch: 1/20... Training loss: 0.1646\n",
      "Epoch: 1/20... Training loss: 0.1739\n",
      "Epoch: 1/20... Training loss: 0.1714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20... Training loss: 0.1695\n",
      "Epoch: 1/20... Training loss: 0.1707\n",
      "Epoch: 1/20... Training loss: 0.1671\n",
      "Epoch: 1/20... Training loss: 0.1673\n",
      "Epoch: 1/20... Training loss: 0.1752\n",
      "Epoch: 1/20... Training loss: 0.1680\n",
      "Epoch: 1/20... Training loss: 0.1700\n",
      "Epoch: 1/20... Training loss: 0.1686\n",
      "Epoch: 1/20... Training loss: 0.1668\n",
      "Epoch: 1/20... Training loss: 0.1699\n",
      "Epoch: 1/20... Training loss: 0.1718\n",
      "Epoch: 1/20... Training loss: 0.1696\n",
      "Epoch: 1/20... Training loss: 0.1739\n",
      "Epoch: 1/20... Training loss: 0.1633\n",
      "Epoch: 1/20... Training loss: 0.1632\n",
      "Epoch: 1/20... Training loss: 0.1686\n",
      "Epoch: 1/20... Training loss: 0.1703\n",
      "Epoch: 1/20... Training loss: 0.1607\n",
      "Epoch: 1/20... Training loss: 0.1620\n",
      "Epoch: 1/20... Training loss: 0.1668\n",
      "Epoch: 1/20... Training loss: 0.1648\n",
      "Epoch: 1/20... Training loss: 0.1688\n",
      "Epoch: 1/20... Training loss: 0.1578\n",
      "Epoch: 1/20... Training loss: 0.1721\n",
      "Epoch: 1/20... Training loss: 0.1636\n",
      "Epoch: 1/20... Training loss: 0.1702\n",
      "Epoch: 1/20... Training loss: 0.1706\n",
      "Epoch: 1/20... Training loss: 0.1641\n",
      "Epoch: 1/20... Training loss: 0.1576\n",
      "Epoch: 1/20... Training loss: 0.1662\n",
      "Epoch: 1/20... Training loss: 0.1648\n",
      "Epoch: 1/20... Training loss: 0.1619\n",
      "Epoch: 1/20... Training loss: 0.1568\n",
      "Epoch: 1/20... Training loss: 0.1591\n",
      "Epoch: 1/20... Training loss: 0.1625\n",
      "Epoch: 1/20... Training loss: 0.1669\n",
      "Epoch: 1/20... Training loss: 0.1637\n",
      "Epoch: 1/20... Training loss: 0.1639\n",
      "Epoch: 1/20... Training loss: 0.1579\n",
      "Epoch: 1/20... Training loss: 0.1517\n",
      "Epoch: 1/20... Training loss: 0.1634\n",
      "Epoch: 1/20... Training loss: 0.1550\n",
      "Epoch: 1/20... Training loss: 0.1611\n",
      "Epoch: 1/20... Training loss: 0.1594\n",
      "Epoch: 1/20... Training loss: 0.1641\n",
      "Epoch: 1/20... Training loss: 0.1550\n",
      "Epoch: 1/20... Training loss: 0.1625\n",
      "Epoch: 1/20... Training loss: 0.1643\n",
      "Epoch: 1/20... Training loss: 0.1647\n",
      "Epoch: 1/20... Training loss: 0.1563\n",
      "Epoch: 1/20... Training loss: 0.1617\n",
      "Epoch: 1/20... Training loss: 0.1532\n",
      "Epoch: 1/20... Training loss: 0.1589\n",
      "Epoch: 1/20... Training loss: 0.1594\n",
      "Epoch: 1/20... Training loss: 0.1535\n",
      "Epoch: 1/20... Training loss: 0.1575\n",
      "Epoch: 1/20... Training loss: 0.1609\n",
      "Epoch: 1/20... Training loss: 0.1633\n",
      "Epoch: 1/20... Training loss: 0.1577\n",
      "Epoch: 1/20... Training loss: 0.1542\n",
      "Epoch: 1/20... Training loss: 0.1616\n",
      "Epoch: 1/20... Training loss: 0.1558\n",
      "Epoch: 1/20... Training loss: 0.1552\n",
      "Epoch: 1/20... Training loss: 0.1529\n",
      "Epoch: 1/20... Training loss: 0.1630\n",
      "Epoch: 1/20... Training loss: 0.1619\n",
      "Epoch: 1/20... Training loss: 0.1558\n",
      "Epoch: 1/20... Training loss: 0.1588\n",
      "Epoch: 1/20... Training loss: 0.1564\n",
      "Epoch: 1/20... Training loss: 0.1657\n",
      "Epoch: 1/20... Training loss: 0.1620\n",
      "Epoch: 1/20... Training loss: 0.1520\n",
      "Epoch: 1/20... Training loss: 0.1709\n",
      "Epoch: 1/20... Training loss: 0.1578\n",
      "Epoch: 1/20... Training loss: 0.1665\n",
      "Epoch: 1/20... Training loss: 0.1630\n",
      "Epoch: 1/20... Training loss: 0.1547\n",
      "Epoch: 1/20... Training loss: 0.1546\n",
      "Epoch: 2/20... Training loss: 0.1529\n",
      "Epoch: 2/20... Training loss: 0.1502\n",
      "Epoch: 2/20... Training loss: 0.1542\n",
      "Epoch: 2/20... Training loss: 0.1546\n",
      "Epoch: 2/20... Training loss: 0.1564\n",
      "Epoch: 2/20... Training loss: 0.1531\n",
      "Epoch: 2/20... Training loss: 0.1525\n",
      "Epoch: 2/20... Training loss: 0.1549\n",
      "Epoch: 2/20... Training loss: 0.1538\n",
      "Epoch: 2/20... Training loss: 0.1514\n",
      "Epoch: 2/20... Training loss: 0.1506\n",
      "Epoch: 2/20... Training loss: 0.1622\n",
      "Epoch: 2/20... Training loss: 0.1563\n",
      "Epoch: 2/20... Training loss: 0.1559\n",
      "Epoch: 2/20... Training loss: 0.1548\n",
      "Epoch: 2/20... Training loss: 0.1592\n",
      "Epoch: 2/20... Training loss: 0.1469\n",
      "Epoch: 2/20... Training loss: 0.1500\n",
      "Epoch: 2/20... Training loss: 0.1639\n",
      "Epoch: 2/20... Training loss: 0.1528\n",
      "Epoch: 2/20... Training loss: 0.1485\n",
      "Epoch: 2/20... Training loss: 0.1543\n",
      "Epoch: 2/20... Training loss: 0.1516\n",
      "Epoch: 2/20... Training loss: 0.1610\n",
      "Epoch: 2/20... Training loss: 0.1575\n",
      "Epoch: 2/20... Training loss: 0.1600\n",
      "Epoch: 2/20... Training loss: 0.1563\n",
      "Epoch: 2/20... Training loss: 0.1517\n",
      "Epoch: 2/20... Training loss: 0.1524\n",
      "Epoch: 2/20... Training loss: 0.1506\n",
      "Epoch: 2/20... Training loss: 0.1540\n",
      "Epoch: 2/20... Training loss: 0.1480\n",
      "Epoch: 2/20... Training loss: 0.1490\n",
      "Epoch: 2/20... Training loss: 0.1477\n",
      "Epoch: 2/20... Training loss: 0.1502\n",
      "Epoch: 2/20... Training loss: 0.1504\n",
      "Epoch: 2/20... Training loss: 0.1530\n",
      "Epoch: 2/20... Training loss: 0.1515\n",
      "Epoch: 2/20... Training loss: 0.1512\n",
      "Epoch: 2/20... Training loss: 0.1528\n",
      "Epoch: 2/20... Training loss: 0.1462\n",
      "Epoch: 2/20... Training loss: 0.1520\n",
      "Epoch: 2/20... Training loss: 0.1450\n",
      "Epoch: 2/20... Training loss: 0.1519\n",
      "Epoch: 2/20... Training loss: 0.1463\n",
      "Epoch: 2/20... Training loss: 0.1512\n",
      "Epoch: 2/20... Training loss: 0.1544\n",
      "Epoch: 2/20... Training loss: 0.1535\n",
      "Epoch: 2/20... Training loss: 0.1527\n",
      "Epoch: 2/20... Training loss: 0.1553\n",
      "Epoch: 2/20... Training loss: 0.1468\n",
      "Epoch: 2/20... Training loss: 0.1525\n",
      "Epoch: 2/20... Training loss: 0.1549\n",
      "Epoch: 2/20... Training loss: 0.1515\n",
      "Epoch: 2/20... Training loss: 0.1448\n",
      "Epoch: 2/20... Training loss: 0.1485\n",
      "Epoch: 2/20... Training loss: 0.1462\n",
      "Epoch: 2/20... Training loss: 0.1450\n",
      "Epoch: 2/20... Training loss: 0.1410\n",
      "Epoch: 2/20... Training loss: 0.1417\n",
      "Epoch: 2/20... Training loss: 0.1442\n",
      "Epoch: 2/20... Training loss: 0.1530\n",
      "Epoch: 2/20... Training loss: 0.1590\n",
      "Epoch: 2/20... Training loss: 0.1577\n",
      "Epoch: 2/20... Training loss: 0.1538\n",
      "Epoch: 2/20... Training loss: 0.1482\n",
      "Epoch: 2/20... Training loss: 0.1547\n",
      "Epoch: 2/20... Training loss: 0.1553\n",
      "Epoch: 2/20... Training loss: 0.1452\n",
      "Epoch: 2/20... Training loss: 0.1544\n",
      "Epoch: 2/20... Training loss: 0.1501\n",
      "Epoch: 2/20... Training loss: 0.1481\n",
      "Epoch: 2/20... Training loss: 0.1520\n",
      "Epoch: 2/20... Training loss: 0.1506\n",
      "Epoch: 2/20... Training loss: 0.1429\n",
      "Epoch: 2/20... Training loss: 0.1491\n",
      "Epoch: 2/20... Training loss: 0.1509\n",
      "Epoch: 2/20... Training loss: 0.1480\n",
      "Epoch: 2/20... Training loss: 0.1570\n",
      "Epoch: 2/20... Training loss: 0.1443\n",
      "Epoch: 2/20... Training loss: 0.1459\n",
      "Epoch: 2/20... Training loss: 0.1450\n",
      "Epoch: 2/20... Training loss: 0.1470\n",
      "Epoch: 2/20... Training loss: 0.1492\n",
      "Epoch: 2/20... Training loss: 0.1489\n",
      "Epoch: 2/20... Training loss: 0.1505\n",
      "Epoch: 2/20... Training loss: 0.1569\n",
      "Epoch: 2/20... Training loss: 0.1543\n",
      "Epoch: 2/20... Training loss: 0.1477\n",
      "Epoch: 2/20... Training loss: 0.1402\n",
      "Epoch: 2/20... Training loss: 0.1381\n",
      "Epoch: 2/20... Training loss: 0.1399\n",
      "Epoch: 2/20... Training loss: 0.1465\n",
      "Epoch: 2/20... Training loss: 0.1528\n",
      "Epoch: 2/20... Training loss: 0.1469\n",
      "Epoch: 2/20... Training loss: 0.1427\n",
      "Epoch: 2/20... Training loss: 0.1591\n",
      "Epoch: 2/20... Training loss: 0.1442\n",
      "Epoch: 2/20... Training loss: 0.1466\n",
      "Epoch: 2/20... Training loss: 0.1532\n",
      "Epoch: 2/20... Training loss: 0.1497\n",
      "Epoch: 2/20... Training loss: 0.1455\n",
      "Epoch: 2/20... Training loss: 0.1458\n",
      "Epoch: 2/20... Training loss: 0.1412\n",
      "Epoch: 2/20... Training loss: 0.1453\n",
      "Epoch: 2/20... Training loss: 0.1459\n",
      "Epoch: 2/20... Training loss: 0.1526\n",
      "Epoch: 2/20... Training loss: 0.1488\n",
      "Epoch: 2/20... Training loss: 0.1441\n",
      "Epoch: 2/20... Training loss: 0.1462\n",
      "Epoch: 2/20... Training loss: 0.1590\n",
      "Epoch: 2/20... Training loss: 0.1489\n",
      "Epoch: 2/20... Training loss: 0.1432\n",
      "Epoch: 2/20... Training loss: 0.1461\n",
      "Epoch: 2/20... Training loss: 0.1477\n",
      "Epoch: 2/20... Training loss: 0.1478\n",
      "Epoch: 2/20... Training loss: 0.1404\n",
      "Epoch: 2/20... Training loss: 0.1452\n",
      "Epoch: 2/20... Training loss: 0.1531\n",
      "Epoch: 2/20... Training loss: 0.1528\n",
      "Epoch: 2/20... Training loss: 0.1345\n",
      "Epoch: 2/20... Training loss: 0.1416\n",
      "Epoch: 2/20... Training loss: 0.1526\n",
      "Epoch: 2/20... Training loss: 0.1393\n",
      "Epoch: 2/20... Training loss: 0.1335\n",
      "Epoch: 2/20... Training loss: 0.1473\n",
      "Epoch: 2/20... Training loss: 0.1489\n",
      "Epoch: 2/20... Training loss: 0.1401\n",
      "Epoch: 2/20... Training loss: 0.1442\n",
      "Epoch: 2/20... Training loss: 0.1422\n",
      "Epoch: 2/20... Training loss: 0.1384\n",
      "Epoch: 2/20... Training loss: 0.1407\n",
      "Epoch: 2/20... Training loss: 0.1434\n",
      "Epoch: 2/20... Training loss: 0.1461\n",
      "Epoch: 2/20... Training loss: 0.1386\n",
      "Epoch: 2/20... Training loss: 0.1543\n",
      "Epoch: 2/20... Training loss: 0.1508\n",
      "Epoch: 2/20... Training loss: 0.1469\n",
      "Epoch: 2/20... Training loss: 0.1459\n",
      "Epoch: 2/20... Training loss: 0.1445\n",
      "Epoch: 2/20... Training loss: 0.1394\n",
      "Epoch: 2/20... Training loss: 0.1431\n",
      "Epoch: 2/20... Training loss: 0.1388\n",
      "Epoch: 2/20... Training loss: 0.1423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/20... Training loss: 0.1523\n",
      "Epoch: 2/20... Training loss: 0.1561\n",
      "Epoch: 2/20... Training loss: 0.1442\n",
      "Epoch: 2/20... Training loss: 0.1385\n",
      "Epoch: 2/20... Training loss: 0.1430\n",
      "Epoch: 2/20... Training loss: 0.1365\n",
      "Epoch: 2/20... Training loss: 0.1453\n",
      "Epoch: 2/20... Training loss: 0.1475\n",
      "Epoch: 2/20... Training loss: 0.1464\n",
      "Epoch: 2/20... Training loss: 0.1444\n",
      "Epoch: 2/20... Training loss: 0.1419\n",
      "Epoch: 2/20... Training loss: 0.1418\n",
      "Epoch: 2/20... Training loss: 0.1413\n",
      "Epoch: 2/20... Training loss: 0.1443\n",
      "Epoch: 2/20... Training loss: 0.1471\n",
      "Epoch: 2/20... Training loss: 0.1429\n",
      "Epoch: 2/20... Training loss: 0.1451\n",
      "Epoch: 2/20... Training loss: 0.1406\n",
      "Epoch: 2/20... Training loss: 0.1419\n",
      "Epoch: 2/20... Training loss: 0.1516\n",
      "Epoch: 2/20... Training loss: 0.1439\n",
      "Epoch: 2/20... Training loss: 0.1421\n",
      "Epoch: 2/20... Training loss: 0.1467\n",
      "Epoch: 2/20... Training loss: 0.1422\n",
      "Epoch: 2/20... Training loss: 0.1343\n",
      "Epoch: 2/20... Training loss: 0.1347\n",
      "Epoch: 2/20... Training loss: 0.1450\n",
      "Epoch: 2/20... Training loss: 0.1428\n",
      "Epoch: 2/20... Training loss: 0.1458\n",
      "Epoch: 2/20... Training loss: 0.1440\n",
      "Epoch: 2/20... Training loss: 0.1422\n",
      "Epoch: 2/20... Training loss: 0.1460\n",
      "Epoch: 2/20... Training loss: 0.1398\n",
      "Epoch: 2/20... Training loss: 0.1477\n",
      "Epoch: 2/20... Training loss: 0.1471\n",
      "Epoch: 2/20... Training loss: 0.1460\n",
      "Epoch: 2/20... Training loss: 0.1467\n",
      "Epoch: 2/20... Training loss: 0.1480\n",
      "Epoch: 2/20... Training loss: 0.1488\n",
      "Epoch: 2/20... Training loss: 0.1481\n",
      "Epoch: 2/20... Training loss: 0.1424\n",
      "Epoch: 2/20... Training loss: 0.1356\n",
      "Epoch: 2/20... Training loss: 0.1429\n",
      "Epoch: 2/20... Training loss: 0.1488\n",
      "Epoch: 2/20... Training loss: 0.1485\n",
      "Epoch: 2/20... Training loss: 0.1414\n",
      "Epoch: 2/20... Training loss: 0.1439\n",
      "Epoch: 2/20... Training loss: 0.1426\n",
      "Epoch: 2/20... Training loss: 0.1373\n",
      "Epoch: 2/20... Training loss: 0.1483\n",
      "Epoch: 2/20... Training loss: 0.1419\n",
      "Epoch: 2/20... Training loss: 0.1355\n",
      "Epoch: 2/20... Training loss: 0.1389\n",
      "Epoch: 2/20... Training loss: 0.1288\n",
      "Epoch: 2/20... Training loss: 0.1396\n",
      "Epoch: 2/20... Training loss: 0.1451\n",
      "Epoch: 2/20... Training loss: 0.1408\n",
      "Epoch: 2/20... Training loss: 0.1385\n",
      "Epoch: 2/20... Training loss: 0.1433\n",
      "Epoch: 2/20... Training loss: 0.1409\n",
      "Epoch: 2/20... Training loss: 0.1415\n",
      "Epoch: 2/20... Training loss: 0.1445\n",
      "Epoch: 2/20... Training loss: 0.1491\n",
      "Epoch: 2/20... Training loss: 0.1399\n",
      "Epoch: 2/20... Training loss: 0.1370\n",
      "Epoch: 2/20... Training loss: 0.1359\n",
      "Epoch: 2/20... Training loss: 0.1317\n",
      "Epoch: 2/20... Training loss: 0.1409\n",
      "Epoch: 2/20... Training loss: 0.1435\n",
      "Epoch: 2/20... Training loss: 0.1434\n",
      "Epoch: 2/20... Training loss: 0.1443\n",
      "Epoch: 2/20... Training loss: 0.1316\n",
      "Epoch: 2/20... Training loss: 0.1401\n",
      "Epoch: 2/20... Training loss: 0.1422\n",
      "Epoch: 2/20... Training loss: 0.1382\n",
      "Epoch: 2/20... Training loss: 0.1376\n",
      "Epoch: 2/20... Training loss: 0.1478\n",
      "Epoch: 2/20... Training loss: 0.1444\n",
      "Epoch: 2/20... Training loss: 0.1408\n",
      "Epoch: 2/20... Training loss: 0.1434\n",
      "Epoch: 2/20... Training loss: 0.1386\n",
      "Epoch: 2/20... Training loss: 0.1385\n",
      "Epoch: 2/20... Training loss: 0.1458\n",
      "Epoch: 2/20... Training loss: 0.1439\n",
      "Epoch: 2/20... Training loss: 0.1428\n",
      "Epoch: 2/20... Training loss: 0.1444\n",
      "Epoch: 2/20... Training loss: 0.1403\n",
      "Epoch: 2/20... Training loss: 0.1450\n",
      "Epoch: 2/20... Training loss: 0.1427\n",
      "Epoch: 2/20... Training loss: 0.1425\n",
      "Epoch: 2/20... Training loss: 0.1444\n",
      "Epoch: 2/20... Training loss: 0.1383\n",
      "Epoch: 2/20... Training loss: 0.1369\n",
      "Epoch: 2/20... Training loss: 0.1446\n",
      "Epoch: 2/20... Training loss: 0.1454\n",
      "Epoch: 2/20... Training loss: 0.1354\n",
      "Epoch: 2/20... Training loss: 0.1362\n",
      "Epoch: 2/20... Training loss: 0.1400\n",
      "Epoch: 2/20... Training loss: 0.1395\n",
      "Epoch: 2/20... Training loss: 0.1441\n",
      "Epoch: 2/20... Training loss: 0.1351\n",
      "Epoch: 2/20... Training loss: 0.1487\n",
      "Epoch: 2/20... Training loss: 0.1386\n",
      "Epoch: 2/20... Training loss: 0.1485\n",
      "Epoch: 2/20... Training loss: 0.1457\n",
      "Epoch: 2/20... Training loss: 0.1416\n",
      "Epoch: 2/20... Training loss: 0.1362\n",
      "Epoch: 2/20... Training loss: 0.1421\n",
      "Epoch: 2/20... Training loss: 0.1418\n",
      "Epoch: 2/20... Training loss: 0.1368\n",
      "Epoch: 2/20... Training loss: 0.1335\n",
      "Epoch: 2/20... Training loss: 0.1364\n",
      "Epoch: 2/20... Training loss: 0.1393\n",
      "Epoch: 2/20... Training loss: 0.1412\n",
      "Epoch: 2/20... Training loss: 0.1419\n",
      "Epoch: 2/20... Training loss: 0.1413\n",
      "Epoch: 2/20... Training loss: 0.1367\n",
      "Epoch: 2/20... Training loss: 0.1306\n",
      "Epoch: 2/20... Training loss: 0.1399\n",
      "Epoch: 2/20... Training loss: 0.1329\n",
      "Epoch: 2/20... Training loss: 0.1393\n",
      "Epoch: 2/20... Training loss: 0.1386\n",
      "Epoch: 2/20... Training loss: 0.1412\n",
      "Epoch: 2/20... Training loss: 0.1336\n",
      "Epoch: 2/20... Training loss: 0.1412\n",
      "Epoch: 2/20... Training loss: 0.1431\n",
      "Epoch: 2/20... Training loss: 0.1436\n",
      "Epoch: 2/20... Training loss: 0.1350\n",
      "Epoch: 2/20... Training loss: 0.1398\n",
      "Epoch: 2/20... Training loss: 0.1322\n",
      "Epoch: 2/20... Training loss: 0.1390\n",
      "Epoch: 2/20... Training loss: 0.1388\n",
      "Epoch: 2/20... Training loss: 0.1329\n",
      "Epoch: 2/20... Training loss: 0.1360\n",
      "Epoch: 2/20... Training loss: 0.1392\n",
      "Epoch: 2/20... Training loss: 0.1402\n",
      "Epoch: 2/20... Training loss: 0.1378\n",
      "Epoch: 2/20... Training loss: 0.1335\n",
      "Epoch: 2/20... Training loss: 0.1408\n",
      "Epoch: 2/20... Training loss: 0.1354\n",
      "Epoch: 2/20... Training loss: 0.1333\n",
      "Epoch: 2/20... Training loss: 0.1364\n",
      "Epoch: 2/20... Training loss: 0.1409\n",
      "Epoch: 2/20... Training loss: 0.1420\n",
      "Epoch: 2/20... Training loss: 0.1354\n",
      "Epoch: 2/20... Training loss: 0.1384\n",
      "Epoch: 2/20... Training loss: 0.1379\n",
      "Epoch: 2/20... Training loss: 0.1471\n",
      "Epoch: 2/20... Training loss: 0.1404\n",
      "Epoch: 2/20... Training loss: 0.1343\n",
      "Epoch: 2/20... Training loss: 0.1508\n",
      "Epoch: 2/20... Training loss: 0.1390\n",
      "Epoch: 2/20... Training loss: 0.1453\n",
      "Epoch: 2/20... Training loss: 0.1411\n",
      "Epoch: 2/20... Training loss: 0.1351\n",
      "Epoch: 2/20... Training loss: 0.1357\n",
      "Epoch: 3/20... Training loss: 0.1333\n",
      "Epoch: 3/20... Training loss: 0.1309\n",
      "Epoch: 3/20... Training loss: 0.1344\n",
      "Epoch: 3/20... Training loss: 0.1358\n",
      "Epoch: 3/20... Training loss: 0.1360\n",
      "Epoch: 3/20... Training loss: 0.1361\n",
      "Epoch: 3/20... Training loss: 0.1350\n",
      "Epoch: 3/20... Training loss: 0.1375\n",
      "Epoch: 3/20... Training loss: 0.1362\n",
      "Epoch: 3/20... Training loss: 0.1348\n",
      "Epoch: 3/20... Training loss: 0.1311\n",
      "Epoch: 3/20... Training loss: 0.1430\n",
      "Epoch: 3/20... Training loss: 0.1373\n",
      "Epoch: 3/20... Training loss: 0.1384\n",
      "Epoch: 3/20... Training loss: 0.1353\n",
      "Epoch: 3/20... Training loss: 0.1439\n",
      "Epoch: 3/20... Training loss: 0.1291\n",
      "Epoch: 3/20... Training loss: 0.1340\n",
      "Epoch: 3/20... Training loss: 0.1457\n",
      "Epoch: 3/20... Training loss: 0.1369\n",
      "Epoch: 3/20... Training loss: 0.1305\n",
      "Epoch: 3/20... Training loss: 0.1373\n",
      "Epoch: 3/20... Training loss: 0.1343\n",
      "Epoch: 3/20... Training loss: 0.1416\n",
      "Epoch: 3/20... Training loss: 0.1382\n",
      "Epoch: 3/20... Training loss: 0.1395\n",
      "Epoch: 3/20... Training loss: 0.1379\n",
      "Epoch: 3/20... Training loss: 0.1321\n",
      "Epoch: 3/20... Training loss: 0.1344\n",
      "Epoch: 3/20... Training loss: 0.1325\n",
      "Epoch: 3/20... Training loss: 0.1366\n",
      "Epoch: 3/20... Training loss: 0.1293\n",
      "Epoch: 3/20... Training loss: 0.1314\n",
      "Epoch: 3/20... Training loss: 0.1309\n",
      "Epoch: 3/20... Training loss: 0.1341\n",
      "Epoch: 3/20... Training loss: 0.1337\n",
      "Epoch: 3/20... Training loss: 0.1395\n",
      "Epoch: 3/20... Training loss: 0.1331\n",
      "Epoch: 3/20... Training loss: 0.1347\n",
      "Epoch: 3/20... Training loss: 0.1363\n",
      "Epoch: 3/20... Training loss: 0.1309\n",
      "Epoch: 3/20... Training loss: 0.1359\n",
      "Epoch: 3/20... Training loss: 0.1298\n",
      "Epoch: 3/20... Training loss: 0.1352\n",
      "Epoch: 3/20... Training loss: 0.1303\n",
      "Epoch: 3/20... Training loss: 0.1349\n",
      "Epoch: 3/20... Training loss: 0.1399\n",
      "Epoch: 3/20... Training loss: 0.1387\n",
      "Epoch: 3/20... Training loss: 0.1388\n",
      "Epoch: 3/20... Training loss: 0.1377\n",
      "Epoch: 3/20... Training loss: 0.1321\n",
      "Epoch: 3/20... Training loss: 0.1353\n",
      "Epoch: 3/20... Training loss: 0.1406\n",
      "Epoch: 3/20... Training loss: 0.1361\n",
      "Epoch: 3/20... Training loss: 0.1322\n",
      "Epoch: 3/20... Training loss: 0.1318\n",
      "Epoch: 3/20... Training loss: 0.1326\n",
      "Epoch: 3/20... Training loss: 0.1295\n",
      "Epoch: 3/20... Training loss: 0.1288\n",
      "Epoch: 3/20... Training loss: 0.1270\n",
      "Epoch: 3/20... Training loss: 0.1309\n",
      "Epoch: 3/20... Training loss: 0.1355\n",
      "Epoch: 3/20... Training loss: 0.1439\n",
      "Epoch: 3/20... Training loss: 0.1410\n",
      "Epoch: 3/20... Training loss: 0.1405\n",
      "Epoch: 3/20... Training loss: 0.1333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/20... Training loss: 0.1386\n",
      "Epoch: 3/20... Training loss: 0.1387\n",
      "Epoch: 3/20... Training loss: 0.1313\n",
      "Epoch: 3/20... Training loss: 0.1389\n",
      "Epoch: 3/20... Training loss: 0.1365\n",
      "Epoch: 3/20... Training loss: 0.1336\n",
      "Epoch: 3/20... Training loss: 0.1372\n",
      "Epoch: 3/20... Training loss: 0.1364\n",
      "Epoch: 3/20... Training loss: 0.1286\n",
      "Epoch: 3/20... Training loss: 0.1346\n",
      "Epoch: 3/20... Training loss: 0.1357\n",
      "Epoch: 3/20... Training loss: 0.1340\n",
      "Epoch: 3/20... Training loss: 0.1418\n",
      "Epoch: 3/20... Training loss: 0.1293\n",
      "Epoch: 3/20... Training loss: 0.1316\n",
      "Epoch: 3/20... Training loss: 0.1292\n",
      "Epoch: 3/20... Training loss: 0.1320\n",
      "Epoch: 3/20... Training loss: 0.1365\n",
      "Epoch: 3/20... Training loss: 0.1354\n",
      "Epoch: 3/20... Training loss: 0.1366\n",
      "Epoch: 3/20... Training loss: 0.1415\n",
      "Epoch: 3/20... Training loss: 0.1410\n",
      "Epoch: 3/20... Training loss: 0.1343\n",
      "Epoch: 3/20... Training loss: 0.1255\n",
      "Epoch: 3/20... Training loss: 0.1240\n",
      "Epoch: 3/20... Training loss: 0.1261\n",
      "Epoch: 3/20... Training loss: 0.1323\n",
      "Epoch: 3/20... Training loss: 0.1392\n",
      "Epoch: 3/20... Training loss: 0.1325\n",
      "Epoch: 3/20... Training loss: 0.1291\n",
      "Epoch: 3/20... Training loss: 0.1435\n",
      "Epoch: 3/20... Training loss: 0.1290\n",
      "Epoch: 3/20... Training loss: 0.1323\n",
      "Epoch: 3/20... Training loss: 0.1391\n",
      "Epoch: 3/20... Training loss: 0.1345\n",
      "Epoch: 3/20... Training loss: 0.1313\n",
      "Epoch: 3/20... Training loss: 0.1313\n",
      "Epoch: 3/20... Training loss: 0.1274\n",
      "Epoch: 3/20... Training loss: 0.1324\n",
      "Epoch: 3/20... Training loss: 0.1318\n",
      "Epoch: 3/20... Training loss: 0.1368\n",
      "Epoch: 3/20... Training loss: 0.1343\n",
      "Epoch: 3/20... Training loss: 0.1317\n",
      "Epoch: 3/20... Training loss: 0.1319\n",
      "Epoch: 3/20... Training loss: 0.1464\n",
      "Epoch: 3/20... Training loss: 0.1359\n",
      "Epoch: 3/20... Training loss: 0.1311\n",
      "Epoch: 3/20... Training loss: 0.1322\n",
      "Epoch: 3/20... Training loss: 0.1342\n",
      "Epoch: 3/20... Training loss: 0.1336\n",
      "Epoch: 3/20... Training loss: 0.1274\n",
      "Epoch: 3/20... Training loss: 0.1312\n",
      "Epoch: 3/20... Training loss: 0.1394\n",
      "Epoch: 3/20... Training loss: 0.1397\n",
      "Epoch: 3/20... Training loss: 0.1219\n",
      "Epoch: 3/20... Training loss: 0.1285\n",
      "Epoch: 3/20... Training loss: 0.1392\n",
      "Epoch: 3/20... Training loss: 0.1283\n",
      "Epoch: 3/20... Training loss: 0.1215\n",
      "Epoch: 3/20... Training loss: 0.1352\n",
      "Epoch: 3/20... Training loss: 0.1350\n",
      "Epoch: 3/20... Training loss: 0.1271\n",
      "Epoch: 3/20... Training loss: 0.1295\n",
      "Epoch: 3/20... Training loss: 0.1288\n",
      "Epoch: 3/20... Training loss: 0.1260\n",
      "Epoch: 3/20... Training loss: 0.1281\n",
      "Epoch: 3/20... Training loss: 0.1309\n",
      "Epoch: 3/20... Training loss: 0.1336\n",
      "Epoch: 3/20... Training loss: 0.1264\n",
      "Epoch: 3/20... Training loss: 0.1403\n",
      "Epoch: 3/20... Training loss: 0.1375\n",
      "Epoch: 3/20... Training loss: 0.1327\n",
      "Epoch: 3/20... Training loss: 0.1338\n",
      "Epoch: 3/20... Training loss: 0.1311\n",
      "Epoch: 3/20... Training loss: 0.1267\n",
      "Epoch: 3/20... Training loss: 0.1316\n",
      "Epoch: 3/20... Training loss: 0.1258\n",
      "Epoch: 3/20... Training loss: 0.1306\n",
      "Epoch: 3/20... Training loss: 0.1388\n",
      "Epoch: 3/20... Training loss: 0.1447\n",
      "Epoch: 3/20... Training loss: 0.1316\n",
      "Epoch: 3/20... Training loss: 0.1256\n",
      "Epoch: 3/20... Training loss: 0.1309\n",
      "Epoch: 3/20... Training loss: 0.1259\n",
      "Epoch: 3/20... Training loss: 0.1328\n",
      "Epoch: 3/20... Training loss: 0.1352\n",
      "Epoch: 3/20... Training loss: 0.1347\n",
      "Epoch: 3/20... Training loss: 0.1338\n",
      "Epoch: 3/20... Training loss: 0.1308\n",
      "Epoch: 3/20... Training loss: 0.1311\n",
      "Epoch: 3/20... Training loss: 0.1298\n",
      "Epoch: 3/20... Training loss: 0.1327\n",
      "Epoch: 3/20... Training loss: 0.1366\n",
      "Epoch: 3/20... Training loss: 0.1315\n",
      "Epoch: 3/20... Training loss: 0.1338\n",
      "Epoch: 3/20... Training loss: 0.1290\n",
      "Epoch: 3/20... Training loss: 0.1301\n",
      "Epoch: 3/20... Training loss: 0.1382\n",
      "Epoch: 3/20... Training loss: 0.1320\n",
      "Epoch: 3/20... Training loss: 0.1298\n",
      "Epoch: 3/20... Training loss: 0.1345\n",
      "Epoch: 3/20... Training loss: 0.1305\n",
      "Epoch: 3/20... Training loss: 0.1229\n",
      "Epoch: 3/20... Training loss: 0.1234\n",
      "Epoch: 3/20... Training loss: 0.1321\n",
      "Epoch: 3/20... Training loss: 0.1314\n",
      "Epoch: 3/20... Training loss: 0.1330\n",
      "Epoch: 3/20... Training loss: 0.1325\n",
      "Epoch: 3/20... Training loss: 0.1309\n",
      "Epoch: 3/20... Training loss: 0.1352\n",
      "Epoch: 3/20... Training loss: 0.1279\n",
      "Epoch: 3/20... Training loss: 0.1362\n",
      "Epoch: 3/20... Training loss: 0.1352\n",
      "Epoch: 3/20... Training loss: 0.1348\n",
      "Epoch: 3/20... Training loss: 0.1352\n",
      "Epoch: 3/20... Training loss: 0.1362\n",
      "Epoch: 3/20... Training loss: 0.1363\n",
      "Epoch: 3/20... Training loss: 0.1350\n",
      "Epoch: 3/20... Training loss: 0.1314\n",
      "Epoch: 3/20... Training loss: 0.1257\n",
      "Epoch: 3/20... Training loss: 0.1329\n",
      "Epoch: 3/20... Training loss: 0.1375\n",
      "Epoch: 3/20... Training loss: 0.1362\n",
      "Epoch: 3/20... Training loss: 0.1312\n",
      "Epoch: 3/20... Training loss: 0.1328\n",
      "Epoch: 3/20... Training loss: 0.1321\n",
      "Epoch: 3/20... Training loss: 0.1265\n",
      "Epoch: 3/20... Training loss: 0.1369\n",
      "Epoch: 3/20... Training loss: 0.1304\n",
      "Epoch: 3/20... Training loss: 0.1248\n",
      "Epoch: 3/20... Training loss: 0.1287\n",
      "Epoch: 3/20... Training loss: 0.1195\n",
      "Epoch: 3/20... Training loss: 0.1301\n",
      "Epoch: 3/20... Training loss: 0.1334\n",
      "Epoch: 3/20... Training loss: 0.1305\n",
      "Epoch: 3/20... Training loss: 0.1281\n",
      "Epoch: 3/20... Training loss: 0.1337\n",
      "Epoch: 3/20... Training loss: 0.1298\n",
      "Epoch: 3/20... Training loss: 0.1310\n",
      "Epoch: 3/20... Training loss: 0.1330\n",
      "Epoch: 3/20... Training loss: 0.1389\n",
      "Epoch: 3/20... Training loss: 0.1306\n",
      "Epoch: 3/20... Training loss: 0.1280\n",
      "Epoch: 3/20... Training loss: 0.1260\n",
      "Epoch: 3/20... Training loss: 0.1225\n",
      "Epoch: 3/20... Training loss: 0.1300\n",
      "Epoch: 3/20... Training loss: 0.1332\n",
      "Epoch: 3/20... Training loss: 0.1333\n",
      "Epoch: 3/20... Training loss: 0.1344\n",
      "Epoch: 3/20... Training loss: 0.1225\n",
      "Epoch: 3/20... Training loss: 0.1303\n",
      "Epoch: 3/20... Training loss: 0.1316\n",
      "Epoch: 3/20... Training loss: 0.1281\n",
      "Epoch: 3/20... Training loss: 0.1285\n",
      "Epoch: 3/20... Training loss: 0.1382\n",
      "Epoch: 3/20... Training loss: 0.1342\n",
      "Epoch: 3/20... Training loss: 0.1305\n",
      "Epoch: 3/20... Training loss: 0.1334\n",
      "Epoch: 3/20... Training loss: 0.1296\n",
      "Epoch: 3/20... Training loss: 0.1284\n",
      "Epoch: 3/20... Training loss: 0.1348\n",
      "Epoch: 3/20... Training loss: 0.1350\n",
      "Epoch: 3/20... Training loss: 0.1331\n",
      "Epoch: 3/20... Training loss: 0.1344\n",
      "Epoch: 3/20... Training loss: 0.1313\n",
      "Epoch: 3/20... Training loss: 0.1354\n",
      "Epoch: 3/20... Training loss: 0.1322\n",
      "Epoch: 3/20... Training loss: 0.1328\n",
      "Epoch: 3/20... Training loss: 0.1340\n",
      "Epoch: 3/20... Training loss: 0.1291\n",
      "Epoch: 3/20... Training loss: 0.1280\n",
      "Epoch: 3/20... Training loss: 0.1352\n",
      "Epoch: 3/20... Training loss: 0.1354\n",
      "Epoch: 3/20... Training loss: 0.1261\n",
      "Epoch: 3/20... Training loss: 0.1273\n",
      "Epoch: 3/20... Training loss: 0.1311\n",
      "Epoch: 3/20... Training loss: 0.1307\n",
      "Epoch: 3/20... Training loss: 0.1355\n",
      "Epoch: 3/20... Training loss: 0.1273\n",
      "Epoch: 3/20... Training loss: 0.1394\n",
      "Epoch: 3/20... Training loss: 0.1301\n",
      "Epoch: 3/20... Training loss: 0.1391\n",
      "Epoch: 3/20... Training loss: 0.1361\n",
      "Epoch: 3/20... Training loss: 0.1322\n",
      "Epoch: 3/20... Training loss: 0.1278\n",
      "Epoch: 3/20... Training loss: 0.1326\n",
      "Epoch: 3/20... Training loss: 0.1319\n",
      "Epoch: 3/20... Training loss: 0.1280\n",
      "Epoch: 3/20... Training loss: 0.1244\n",
      "Epoch: 3/20... Training loss: 0.1272\n",
      "Epoch: 3/20... Training loss: 0.1294\n",
      "Epoch: 3/20... Training loss: 0.1323\n",
      "Epoch: 3/20... Training loss: 0.1326\n",
      "Epoch: 3/20... Training loss: 0.1319\n",
      "Epoch: 3/20... Training loss: 0.1293\n",
      "Epoch: 3/20... Training loss: 0.1226\n",
      "Epoch: 3/20... Training loss: 0.1309\n",
      "Epoch: 3/20... Training loss: 0.1243\n",
      "Epoch: 3/20... Training loss: 0.1306\n",
      "Epoch: 3/20... Training loss: 0.1306\n",
      "Epoch: 3/20... Training loss: 0.1311\n",
      "Epoch: 3/20... Training loss: 0.1260\n",
      "Epoch: 3/20... Training loss: 0.1322\n",
      "Epoch: 3/20... Training loss: 0.1345\n",
      "Epoch: 3/20... Training loss: 0.1346\n",
      "Epoch: 3/20... Training loss: 0.1264\n",
      "Epoch: 3/20... Training loss: 0.1303\n",
      "Epoch: 3/20... Training loss: 0.1235\n",
      "Epoch: 3/20... Training loss: 0.1300\n",
      "Epoch: 3/20... Training loss: 0.1290\n",
      "Epoch: 3/20... Training loss: 0.1249\n",
      "Epoch: 3/20... Training loss: 0.1268\n",
      "Epoch: 3/20... Training loss: 0.1301\n",
      "Epoch: 3/20... Training loss: 0.1315\n",
      "Epoch: 3/20... Training loss: 0.1285\n",
      "Epoch: 3/20... Training loss: 0.1249\n",
      "Epoch: 3/20... Training loss: 0.1317\n",
      "Epoch: 3/20... Training loss: 0.1264\n",
      "Epoch: 3/20... Training loss: 0.1242\n",
      "Epoch: 3/20... Training loss: 0.1281\n",
      "Epoch: 3/20... Training loss: 0.1319\n",
      "Epoch: 3/20... Training loss: 0.1327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/20... Training loss: 0.1269\n",
      "Epoch: 3/20... Training loss: 0.1297\n",
      "Epoch: 3/20... Training loss: 0.1294\n",
      "Epoch: 3/20... Training loss: 0.1382\n",
      "Epoch: 3/20... Training loss: 0.1312\n",
      "Epoch: 3/20... Training loss: 0.1264\n",
      "Epoch: 3/20... Training loss: 0.1417\n",
      "Epoch: 3/20... Training loss: 0.1315\n",
      "Epoch: 3/20... Training loss: 0.1368\n",
      "Epoch: 3/20... Training loss: 0.1325\n",
      "Epoch: 3/20... Training loss: 0.1271\n",
      "Epoch: 3/20... Training loss: 0.1276\n",
      "Epoch: 4/20... Training loss: 0.1259\n",
      "Epoch: 4/20... Training loss: 0.1229\n",
      "Epoch: 4/20... Training loss: 0.1273\n",
      "Epoch: 4/20... Training loss: 0.1282\n",
      "Epoch: 4/20... Training loss: 0.1278\n",
      "Epoch: 4/20... Training loss: 0.1290\n",
      "Epoch: 4/20... Training loss: 0.1267\n",
      "Epoch: 4/20... Training loss: 0.1300\n",
      "Epoch: 4/20... Training loss: 0.1279\n",
      "Epoch: 4/20... Training loss: 0.1264\n",
      "Epoch: 4/20... Training loss: 0.1227\n",
      "Epoch: 4/20... Training loss: 0.1336\n",
      "Epoch: 4/20... Training loss: 0.1291\n",
      "Epoch: 4/20... Training loss: 0.1305\n",
      "Epoch: 4/20... Training loss: 0.1271\n",
      "Epoch: 4/20... Training loss: 0.1346\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1264\n",
      "Epoch: 4/20... Training loss: 0.1379\n",
      "Epoch: 4/20... Training loss: 0.1287\n",
      "Epoch: 4/20... Training loss: 0.1230\n",
      "Epoch: 4/20... Training loss: 0.1297\n",
      "Epoch: 4/20... Training loss: 0.1270\n",
      "Epoch: 4/20... Training loss: 0.1332\n",
      "Epoch: 4/20... Training loss: 0.1301\n",
      "Epoch: 4/20... Training loss: 0.1309\n",
      "Epoch: 4/20... Training loss: 0.1300\n",
      "Epoch: 4/20... Training loss: 0.1241\n",
      "Epoch: 4/20... Training loss: 0.1269\n",
      "Epoch: 4/20... Training loss: 0.1250\n",
      "Epoch: 4/20... Training loss: 0.1284\n",
      "Epoch: 4/20... Training loss: 0.1216\n",
      "Epoch: 4/20... Training loss: 0.1239\n",
      "Epoch: 4/20... Training loss: 0.1232\n",
      "Epoch: 4/20... Training loss: 0.1272\n",
      "Epoch: 4/20... Training loss: 0.1259\n",
      "Epoch: 4/20... Training loss: 0.1323\n",
      "Epoch: 4/20... Training loss: 0.1249\n",
      "Epoch: 4/20... Training loss: 0.1280\n",
      "Epoch: 4/20... Training loss: 0.1291\n",
      "Epoch: 4/20... Training loss: 0.1242\n",
      "Epoch: 4/20... Training loss: 0.1278\n",
      "Epoch: 4/20... Training loss: 0.1229\n",
      "Epoch: 4/20... Training loss: 0.1279\n",
      "Epoch: 4/20... Training loss: 0.1234\n",
      "Epoch: 4/20... Training loss: 0.1277\n",
      "Epoch: 4/20... Training loss: 0.1321\n",
      "Epoch: 4/20... Training loss: 0.1316\n",
      "Epoch: 4/20... Training loss: 0.1322\n",
      "Epoch: 4/20... Training loss: 0.1302\n",
      "Epoch: 4/20... Training loss: 0.1254\n",
      "Epoch: 4/20... Training loss: 0.1272\n",
      "Epoch: 4/20... Training loss: 0.1320\n",
      "Epoch: 4/20... Training loss: 0.1294\n",
      "Epoch: 4/20... Training loss: 0.1247\n",
      "Epoch: 4/20... Training loss: 0.1249\n",
      "Epoch: 4/20... Training loss: 0.1246\n",
      "Epoch: 4/20... Training loss: 0.1225\n",
      "Epoch: 4/20... Training loss: 0.1227\n",
      "Epoch: 4/20... Training loss: 0.1214\n",
      "Epoch: 4/20... Training loss: 0.1242\n",
      "Epoch: 4/20... Training loss: 0.1278\n",
      "Epoch: 4/20... Training loss: 0.1366\n",
      "Epoch: 4/20... Training loss: 0.1334\n",
      "Epoch: 4/20... Training loss: 0.1335\n",
      "Epoch: 4/20... Training loss: 0.1261\n",
      "Epoch: 4/20... Training loss: 0.1317\n",
      "Epoch: 4/20... Training loss: 0.1305\n",
      "Epoch: 4/20... Training loss: 0.1248\n",
      "Epoch: 4/20... Training loss: 0.1313\n",
      "Epoch: 4/20... Training loss: 0.1301\n",
      "Epoch: 4/20... Training loss: 0.1270\n",
      "Epoch: 4/20... Training loss: 0.1304\n",
      "Epoch: 4/20... Training loss: 0.1292\n",
      "Epoch: 4/20... Training loss: 0.1225\n",
      "Epoch: 4/20... Training loss: 0.1283\n",
      "Epoch: 4/20... Training loss: 0.1293\n",
      "Epoch: 4/20... Training loss: 0.1275\n",
      "Epoch: 4/20... Training loss: 0.1356\n",
      "Epoch: 4/20... Training loss: 0.1227\n",
      "Epoch: 4/20... Training loss: 0.1251\n",
      "Epoch: 4/20... Training loss: 0.1221\n",
      "Epoch: 4/20... Training loss: 0.1257\n",
      "Epoch: 4/20... Training loss: 0.1293\n",
      "Epoch: 4/20... Training loss: 0.1288\n",
      "Epoch: 4/20... Training loss: 0.1293\n",
      "Epoch: 4/20... Training loss: 0.1348\n",
      "Epoch: 4/20... Training loss: 0.1340\n",
      "Epoch: 4/20... Training loss: 0.1278\n",
      "Epoch: 4/20... Training loss: 0.1186\n",
      "Epoch: 4/20... Training loss: 0.1171\n",
      "Epoch: 4/20... Training loss: 0.1195\n",
      "Epoch: 4/20... Training loss: 0.1254\n",
      "Epoch: 4/20... Training loss: 0.1332\n",
      "Epoch: 4/20... Training loss: 0.1249\n",
      "Epoch: 4/20... Training loss: 0.1227\n",
      "Epoch: 4/20... Training loss: 0.1358\n",
      "Epoch: 4/20... Training loss: 0.1226\n",
      "Epoch: 4/20... Training loss: 0.1247\n",
      "Epoch: 4/20... Training loss: 0.1325\n",
      "Epoch: 4/20... Training loss: 0.1277\n",
      "Epoch: 4/20... Training loss: 0.1247\n",
      "Epoch: 4/20... Training loss: 0.1235\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1265\n",
      "Epoch: 4/20... Training loss: 0.1253\n",
      "Epoch: 4/20... Training loss: 0.1302\n",
      "Epoch: 4/20... Training loss: 0.1274\n",
      "Epoch: 4/20... Training loss: 0.1255\n",
      "Epoch: 4/20... Training loss: 0.1259\n",
      "Epoch: 4/20... Training loss: 0.1396\n",
      "Epoch: 4/20... Training loss: 0.1290\n",
      "Epoch: 4/20... Training loss: 0.1251\n",
      "Epoch: 4/20... Training loss: 0.1259\n",
      "Epoch: 4/20... Training loss: 0.1274\n",
      "Epoch: 4/20... Training loss: 0.1268\n",
      "Epoch: 4/20... Training loss: 0.1211\n",
      "Epoch: 4/20... Training loss: 0.1244\n",
      "Epoch: 4/20... Training loss: 0.1322\n",
      "Epoch: 4/20... Training loss: 0.1322\n",
      "Epoch: 4/20... Training loss: 0.1160\n",
      "Epoch: 4/20... Training loss: 0.1216\n",
      "Epoch: 4/20... Training loss: 0.1318\n",
      "Epoch: 4/20... Training loss: 0.1217\n",
      "Epoch: 4/20... Training loss: 0.1159\n",
      "Epoch: 4/20... Training loss: 0.1287\n",
      "Epoch: 4/20... Training loss: 0.1298\n",
      "Epoch: 4/20... Training loss: 0.1206\n",
      "Epoch: 4/20... Training loss: 0.1236\n",
      "Epoch: 4/20... Training loss: 0.1227\n",
      "Epoch: 4/20... Training loss: 0.1213\n",
      "Epoch: 4/20... Training loss: 0.1225\n",
      "Epoch: 4/20... Training loss: 0.1255\n",
      "Epoch: 4/20... Training loss: 0.1275\n",
      "Epoch: 4/20... Training loss: 0.1207\n",
      "Epoch: 4/20... Training loss: 0.1337\n",
      "Epoch: 4/20... Training loss: 0.1313\n",
      "Epoch: 4/20... Training loss: 0.1261\n",
      "Epoch: 4/20... Training loss: 0.1273\n",
      "Epoch: 4/20... Training loss: 0.1250\n",
      "Epoch: 4/20... Training loss: 0.1209\n",
      "Epoch: 4/20... Training loss: 0.1259\n",
      "Epoch: 4/20... Training loss: 0.1202\n",
      "Epoch: 4/20... Training loss: 0.1250\n",
      "Epoch: 4/20... Training loss: 0.1318\n",
      "Epoch: 4/20... Training loss: 0.1386\n",
      "Epoch: 4/20... Training loss: 0.1252\n",
      "Epoch: 4/20... Training loss: 0.1193\n",
      "Epoch: 4/20... Training loss: 0.1252\n",
      "Epoch: 4/20... Training loss: 0.1204\n",
      "Epoch: 4/20... Training loss: 0.1264\n",
      "Epoch: 4/20... Training loss: 0.1292\n",
      "Epoch: 4/20... Training loss: 0.1283\n",
      "Epoch: 4/20... Training loss: 0.1280\n",
      "Epoch: 4/20... Training loss: 0.1252\n",
      "Epoch: 4/20... Training loss: 0.1256\n",
      "Epoch: 4/20... Training loss: 0.1234\n",
      "Epoch: 4/20... Training loss: 0.1270\n",
      "Epoch: 4/20... Training loss: 0.1304\n",
      "Epoch: 4/20... Training loss: 0.1252\n",
      "Epoch: 4/20... Training loss: 0.1279\n",
      "Epoch: 4/20... Training loss: 0.1233\n",
      "Epoch: 4/20... Training loss: 0.1236\n",
      "Epoch: 4/20... Training loss: 0.1317\n",
      "Epoch: 4/20... Training loss: 0.1259\n",
      "Epoch: 4/20... Training loss: 0.1237\n",
      "Epoch: 4/20... Training loss: 0.1283\n",
      "Epoch: 4/20... Training loss: 0.1243\n",
      "Epoch: 4/20... Training loss: 0.1174\n",
      "Epoch: 4/20... Training loss: 0.1183\n",
      "Epoch: 4/20... Training loss: 0.1261\n",
      "Epoch: 4/20... Training loss: 0.1255\n",
      "Epoch: 4/20... Training loss: 0.1263\n",
      "Epoch: 4/20... Training loss: 0.1271\n",
      "Epoch: 4/20... Training loss: 0.1245\n",
      "Epoch: 4/20... Training loss: 0.1290\n",
      "Epoch: 4/20... Training loss: 0.1221\n",
      "Epoch: 4/20... Training loss: 0.1299\n",
      "Epoch: 4/20... Training loss: 0.1285\n",
      "Epoch: 4/20... Training loss: 0.1284\n",
      "Epoch: 4/20... Training loss: 0.1289\n",
      "Epoch: 4/20... Training loss: 0.1300\n",
      "Epoch: 4/20... Training loss: 0.1300\n",
      "Epoch: 4/20... Training loss: 0.1289\n",
      "Epoch: 4/20... Training loss: 0.1251\n",
      "Epoch: 4/20... Training loss: 0.1204\n",
      "Epoch: 4/20... Training loss: 0.1272\n",
      "Epoch: 4/20... Training loss: 0.1311\n",
      "Epoch: 4/20... Training loss: 0.1300\n",
      "Epoch: 4/20... Training loss: 0.1257\n",
      "Epoch: 4/20... Training loss: 0.1262\n",
      "Epoch: 4/20... Training loss: 0.1266\n",
      "Epoch: 4/20... Training loss: 0.1209\n",
      "Epoch: 4/20... Training loss: 0.1305\n",
      "Epoch: 4/20... Training loss: 0.1237\n",
      "Epoch: 4/20... Training loss: 0.1195\n",
      "Epoch: 4/20... Training loss: 0.1229\n",
      "Epoch: 4/20... Training loss: 0.1142\n",
      "Epoch: 4/20... Training loss: 0.1237\n",
      "Epoch: 4/20... Training loss: 0.1277\n",
      "Epoch: 4/20... Training loss: 0.1240\n",
      "Epoch: 4/20... Training loss: 0.1226\n",
      "Epoch: 4/20... Training loss: 0.1270\n",
      "Epoch: 4/20... Training loss: 0.1235\n",
      "Epoch: 4/20... Training loss: 0.1241\n",
      "Epoch: 4/20... Training loss: 0.1264\n",
      "Epoch: 4/20... Training loss: 0.1326\n",
      "Epoch: 4/20... Training loss: 0.1257\n",
      "Epoch: 4/20... Training loss: 0.1220\n",
      "Epoch: 4/20... Training loss: 0.1204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/20... Training loss: 0.1172\n",
      "Epoch: 4/20... Training loss: 0.1242\n",
      "Epoch: 4/20... Training loss: 0.1269\n",
      "Epoch: 4/20... Training loss: 0.1274\n",
      "Epoch: 4/20... Training loss: 0.1286\n",
      "Epoch: 4/20... Training loss: 0.1177\n",
      "Epoch: 4/20... Training loss: 0.1237\n",
      "Epoch: 4/20... Training loss: 0.1257\n",
      "Epoch: 4/20... Training loss: 0.1225\n",
      "Epoch: 4/20... Training loss: 0.1234\n",
      "Epoch: 4/20... Training loss: 0.1324\n",
      "Epoch: 4/20... Training loss: 0.1282\n",
      "Epoch: 4/20... Training loss: 0.1245\n",
      "Epoch: 4/20... Training loss: 0.1279\n",
      "Epoch: 4/20... Training loss: 0.1245\n",
      "Epoch: 4/20... Training loss: 0.1235\n",
      "Epoch: 4/20... Training loss: 0.1288\n",
      "Epoch: 4/20... Training loss: 0.1290\n",
      "Epoch: 4/20... Training loss: 0.1283\n",
      "Epoch: 4/20... Training loss: 0.1284\n",
      "Epoch: 4/20... Training loss: 0.1265\n",
      "Epoch: 4/20... Training loss: 0.1292\n",
      "Epoch: 4/20... Training loss: 0.1266\n",
      "Epoch: 4/20... Training loss: 0.1275\n",
      "Epoch: 4/20... Training loss: 0.1280\n",
      "Epoch: 4/20... Training loss: 0.1233\n",
      "Epoch: 4/20... Training loss: 0.1231\n",
      "Epoch: 4/20... Training loss: 0.1298\n",
      "Epoch: 4/20... Training loss: 0.1299\n",
      "Epoch: 4/20... Training loss: 0.1208\n",
      "Epoch: 4/20... Training loss: 0.1220\n",
      "Epoch: 4/20... Training loss: 0.1257\n",
      "Epoch: 4/20... Training loss: 0.1253\n",
      "Epoch: 4/20... Training loss: 0.1297\n",
      "Epoch: 4/20... Training loss: 0.1228\n",
      "Epoch: 4/20... Training loss: 0.1335\n",
      "Epoch: 4/20... Training loss: 0.1246\n",
      "Epoch: 4/20... Training loss: 0.1328\n",
      "Epoch: 4/20... Training loss: 0.1303\n",
      "Epoch: 4/20... Training loss: 0.1270\n",
      "Epoch: 4/20... Training loss: 0.1222\n",
      "Epoch: 4/20... Training loss: 0.1272\n",
      "Epoch: 4/20... Training loss: 0.1258\n",
      "Epoch: 4/20... Training loss: 0.1229\n",
      "Epoch: 4/20... Training loss: 0.1189\n",
      "Epoch: 4/20... Training loss: 0.1218\n",
      "Epoch: 4/20... Training loss: 0.1235\n",
      "Epoch: 4/20... Training loss: 0.1266\n",
      "Epoch: 4/20... Training loss: 0.1271\n",
      "Epoch: 4/20... Training loss: 0.1268\n",
      "Epoch: 4/20... Training loss: 0.1252\n",
      "Epoch: 4/20... Training loss: 0.1177\n",
      "Epoch: 4/20... Training loss: 0.1252\n",
      "Epoch: 4/20... Training loss: 0.1191\n",
      "Epoch: 4/20... Training loss: 0.1257\n",
      "Epoch: 4/20... Training loss: 0.1249\n",
      "Epoch: 4/20... Training loss: 0.1256\n",
      "Epoch: 4/20... Training loss: 0.1211\n",
      "Epoch: 4/20... Training loss: 0.1265\n",
      "Epoch: 4/20... Training loss: 0.1287\n",
      "Epoch: 4/20... Training loss: 0.1291\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1248\n",
      "Epoch: 4/20... Training loss: 0.1179\n",
      "Epoch: 4/20... Training loss: 0.1250\n",
      "Epoch: 4/20... Training loss: 0.1237\n",
      "Epoch: 4/20... Training loss: 0.1199\n",
      "Epoch: 4/20... Training loss: 0.1215\n",
      "Epoch: 4/20... Training loss: 0.1249\n",
      "Epoch: 4/20... Training loss: 0.1262\n",
      "Epoch: 4/20... Training loss: 0.1231\n",
      "Epoch: 4/20... Training loss: 0.1197\n",
      "Epoch: 4/20... Training loss: 0.1265\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1190\n",
      "Epoch: 4/20... Training loss: 0.1230\n",
      "Epoch: 4/20... Training loss: 0.1265\n",
      "Epoch: 4/20... Training loss: 0.1272\n",
      "Epoch: 4/20... Training loss: 0.1217\n",
      "Epoch: 4/20... Training loss: 0.1246\n",
      "Epoch: 4/20... Training loss: 0.1242\n",
      "Epoch: 4/20... Training loss: 0.1320\n",
      "Epoch: 4/20... Training loss: 0.1256\n",
      "Epoch: 4/20... Training loss: 0.1216\n",
      "Epoch: 4/20... Training loss: 0.1360\n",
      "Epoch: 4/20... Training loss: 0.1260\n",
      "Epoch: 4/20... Training loss: 0.1306\n",
      "Epoch: 4/20... Training loss: 0.1272\n",
      "Epoch: 4/20... Training loss: 0.1219\n",
      "Epoch: 4/20... Training loss: 0.1226\n",
      "Epoch: 5/20... Training loss: 0.1217\n",
      "Epoch: 5/20... Training loss: 0.1181\n",
      "Epoch: 5/20... Training loss: 0.1225\n",
      "Epoch: 5/20... Training loss: 0.1232\n",
      "Epoch: 5/20... Training loss: 0.1225\n",
      "Epoch: 5/20... Training loss: 0.1240\n",
      "Epoch: 5/20... Training loss: 0.1213\n",
      "Epoch: 5/20... Training loss: 0.1250\n",
      "Epoch: 5/20... Training loss: 0.1221\n",
      "Epoch: 5/20... Training loss: 0.1206\n",
      "Epoch: 5/20... Training loss: 0.1175\n",
      "Epoch: 5/20... Training loss: 0.1272\n",
      "Epoch: 5/20... Training loss: 0.1239\n",
      "Epoch: 5/20... Training loss: 0.1248\n",
      "Epoch: 5/20... Training loss: 0.1215\n",
      "Epoch: 5/20... Training loss: 0.1281\n",
      "Epoch: 5/20... Training loss: 0.1164\n",
      "Epoch: 5/20... Training loss: 0.1212\n",
      "Epoch: 5/20... Training loss: 0.1323\n",
      "Epoch: 5/20... Training loss: 0.1236\n",
      "Epoch: 5/20... Training loss: 0.1182\n",
      "Epoch: 5/20... Training loss: 0.1242\n",
      "Epoch: 5/20... Training loss: 0.1223\n",
      "Epoch: 5/20... Training loss: 0.1279\n",
      "Epoch: 5/20... Training loss: 0.1249\n",
      "Epoch: 5/20... Training loss: 0.1250\n",
      "Epoch: 5/20... Training loss: 0.1247\n",
      "Epoch: 5/20... Training loss: 0.1195\n",
      "Epoch: 5/20... Training loss: 0.1221\n",
      "Epoch: 5/20... Training loss: 0.1202\n",
      "Epoch: 5/20... Training loss: 0.1228\n",
      "Epoch: 5/20... Training loss: 0.1168\n",
      "Epoch: 5/20... Training loss: 0.1189\n",
      "Epoch: 5/20... Training loss: 0.1179\n",
      "Epoch: 5/20... Training loss: 0.1221\n",
      "Epoch: 5/20... Training loss: 0.1210\n",
      "Epoch: 5/20... Training loss: 0.1272\n",
      "Epoch: 5/20... Training loss: 0.1189\n",
      "Epoch: 5/20... Training loss: 0.1231\n",
      "Epoch: 5/20... Training loss: 0.1241\n",
      "Epoch: 5/20... Training loss: 0.1196\n",
      "Epoch: 5/20... Training loss: 0.1227\n",
      "Epoch: 5/20... Training loss: 0.1181\n",
      "Epoch: 5/20... Training loss: 0.1237\n",
      "Epoch: 5/20... Training loss: 0.1180\n",
      "Epoch: 5/20... Training loss: 0.1234\n",
      "Epoch: 5/20... Training loss: 0.1260\n",
      "Epoch: 5/20... Training loss: 0.1268\n",
      "Epoch: 5/20... Training loss: 0.1268\n",
      "Epoch: 5/20... Training loss: 0.1258\n",
      "Epoch: 5/20... Training loss: 0.1202\n",
      "Epoch: 5/20... Training loss: 0.1214\n",
      "Epoch: 5/20... Training loss: 0.1245\n",
      "Epoch: 5/20... Training loss: 0.1251\n",
      "Epoch: 5/20... Training loss: 0.1175\n",
      "Epoch: 5/20... Training loss: 0.1201\n",
      "Epoch: 5/20... Training loss: 0.1170\n",
      "Epoch: 5/20... Training loss: 0.1185\n",
      "Epoch: 5/20... Training loss: 0.1160\n",
      "Epoch: 5/20... Training loss: 0.1180\n",
      "Epoch: 5/20... Training loss: 0.1175\n",
      "Epoch: 5/20... Training loss: 0.1233\n",
      "Epoch: 5/20... Training loss: 0.1290\n",
      "Epoch: 5/20... Training loss: 0.1289\n",
      "Epoch: 5/20... Training loss: 0.1274\n",
      "Epoch: 5/20... Training loss: 0.1217\n",
      "Epoch: 5/20... Training loss: 0.1260\n",
      "Epoch: 5/20... Training loss: 0.1251\n",
      "Epoch: 5/20... Training loss: 0.1199\n",
      "Epoch: 5/20... Training loss: 0.1261\n",
      "Epoch: 5/20... Training loss: 0.1239\n",
      "Epoch: 5/20... Training loss: 0.1229\n",
      "Epoch: 5/20... Training loss: 0.1246\n",
      "Epoch: 5/20... Training loss: 0.1261\n",
      "Epoch: 5/20... Training loss: 0.1177\n",
      "Epoch: 5/20... Training loss: 0.1249\n",
      "Epoch: 5/20... Training loss: 0.1238\n",
      "Epoch: 5/20... Training loss: 0.1242\n",
      "Epoch: 5/20... Training loss: 0.1309\n",
      "Epoch: 5/20... Training loss: 0.1183\n",
      "Epoch: 5/20... Training loss: 0.1198\n",
      "Epoch: 5/20... Training loss: 0.1168\n",
      "Epoch: 5/20... Training loss: 0.1204\n",
      "Epoch: 5/20... Training loss: 0.1243\n",
      "Epoch: 5/20... Training loss: 0.1239\n",
      "Epoch: 5/20... Training loss: 0.1239\n",
      "Epoch: 5/20... Training loss: 0.1302\n",
      "Epoch: 5/20... Training loss: 0.1285\n",
      "Epoch: 5/20... Training loss: 0.1230\n",
      "Epoch: 5/20... Training loss: 0.1140\n",
      "Epoch: 5/20... Training loss: 0.1125\n",
      "Epoch: 5/20... Training loss: 0.1149\n",
      "Epoch: 5/20... Training loss: 0.1216\n",
      "Epoch: 5/20... Training loss: 0.1286\n",
      "Epoch: 5/20... Training loss: 0.1196\n",
      "Epoch: 5/20... Training loss: 0.1174\n",
      "Epoch: 5/20... Training loss: 0.1307\n",
      "Epoch: 5/20... Training loss: 0.1184\n",
      "Epoch: 5/20... Training loss: 0.1200\n",
      "Epoch: 5/20... Training loss: 0.1276\n",
      "Epoch: 5/20... Training loss: 0.1235\n",
      "Epoch: 5/20... Training loss: 0.1200\n",
      "Epoch: 5/20... Training loss: 0.1183\n",
      "Epoch: 5/20... Training loss: 0.1169\n",
      "Epoch: 5/20... Training loss: 0.1225\n",
      "Epoch: 5/20... Training loss: 0.1200\n",
      "Epoch: 5/20... Training loss: 0.1251\n",
      "Epoch: 5/20... Training loss: 0.1227\n",
      "Epoch: 5/20... Training loss: 0.1207\n",
      "Epoch: 5/20... Training loss: 0.1217\n",
      "Epoch: 5/20... Training loss: 0.1347\n",
      "Epoch: 5/20... Training loss: 0.1244\n",
      "Epoch: 5/20... Training loss: 0.1207\n",
      "Epoch: 5/20... Training loss: 0.1219\n",
      "Epoch: 5/20... Training loss: 0.1232\n",
      "Epoch: 5/20... Training loss: 0.1218\n",
      "Epoch: 5/20... Training loss: 0.1168\n",
      "Epoch: 5/20... Training loss: 0.1195\n",
      "Epoch: 5/20... Training loss: 0.1273\n",
      "Epoch: 5/20... Training loss: 0.1265\n",
      "Epoch: 5/20... Training loss: 0.1114\n",
      "Epoch: 5/20... Training loss: 0.1166\n",
      "Epoch: 5/20... Training loss: 0.1264\n",
      "Epoch: 5/20... Training loss: 0.1157\n",
      "Epoch: 5/20... Training loss: 0.1118\n",
      "Epoch: 5/20... Training loss: 0.1229\n",
      "Epoch: 5/20... Training loss: 0.1247\n",
      "Epoch: 5/20... Training loss: 0.1155\n",
      "Epoch: 5/20... Training loss: 0.1185\n",
      "Epoch: 5/20... Training loss: 0.1186\n",
      "Epoch: 5/20... Training loss: 0.1171\n",
      "Epoch: 5/20... Training loss: 0.1187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/20... Training loss: 0.1205\n",
      "Epoch: 5/20... Training loss: 0.1242\n",
      "Epoch: 5/20... Training loss: 0.1163\n",
      "Epoch: 5/20... Training loss: 0.1299\n",
      "Epoch: 5/20... Training loss: 0.1279\n",
      "Epoch: 5/20... Training loss: 0.1216\n",
      "Epoch: 5/20... Training loss: 0.1231\n",
      "Epoch: 5/20... Training loss: 0.1207\n",
      "Epoch: 5/20... Training loss: 0.1175\n",
      "Epoch: 5/20... Training loss: 0.1214\n",
      "Epoch: 5/20... Training loss: 0.1165\n",
      "Epoch: 5/20... Training loss: 0.1207\n",
      "Epoch: 5/20... Training loss: 0.1272\n",
      "Epoch: 5/20... Training loss: 0.1334\n",
      "Epoch: 5/20... Training loss: 0.1214\n",
      "Epoch: 5/20... Training loss: 0.1151\n",
      "Epoch: 5/20... Training loss: 0.1213\n",
      "Epoch: 5/20... Training loss: 0.1159\n",
      "Epoch: 5/20... Training loss: 0.1221\n",
      "Epoch: 5/20... Training loss: 0.1239\n",
      "Epoch: 5/20... Training loss: 0.1238\n",
      "Epoch: 5/20... Training loss: 0.1236\n",
      "Epoch: 5/20... Training loss: 0.1215\n",
      "Epoch: 5/20... Training loss: 0.1209\n",
      "Epoch: 5/20... Training loss: 0.1185\n",
      "Epoch: 5/20... Training loss: 0.1221\n",
      "Epoch: 5/20... Training loss: 0.1257\n",
      "Epoch: 5/20... Training loss: 0.1203\n",
      "Epoch: 5/20... Training loss: 0.1235\n",
      "Epoch: 5/20... Training loss: 0.1191\n",
      "Epoch: 5/20... Training loss: 0.1184\n",
      "Epoch: 5/20... Training loss: 0.1268\n",
      "Epoch: 5/20... Training loss: 0.1218\n",
      "Epoch: 5/20... Training loss: 0.1185\n",
      "Epoch: 5/20... Training loss: 0.1241\n",
      "Epoch: 5/20... Training loss: 0.1199\n",
      "Epoch: 5/20... Training loss: 0.1144\n",
      "Epoch: 5/20... Training loss: 0.1142\n",
      "Epoch: 5/20... Training loss: 0.1224\n",
      "Epoch: 5/20... Training loss: 0.1206\n",
      "Epoch: 5/20... Training loss: 0.1222\n",
      "Epoch: 5/20... Training loss: 0.1228\n",
      "Epoch: 5/20... Training loss: 0.1205\n",
      "Epoch: 5/20... Training loss: 0.1246\n",
      "Epoch: 5/20... Training loss: 0.1182\n",
      "Epoch: 5/20... Training loss: 0.1249\n",
      "Epoch: 5/20... Training loss: 0.1238\n",
      "Epoch: 5/20... Training loss: 0.1237\n",
      "Epoch: 5/20... Training loss: 0.1243\n",
      "Epoch: 5/20... Training loss: 0.1257\n",
      "Epoch: 5/20... Training loss: 0.1254\n",
      "Epoch: 5/20... Training loss: 0.1244\n",
      "Epoch: 5/20... Training loss: 0.1204\n",
      "Epoch: 5/20... Training loss: 0.1167\n",
      "Epoch: 5/20... Training loss: 0.1230\n",
      "Epoch: 5/20... Training loss: 0.1269\n",
      "Epoch: 5/20... Training loss: 0.1258\n",
      "Epoch: 5/20... Training loss: 0.1216\n",
      "Epoch: 5/20... Training loss: 0.1215\n",
      "Epoch: 5/20... Training loss: 0.1229\n",
      "Epoch: 5/20... Training loss: 0.1170\n",
      "Epoch: 5/20... Training loss: 0.1262\n",
      "Epoch: 5/20... Training loss: 0.1193\n",
      "Epoch: 5/20... Training loss: 0.1159\n",
      "Epoch: 5/20... Training loss: 0.1188\n",
      "Epoch: 5/20... Training loss: 0.1107\n",
      "Epoch: 5/20... Training loss: 0.1195\n",
      "Epoch: 5/20... Training loss: 0.1240\n",
      "Epoch: 5/20... Training loss: 0.1195\n",
      "Epoch: 5/20... Training loss: 0.1184\n",
      "Epoch: 5/20... Training loss: 0.1223\n",
      "Epoch: 5/20... Training loss: 0.1196\n",
      "Epoch: 5/20... Training loss: 0.1196\n",
      "Epoch: 5/20... Training loss: 0.1221\n",
      "Epoch: 5/20... Training loss: 0.1285\n",
      "Epoch: 5/20... Training loss: 0.1220\n",
      "Epoch: 5/20... Training loss: 0.1179\n",
      "Epoch: 5/20... Training loss: 0.1164\n",
      "Epoch: 5/20... Training loss: 0.1133\n",
      "Epoch: 5/20... Training loss: 0.1200\n",
      "Epoch: 5/20... Training loss: 0.1222\n",
      "Epoch: 5/20... Training loss: 0.1230\n",
      "Epoch: 5/20... Training loss: 0.1242\n",
      "Epoch: 5/20... Training loss: 0.1139\n",
      "Epoch: 5/20... Training loss: 0.1194\n",
      "Epoch: 5/20... Training loss: 0.1214\n",
      "Epoch: 5/20... Training loss: 0.1180\n",
      "Epoch: 5/20... Training loss: 0.1192\n",
      "Epoch: 5/20... Training loss: 0.1282\n",
      "Epoch: 5/20... Training loss: 0.1237\n",
      "Epoch: 5/20... Training loss: 0.1203\n",
      "Epoch: 5/20... Training loss: 0.1238\n",
      "Epoch: 5/20... Training loss: 0.1207\n",
      "Epoch: 5/20... Training loss: 0.1197\n",
      "Epoch: 5/20... Training loss: 0.1240\n",
      "Epoch: 5/20... Training loss: 0.1247\n",
      "Epoch: 5/20... Training loss: 0.1246\n",
      "Epoch: 5/20... Training loss: 0.1241\n",
      "Epoch: 5/20... Training loss: 0.1225\n",
      "Epoch: 5/20... Training loss: 0.1247\n",
      "Epoch: 5/20... Training loss: 0.1227\n",
      "Epoch: 5/20... Training loss: 0.1232\n",
      "Epoch: 5/20... Training loss: 0.1237\n",
      "Epoch: 5/20... Training loss: 0.1190\n",
      "Epoch: 5/20... Training loss: 0.1195\n",
      "Epoch: 5/20... Training loss: 0.1261\n",
      "Epoch: 5/20... Training loss: 0.1261\n",
      "Epoch: 5/20... Training loss: 0.1173\n",
      "Epoch: 5/20... Training loss: 0.1183\n",
      "Epoch: 5/20... Training loss: 0.1216\n",
      "Epoch: 5/20... Training loss: 0.1209\n",
      "Epoch: 5/20... Training loss: 0.1255\n",
      "Epoch: 5/20... Training loss: 0.1193\n",
      "Epoch: 5/20... Training loss: 0.1293\n",
      "Epoch: 5/20... Training loss: 0.1203\n",
      "Epoch: 5/20... Training loss: 0.1287\n",
      "Epoch: 5/20... Training loss: 0.1258\n",
      "Epoch: 5/20... Training loss: 0.1235\n",
      "Epoch: 5/20... Training loss: 0.1180\n",
      "Epoch: 5/20... Training loss: 0.1231\n",
      "Epoch: 5/20... Training loss: 0.1217\n",
      "Epoch: 5/20... Training loss: 0.1189\n",
      "Epoch: 5/20... Training loss: 0.1149\n",
      "Epoch: 5/20... Training loss: 0.1174\n",
      "Epoch: 5/20... Training loss: 0.1195\n",
      "Epoch: 5/20... Training loss: 0.1223\n",
      "Epoch: 5/20... Training loss: 0.1234\n",
      "Epoch: 5/20... Training loss: 0.1229\n",
      "Epoch: 5/20... Training loss: 0.1221\n",
      "Epoch: 5/20... Training loss: 0.1143\n",
      "Epoch: 5/20... Training loss: 0.1208\n",
      "Epoch: 5/20... Training loss: 0.1148\n",
      "Epoch: 5/20... Training loss: 0.1220\n",
      "Epoch: 5/20... Training loss: 0.1204\n",
      "Epoch: 5/20... Training loss: 0.1212\n",
      "Epoch: 5/20... Training loss: 0.1173\n",
      "Epoch: 5/20... Training loss: 0.1223\n",
      "Epoch: 5/20... Training loss: 0.1243\n",
      "Epoch: 5/20... Training loss: 0.1249\n",
      "Epoch: 5/20... Training loss: 0.1174\n",
      "Epoch: 5/20... Training loss: 0.1208\n",
      "Epoch: 5/20... Training loss: 0.1139\n",
      "Epoch: 5/20... Training loss: 0.1213\n",
      "Epoch: 5/20... Training loss: 0.1200\n",
      "Epoch: 5/20... Training loss: 0.1161\n",
      "Epoch: 5/20... Training loss: 0.1178\n",
      "Epoch: 5/20... Training loss: 0.1209\n",
      "Epoch: 5/20... Training loss: 0.1216\n",
      "Epoch: 5/20... Training loss: 0.1191\n",
      "Epoch: 5/20... Training loss: 0.1163\n",
      "Epoch: 5/20... Training loss: 0.1231\n",
      "Epoch: 5/20... Training loss: 0.1177\n",
      "Epoch: 5/20... Training loss: 0.1156\n",
      "Epoch: 5/20... Training loss: 0.1193\n",
      "Epoch: 5/20... Training loss: 0.1230\n",
      "Epoch: 5/20... Training loss: 0.1231\n",
      "Epoch: 5/20... Training loss: 0.1181\n",
      "Epoch: 5/20... Training loss: 0.1209\n",
      "Epoch: 5/20... Training loss: 0.1204\n",
      "Epoch: 5/20... Training loss: 0.1275\n",
      "Epoch: 5/20... Training loss: 0.1215\n",
      "Epoch: 5/20... Training loss: 0.1181\n",
      "Epoch: 5/20... Training loss: 0.1317\n",
      "Epoch: 5/20... Training loss: 0.1217\n",
      "Epoch: 5/20... Training loss: 0.1266\n",
      "Epoch: 5/20... Training loss: 0.1232\n",
      "Epoch: 5/20... Training loss: 0.1181\n",
      "Epoch: 5/20... Training loss: 0.1193\n",
      "Epoch: 6/20... Training loss: 0.1182\n",
      "Epoch: 6/20... Training loss: 0.1145\n",
      "Epoch: 6/20... Training loss: 0.1189\n",
      "Epoch: 6/20... Training loss: 0.1195\n",
      "Epoch: 6/20... Training loss: 0.1186\n",
      "Epoch: 6/20... Training loss: 0.1205\n",
      "Epoch: 6/20... Training loss: 0.1173\n",
      "Epoch: 6/20... Training loss: 0.1213\n",
      "Epoch: 6/20... Training loss: 0.1180\n",
      "Epoch: 6/20... Training loss: 0.1166\n",
      "Epoch: 6/20... Training loss: 0.1138\n",
      "Epoch: 6/20... Training loss: 0.1229\n",
      "Epoch: 6/20... Training loss: 0.1200\n",
      "Epoch: 6/20... Training loss: 0.1210\n",
      "Epoch: 6/20... Training loss: 0.1175\n",
      "Epoch: 6/20... Training loss: 0.1237\n",
      "Epoch: 6/20... Training loss: 0.1129\n",
      "Epoch: 6/20... Training loss: 0.1172\n",
      "Epoch: 6/20... Training loss: 0.1284\n",
      "Epoch: 6/20... Training loss: 0.1200\n",
      "Epoch: 6/20... Training loss: 0.1145\n",
      "Epoch: 6/20... Training loss: 0.1203\n",
      "Epoch: 6/20... Training loss: 0.1184\n",
      "Epoch: 6/20... Training loss: 0.1242\n",
      "Epoch: 6/20... Training loss: 0.1214\n",
      "Epoch: 6/20... Training loss: 0.1209\n",
      "Epoch: 6/20... Training loss: 0.1210\n",
      "Epoch: 6/20... Training loss: 0.1162\n",
      "Epoch: 6/20... Training loss: 0.1189\n",
      "Epoch: 6/20... Training loss: 0.1163\n",
      "Epoch: 6/20... Training loss: 0.1189\n",
      "Epoch: 6/20... Training loss: 0.1131\n",
      "Epoch: 6/20... Training loss: 0.1153\n",
      "Epoch: 6/20... Training loss: 0.1146\n",
      "Epoch: 6/20... Training loss: 0.1184\n",
      "Epoch: 6/20... Training loss: 0.1177\n",
      "Epoch: 6/20... Training loss: 0.1235\n",
      "Epoch: 6/20... Training loss: 0.1151\n",
      "Epoch: 6/20... Training loss: 0.1195\n",
      "Epoch: 6/20... Training loss: 0.1199\n",
      "Epoch: 6/20... Training loss: 0.1163\n",
      "Epoch: 6/20... Training loss: 0.1189\n",
      "Epoch: 6/20... Training loss: 0.1148\n",
      "Epoch: 6/20... Training loss: 0.1201\n",
      "Epoch: 6/20... Training loss: 0.1139\n",
      "Epoch: 6/20... Training loss: 0.1203\n",
      "Epoch: 6/20... Training loss: 0.1216\n",
      "Epoch: 6/20... Training loss: 0.1231\n",
      "Epoch: 6/20... Training loss: 0.1229\n",
      "Epoch: 6/20... Training loss: 0.1222\n",
      "Epoch: 6/20... Training loss: 0.1168\n",
      "Epoch: 6/20... Training loss: 0.1172\n",
      "Epoch: 6/20... Training loss: 0.1202\n",
      "Epoch: 6/20... Training loss: 0.1214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/20... Training loss: 0.1133\n",
      "Epoch: 6/20... Training loss: 0.1164\n",
      "Epoch: 6/20... Training loss: 0.1125\n",
      "Epoch: 6/20... Training loss: 0.1155\n",
      "Epoch: 6/20... Training loss: 0.1120\n",
      "Epoch: 6/20... Training loss: 0.1146\n",
      "Epoch: 6/20... Training loss: 0.1130\n",
      "Epoch: 6/20... Training loss: 0.1198\n",
      "Epoch: 6/20... Training loss: 0.1246\n",
      "Epoch: 6/20... Training loss: 0.1253\n",
      "Epoch: 6/20... Training loss: 0.1236\n",
      "Epoch: 6/20... Training loss: 0.1182\n",
      "Epoch: 6/20... Training loss: 0.1227\n",
      "Epoch: 6/20... Training loss: 0.1214\n",
      "Epoch: 6/20... Training loss: 0.1167\n",
      "Epoch: 6/20... Training loss: 0.1226\n",
      "Epoch: 6/20... Training loss: 0.1197\n",
      "Epoch: 6/20... Training loss: 0.1186\n",
      "Epoch: 6/20... Training loss: 0.1206\n",
      "Epoch: 6/20... Training loss: 0.1214\n",
      "Epoch: 6/20... Training loss: 0.1145\n",
      "Epoch: 6/20... Training loss: 0.1203\n",
      "Epoch: 6/20... Training loss: 0.1205\n",
      "Epoch: 6/20... Training loss: 0.1203\n",
      "Epoch: 6/20... Training loss: 0.1273\n",
      "Epoch: 6/20... Training loss: 0.1153\n",
      "Epoch: 6/20... Training loss: 0.1163\n",
      "Epoch: 6/20... Training loss: 0.1134\n",
      "Epoch: 6/20... Training loss: 0.1169\n",
      "Epoch: 6/20... Training loss: 0.1209\n",
      "Epoch: 6/20... Training loss: 0.1203\n",
      "Epoch: 6/20... Training loss: 0.1205\n",
      "Epoch: 6/20... Training loss: 0.1267\n",
      "Epoch: 6/20... Training loss: 0.1248\n",
      "Epoch: 6/20... Training loss: 0.1198\n",
      "Epoch: 6/20... Training loss: 0.1112\n",
      "Epoch: 6/20... Training loss: 0.1092\n",
      "Epoch: 6/20... Training loss: 0.1117\n",
      "Epoch: 6/20... Training loss: 0.1186\n",
      "Epoch: 6/20... Training loss: 0.1251\n",
      "Epoch: 6/20... Training loss: 0.1158\n",
      "Epoch: 6/20... Training loss: 0.1138\n",
      "Epoch: 6/20... Training loss: 0.1269\n",
      "Epoch: 6/20... Training loss: 0.1149\n",
      "Epoch: 6/20... Training loss: 0.1161\n",
      "Epoch: 6/20... Training loss: 0.1238\n",
      "Epoch: 6/20... Training loss: 0.1203\n",
      "Epoch: 6/20... Training loss: 0.1167\n",
      "Epoch: 6/20... Training loss: 0.1145\n",
      "Epoch: 6/20... Training loss: 0.1137\n",
      "Epoch: 6/20... Training loss: 0.1196\n",
      "Epoch: 6/20... Training loss: 0.1165\n",
      "Epoch: 6/20... Training loss: 0.1213\n",
      "Epoch: 6/20... Training loss: 0.1195\n",
      "Epoch: 6/20... Training loss: 0.1171\n",
      "Epoch: 6/20... Training loss: 0.1182\n",
      "Epoch: 6/20... Training loss: 0.1311\n",
      "Epoch: 6/20... Training loss: 0.1211\n",
      "Epoch: 6/20... Training loss: 0.1173\n",
      "Epoch: 6/20... Training loss: 0.1191\n",
      "Epoch: 6/20... Training loss: 0.1198\n",
      "Epoch: 6/20... Training loss: 0.1180\n",
      "Epoch: 6/20... Training loss: 0.1135\n",
      "Epoch: 6/20... Training loss: 0.1165\n",
      "Epoch: 6/20... Training loss: 0.1239\n",
      "Epoch: 6/20... Training loss: 0.1230\n",
      "Epoch: 6/20... Training loss: 0.1084\n",
      "Epoch: 6/20... Training loss: 0.1136\n",
      "Epoch: 6/20... Training loss: 0.1225\n",
      "Epoch: 6/20... Training loss: 0.1124\n",
      "Epoch: 6/20... Training loss: 0.1088\n",
      "Epoch: 6/20... Training loss: 0.1195\n",
      "Epoch: 6/20... Training loss: 0.1211\n",
      "Epoch: 6/20... Training loss: 0.1124\n",
      "Epoch: 6/20... Training loss: 0.1147\n",
      "Epoch: 6/20... Training loss: 0.1154\n",
      "Epoch: 6/20... Training loss: 0.1142\n",
      "Epoch: 6/20... Training loss: 0.1153\n",
      "Epoch: 6/20... Training loss: 0.1171\n",
      "Epoch: 6/20... Training loss: 0.1207\n",
      "Epoch: 6/20... Training loss: 0.1134\n",
      "Epoch: 6/20... Training loss: 0.1266\n",
      "Epoch: 6/20... Training loss: 0.1254\n",
      "Epoch: 6/20... Training loss: 0.1180\n",
      "Epoch: 6/20... Training loss: 0.1198\n",
      "Epoch: 6/20... Training loss: 0.1172\n",
      "Epoch: 6/20... Training loss: 0.1142\n",
      "Epoch: 6/20... Training loss: 0.1181\n",
      "Epoch: 6/20... Training loss: 0.1131\n",
      "Epoch: 6/20... Training loss: 0.1173\n",
      "Epoch: 6/20... Training loss: 0.1236\n",
      "Epoch: 6/20... Training loss: 0.1292\n",
      "Epoch: 6/20... Training loss: 0.1180\n",
      "Epoch: 6/20... Training loss: 0.1117\n",
      "Epoch: 6/20... Training loss: 0.1180\n",
      "Epoch: 6/20... Training loss: 0.1125\n",
      "Epoch: 6/20... Training loss: 0.1191\n",
      "Epoch: 6/20... Training loss: 0.1203\n",
      "Epoch: 6/20... Training loss: 0.1206\n",
      "Epoch: 6/20... Training loss: 0.1199\n",
      "Epoch: 6/20... Training loss: 0.1188\n",
      "Epoch: 6/20... Training loss: 0.1174\n",
      "Epoch: 6/20... Training loss: 0.1152\n",
      "Epoch: 6/20... Training loss: 0.1189\n",
      "Epoch: 6/20... Training loss: 0.1224\n",
      "Epoch: 6/20... Training loss: 0.1168\n",
      "Epoch: 6/20... Training loss: 0.1204\n",
      "Epoch: 6/20... Training loss: 0.1161\n",
      "Epoch: 6/20... Training loss: 0.1149\n",
      "Epoch: 6/20... Training loss: 0.1235\n",
      "Epoch: 6/20... Training loss: 0.1183\n",
      "Epoch: 6/20... Training loss: 0.1150\n",
      "Epoch: 6/20... Training loss: 0.1203\n",
      "Epoch: 6/20... Training loss: 0.1168\n",
      "Epoch: 6/20... Training loss: 0.1110\n",
      "Epoch: 6/20... Training loss: 0.1112\n",
      "Epoch: 6/20... Training loss: 0.1192\n",
      "Epoch: 6/20... Training loss: 0.1172\n",
      "Epoch: 6/20... Training loss: 0.1184\n",
      "Epoch: 6/20... Training loss: 0.1196\n",
      "Epoch: 6/20... Training loss: 0.1167\n",
      "Epoch: 6/20... Training loss: 0.1213\n",
      "Epoch: 6/20... Training loss: 0.1146\n",
      "Epoch: 6/20... Training loss: 0.1216\n",
      "Epoch: 6/20... Training loss: 0.1201\n",
      "Epoch: 6/20... Training loss: 0.1204\n",
      "Epoch: 6/20... Training loss: 0.1204\n",
      "Epoch: 6/20... Training loss: 0.1227\n",
      "Epoch: 6/20... Training loss: 0.1222\n",
      "Epoch: 6/20... Training loss: 0.1206\n",
      "Epoch: 6/20... Training loss: 0.1175\n",
      "Epoch: 6/20... Training loss: 0.1137\n",
      "Epoch: 6/20... Training loss: 0.1196\n",
      "Epoch: 6/20... Training loss: 0.1239\n",
      "Epoch: 6/20... Training loss: 0.1224\n",
      "Epoch: 6/20... Training loss: 0.1181\n",
      "Epoch: 6/20... Training loss: 0.1184\n",
      "Epoch: 6/20... Training loss: 0.1201\n",
      "Epoch: 6/20... Training loss: 0.1142\n",
      "Epoch: 6/20... Training loss: 0.1232\n",
      "Epoch: 6/20... Training loss: 0.1164\n",
      "Epoch: 6/20... Training loss: 0.1127\n",
      "Epoch: 6/20... Training loss: 0.1157\n",
      "Epoch: 6/20... Training loss: 0.1080\n",
      "Epoch: 6/20... Training loss: 0.1166\n",
      "Epoch: 6/20... Training loss: 0.1211\n",
      "Epoch: 6/20... Training loss: 0.1170\n",
      "Epoch: 6/20... Training loss: 0.1154\n",
      "Epoch: 6/20... Training loss: 0.1192\n",
      "Epoch: 6/20... Training loss: 0.1167\n",
      "Epoch: 6/20... Training loss: 0.1165\n",
      "Epoch: 6/20... Training loss: 0.1192\n",
      "Epoch: 6/20... Training loss: 0.1256\n",
      "Epoch: 6/20... Training loss: 0.1191\n",
      "Epoch: 6/20... Training loss: 0.1149\n",
      "Epoch: 6/20... Training loss: 0.1137\n",
      "Epoch: 6/20... Training loss: 0.1103\n",
      "Epoch: 6/20... Training loss: 0.1169\n",
      "Epoch: 6/20... Training loss: 0.1189\n",
      "Epoch: 6/20... Training loss: 0.1196\n",
      "Epoch: 6/20... Training loss: 0.1210\n",
      "Epoch: 6/20... Training loss: 0.1111\n",
      "Epoch: 6/20... Training loss: 0.1163\n",
      "Epoch: 6/20... Training loss: 0.1183\n",
      "Epoch: 6/20... Training loss: 0.1145\n",
      "Epoch: 6/20... Training loss: 0.1161\n",
      "Epoch: 6/20... Training loss: 0.1250\n",
      "Epoch: 6/20... Training loss: 0.1204\n",
      "Epoch: 6/20... Training loss: 0.1172\n",
      "Epoch: 6/20... Training loss: 0.1204\n",
      "Epoch: 6/20... Training loss: 0.1179\n",
      "Epoch: 6/20... Training loss: 0.1166\n",
      "Epoch: 6/20... Training loss: 0.1205\n",
      "Epoch: 6/20... Training loss: 0.1217\n",
      "Epoch: 6/20... Training loss: 0.1219\n",
      "Epoch: 6/20... Training loss: 0.1208\n",
      "Epoch: 6/20... Training loss: 0.1194\n",
      "Epoch: 6/20... Training loss: 0.1215\n",
      "Epoch: 6/20... Training loss: 0.1195\n",
      "Epoch: 6/20... Training loss: 0.1205\n",
      "Epoch: 6/20... Training loss: 0.1203\n",
      "Epoch: 6/20... Training loss: 0.1160\n",
      "Epoch: 6/20... Training loss: 0.1160\n",
      "Epoch: 6/20... Training loss: 0.1234\n",
      "Epoch: 6/20... Training loss: 0.1230\n",
      "Epoch: 6/20... Training loss: 0.1145\n",
      "Epoch: 6/20... Training loss: 0.1153\n",
      "Epoch: 6/20... Training loss: 0.1185\n",
      "Epoch: 6/20... Training loss: 0.1176\n",
      "Epoch: 6/20... Training loss: 0.1224\n",
      "Epoch: 6/20... Training loss: 0.1164\n",
      "Epoch: 6/20... Training loss: 0.1259\n",
      "Epoch: 6/20... Training loss: 0.1170\n",
      "Epoch: 6/20... Training loss: 0.1252\n",
      "Epoch: 6/20... Training loss: 0.1224\n",
      "Epoch: 6/20... Training loss: 0.1208\n",
      "Epoch: 6/20... Training loss: 0.1150\n",
      "Epoch: 6/20... Training loss: 0.1199\n",
      "Epoch: 6/20... Training loss: 0.1191\n",
      "Epoch: 6/20... Training loss: 0.1158\n",
      "Epoch: 6/20... Training loss: 0.1119\n",
      "Epoch: 6/20... Training loss: 0.1141\n",
      "Epoch: 6/20... Training loss: 0.1166\n",
      "Epoch: 6/20... Training loss: 0.1192\n",
      "Epoch: 6/20... Training loss: 0.1205\n",
      "Epoch: 6/20... Training loss: 0.1197\n",
      "Epoch: 6/20... Training loss: 0.1192\n",
      "Epoch: 6/20... Training loss: 0.1119\n",
      "Epoch: 6/20... Training loss: 0.1176\n",
      "Epoch: 6/20... Training loss: 0.1119\n",
      "Epoch: 6/20... Training loss: 0.1190\n",
      "Epoch: 6/20... Training loss: 0.1176\n",
      "Epoch: 6/20... Training loss: 0.1176\n",
      "Epoch: 6/20... Training loss: 0.1144\n",
      "Epoch: 6/20... Training loss: 0.1189\n",
      "Epoch: 6/20... Training loss: 0.1213\n",
      "Epoch: 6/20... Training loss: 0.1219\n",
      "Epoch: 6/20... Training loss: 0.1147\n",
      "Epoch: 6/20... Training loss: 0.1177\n",
      "Epoch: 6/20... Training loss: 0.1110\n",
      "Epoch: 6/20... Training loss: 0.1182\n",
      "Epoch: 6/20... Training loss: 0.1171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/20... Training loss: 0.1130\n",
      "Epoch: 6/20... Training loss: 0.1148\n",
      "Epoch: 6/20... Training loss: 0.1177\n",
      "Epoch: 6/20... Training loss: 0.1183\n",
      "Epoch: 6/20... Training loss: 0.1160\n",
      "Epoch: 6/20... Training loss: 0.1138\n",
      "Epoch: 6/20... Training loss: 0.1207\n",
      "Epoch: 6/20... Training loss: 0.1148\n",
      "Epoch: 6/20... Training loss: 0.1128\n",
      "Epoch: 6/20... Training loss: 0.1165\n",
      "Epoch: 6/20... Training loss: 0.1201\n",
      "Epoch: 6/20... Training loss: 0.1202\n",
      "Epoch: 6/20... Training loss: 0.1151\n",
      "Epoch: 6/20... Training loss: 0.1185\n",
      "Epoch: 6/20... Training loss: 0.1171\n",
      "Epoch: 6/20... Training loss: 0.1243\n",
      "Epoch: 6/20... Training loss: 0.1185\n",
      "Epoch: 6/20... Training loss: 0.1152\n",
      "Epoch: 6/20... Training loss: 0.1291\n",
      "Epoch: 6/20... Training loss: 0.1181\n",
      "Epoch: 6/20... Training loss: 0.1249\n",
      "Epoch: 6/20... Training loss: 0.1201\n",
      "Epoch: 6/20... Training loss: 0.1160\n",
      "Epoch: 6/20... Training loss: 0.1169\n",
      "Epoch: 7/20... Training loss: 0.1157\n",
      "Epoch: 7/20... Training loss: 0.1122\n",
      "Epoch: 7/20... Training loss: 0.1161\n",
      "Epoch: 7/20... Training loss: 0.1168\n",
      "Epoch: 7/20... Training loss: 0.1154\n",
      "Epoch: 7/20... Training loss: 0.1189\n",
      "Epoch: 7/20... Training loss: 0.1143\n",
      "Epoch: 7/20... Training loss: 0.1185\n",
      "Epoch: 7/20... Training loss: 0.1150\n",
      "Epoch: 7/20... Training loss: 0.1133\n",
      "Epoch: 7/20... Training loss: 0.1113\n",
      "Epoch: 7/20... Training loss: 0.1196\n",
      "Epoch: 7/20... Training loss: 0.1171\n",
      "Epoch: 7/20... Training loss: 0.1179\n",
      "Epoch: 7/20... Training loss: 0.1145\n",
      "Epoch: 7/20... Training loss: 0.1203\n",
      "Epoch: 7/20... Training loss: 0.1100\n",
      "Epoch: 7/20... Training loss: 0.1140\n",
      "Epoch: 7/20... Training loss: 0.1256\n",
      "Epoch: 7/20... Training loss: 0.1172\n",
      "Epoch: 7/20... Training loss: 0.1117\n",
      "Epoch: 7/20... Training loss: 0.1177\n",
      "Epoch: 7/20... Training loss: 0.1154\n",
      "Epoch: 7/20... Training loss: 0.1214\n",
      "Epoch: 7/20... Training loss: 0.1188\n",
      "Epoch: 7/20... Training loss: 0.1182\n",
      "Epoch: 7/20... Training loss: 0.1185\n",
      "Epoch: 7/20... Training loss: 0.1137\n",
      "Epoch: 7/20... Training loss: 0.1164\n",
      "Epoch: 7/20... Training loss: 0.1134\n",
      "Epoch: 7/20... Training loss: 0.1160\n",
      "Epoch: 7/20... Training loss: 0.1104\n",
      "Epoch: 7/20... Training loss: 0.1125\n",
      "Epoch: 7/20... Training loss: 0.1120\n",
      "Epoch: 7/20... Training loss: 0.1157\n",
      "Epoch: 7/20... Training loss: 0.1152\n",
      "Epoch: 7/20... Training loss: 0.1205\n",
      "Epoch: 7/20... Training loss: 0.1122\n",
      "Epoch: 7/20... Training loss: 0.1164\n",
      "Epoch: 7/20... Training loss: 0.1169\n",
      "Epoch: 7/20... Training loss: 0.1133\n",
      "Epoch: 7/20... Training loss: 0.1163\n",
      "Epoch: 7/20... Training loss: 0.1118\n",
      "Epoch: 7/20... Training loss: 0.1175\n",
      "Epoch: 7/20... Training loss: 0.1107\n",
      "Epoch: 7/20... Training loss: 0.1180\n",
      "Epoch: 7/20... Training loss: 0.1179\n",
      "Epoch: 7/20... Training loss: 0.1202\n",
      "Epoch: 7/20... Training loss: 0.1197\n",
      "Epoch: 7/20... Training loss: 0.1188\n",
      "Epoch: 7/20... Training loss: 0.1143\n",
      "Epoch: 7/20... Training loss: 0.1136\n",
      "Epoch: 7/20... Training loss: 0.1170\n",
      "Epoch: 7/20... Training loss: 0.1181\n",
      "Epoch: 7/20... Training loss: 0.1104\n",
      "Epoch: 7/20... Training loss: 0.1133\n",
      "Epoch: 7/20... Training loss: 0.1096\n",
      "Epoch: 7/20... Training loss: 0.1125\n",
      "Epoch: 7/20... Training loss: 0.1092\n",
      "Epoch: 7/20... Training loss: 0.1112\n",
      "Epoch: 7/20... Training loss: 0.1102\n",
      "Epoch: 7/20... Training loss: 0.1163\n",
      "Epoch: 7/20... Training loss: 0.1220\n",
      "Epoch: 7/20... Training loss: 0.1222\n",
      "Epoch: 7/20... Training loss: 0.1212\n",
      "Epoch: 7/20... Training loss: 0.1156\n",
      "Epoch: 7/20... Training loss: 0.1202\n",
      "Epoch: 7/20... Training loss: 0.1186\n",
      "Epoch: 7/20... Training loss: 0.1141\n",
      "Epoch: 7/20... Training loss: 0.1211\n",
      "Epoch: 7/20... Training loss: 0.1166\n",
      "Epoch: 7/20... Training loss: 0.1155\n",
      "Epoch: 7/20... Training loss: 0.1184\n",
      "Epoch: 7/20... Training loss: 0.1183\n",
      "Epoch: 7/20... Training loss: 0.1124\n",
      "Epoch: 7/20... Training loss: 0.1172\n",
      "Epoch: 7/20... Training loss: 0.1179\n",
      "Epoch: 7/20... Training loss: 0.1176\n",
      "Epoch: 7/20... Training loss: 0.1246\n",
      "Epoch: 7/20... Training loss: 0.1132\n",
      "Epoch: 7/20... Training loss: 0.1139\n",
      "Epoch: 7/20... Training loss: 0.1108\n",
      "Epoch: 7/20... Training loss: 0.1145\n",
      "Epoch: 7/20... Training loss: 0.1181\n",
      "Epoch: 7/20... Training loss: 0.1177\n",
      "Epoch: 7/20... Training loss: 0.1179\n",
      "Epoch: 7/20... Training loss: 0.1234\n",
      "Epoch: 7/20... Training loss: 0.1218\n",
      "Epoch: 7/20... Training loss: 0.1175\n",
      "Epoch: 7/20... Training loss: 0.1089\n",
      "Epoch: 7/20... Training loss: 0.1068\n",
      "Epoch: 7/20... Training loss: 0.1093\n",
      "Epoch: 7/20... Training loss: 0.1161\n",
      "Epoch: 7/20... Training loss: 0.1223\n",
      "Epoch: 7/20... Training loss: 0.1135\n",
      "Epoch: 7/20... Training loss: 0.1112\n",
      "Epoch: 7/20... Training loss: 0.1242\n",
      "Epoch: 7/20... Training loss: 0.1124\n",
      "Epoch: 7/20... Training loss: 0.1131\n",
      "Epoch: 7/20... Training loss: 0.1210\n",
      "Epoch: 7/20... Training loss: 0.1178\n",
      "Epoch: 7/20... Training loss: 0.1144\n",
      "Epoch: 7/20... Training loss: 0.1119\n",
      "Epoch: 7/20... Training loss: 0.1115\n",
      "Epoch: 7/20... Training loss: 0.1171\n",
      "Epoch: 7/20... Training loss: 0.1139\n",
      "Epoch: 7/20... Training loss: 0.1186\n",
      "Epoch: 7/20... Training loss: 0.1168\n",
      "Epoch: 7/20... Training loss: 0.1141\n",
      "Epoch: 7/20... Training loss: 0.1153\n",
      "Epoch: 7/20... Training loss: 0.1282\n",
      "Epoch: 7/20... Training loss: 0.1183\n",
      "Epoch: 7/20... Training loss: 0.1148\n",
      "Epoch: 7/20... Training loss: 0.1169\n",
      "Epoch: 7/20... Training loss: 0.1167\n",
      "Epoch: 7/20... Training loss: 0.1152\n",
      "Epoch: 7/20... Training loss: 0.1109\n",
      "Epoch: 7/20... Training loss: 0.1142\n",
      "Epoch: 7/20... Training loss: 0.1213\n",
      "Epoch: 7/20... Training loss: 0.1204\n",
      "Epoch: 7/20... Training loss: 0.1060\n",
      "Epoch: 7/20... Training loss: 0.1115\n",
      "Epoch: 7/20... Training loss: 0.1199\n",
      "Epoch: 7/20... Training loss: 0.1099\n",
      "Epoch: 7/20... Training loss: 0.1064\n",
      "Epoch: 7/20... Training loss: 0.1167\n",
      "Epoch: 7/20... Training loss: 0.1177\n",
      "Epoch: 7/20... Training loss: 0.1100\n",
      "Epoch: 7/20... Training loss: 0.1118\n",
      "Epoch: 7/20... Training loss: 0.1133\n",
      "Epoch: 7/20... Training loss: 0.1113\n",
      "Epoch: 7/20... Training loss: 0.1127\n",
      "Epoch: 7/20... Training loss: 0.1146\n",
      "Epoch: 7/20... Training loss: 0.1177\n",
      "Epoch: 7/20... Training loss: 0.1112\n",
      "Epoch: 7/20... Training loss: 0.1239\n",
      "Epoch: 7/20... Training loss: 0.1232\n",
      "Epoch: 7/20... Training loss: 0.1154\n",
      "Epoch: 7/20... Training loss: 0.1171\n",
      "Epoch: 7/20... Training loss: 0.1145\n",
      "Epoch: 7/20... Training loss: 0.1116\n",
      "Epoch: 7/20... Training loss: 0.1158\n",
      "Epoch: 7/20... Training loss: 0.1103\n",
      "Epoch: 7/20... Training loss: 0.1148\n",
      "Epoch: 7/20... Training loss: 0.1207\n",
      "Epoch: 7/20... Training loss: 0.1262\n",
      "Epoch: 7/20... Training loss: 0.1154\n",
      "Epoch: 7/20... Training loss: 0.1091\n",
      "Epoch: 7/20... Training loss: 0.1152\n",
      "Epoch: 7/20... Training loss: 0.1100\n",
      "Epoch: 7/20... Training loss: 0.1167\n",
      "Epoch: 7/20... Training loss: 0.1177\n",
      "Epoch: 7/20... Training loss: 0.1179\n",
      "Epoch: 7/20... Training loss: 0.1173\n",
      "Epoch: 7/20... Training loss: 0.1166\n",
      "Epoch: 7/20... Training loss: 0.1149\n",
      "Epoch: 7/20... Training loss: 0.1128\n",
      "Epoch: 7/20... Training loss: 0.1163\n",
      "Epoch: 7/20... Training loss: 0.1198\n",
      "Epoch: 7/20... Training loss: 0.1143\n",
      "Epoch: 7/20... Training loss: 0.1178\n",
      "Epoch: 7/20... Training loss: 0.1139\n",
      "Epoch: 7/20... Training loss: 0.1124\n",
      "Epoch: 7/20... Training loss: 0.1209\n",
      "Epoch: 7/20... Training loss: 0.1157\n",
      "Epoch: 7/20... Training loss: 0.1125\n",
      "Epoch: 7/20... Training loss: 0.1174\n",
      "Epoch: 7/20... Training loss: 0.1142\n",
      "Epoch: 7/20... Training loss: 0.1084\n",
      "Epoch: 7/20... Training loss: 0.1085\n",
      "Epoch: 7/20... Training loss: 0.1169\n",
      "Epoch: 7/20... Training loss: 0.1146\n",
      "Epoch: 7/20... Training loss: 0.1155\n",
      "Epoch: 7/20... Training loss: 0.1172\n",
      "Epoch: 7/20... Training loss: 0.1141\n",
      "Epoch: 7/20... Training loss: 0.1189\n",
      "Epoch: 7/20... Training loss: 0.1121\n",
      "Epoch: 7/20... Training loss: 0.1191\n",
      "Epoch: 7/20... Training loss: 0.1174\n",
      "Epoch: 7/20... Training loss: 0.1177\n",
      "Epoch: 7/20... Training loss: 0.1176\n",
      "Epoch: 7/20... Training loss: 0.1200\n",
      "Epoch: 7/20... Training loss: 0.1198\n",
      "Epoch: 7/20... Training loss: 0.1176\n",
      "Epoch: 7/20... Training loss: 0.1154\n",
      "Epoch: 7/20... Training loss: 0.1114\n",
      "Epoch: 7/20... Training loss: 0.1167\n",
      "Epoch: 7/20... Training loss: 0.1215\n",
      "Epoch: 7/20... Training loss: 0.1199\n",
      "Epoch: 7/20... Training loss: 0.1156\n",
      "Epoch: 7/20... Training loss: 0.1161\n",
      "Epoch: 7/20... Training loss: 0.1176\n",
      "Epoch: 7/20... Training loss: 0.1119\n",
      "Epoch: 7/20... Training loss: 0.1211\n",
      "Epoch: 7/20... Training loss: 0.1142\n",
      "Epoch: 7/20... Training loss: 0.1100\n",
      "Epoch: 7/20... Training loss: 0.1135\n",
      "Epoch: 7/20... Training loss: 0.1061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/20... Training loss: 0.1143\n",
      "Epoch: 7/20... Training loss: 0.1189\n",
      "Epoch: 7/20... Training loss: 0.1149\n",
      "Epoch: 7/20... Training loss: 0.1133\n",
      "Epoch: 7/20... Training loss: 0.1168\n",
      "Epoch: 7/20... Training loss: 0.1144\n",
      "Epoch: 7/20... Training loss: 0.1141\n",
      "Epoch: 7/20... Training loss: 0.1170\n",
      "Epoch: 7/20... Training loss: 0.1231\n",
      "Epoch: 7/20... Training loss: 0.1167\n",
      "Epoch: 7/20... Training loss: 0.1126\n",
      "Epoch: 7/20... Training loss: 0.1116\n",
      "Epoch: 7/20... Training loss: 0.1080\n",
      "Epoch: 7/20... Training loss: 0.1145\n",
      "Epoch: 7/20... Training loss: 0.1165\n",
      "Epoch: 7/20... Training loss: 0.1172\n",
      "Epoch: 7/20... Training loss: 0.1184\n",
      "Epoch: 7/20... Training loss: 0.1090\n",
      "Epoch: 7/20... Training loss: 0.1138\n",
      "Epoch: 7/20... Training loss: 0.1160\n",
      "Epoch: 7/20... Training loss: 0.1122\n",
      "Epoch: 7/20... Training loss: 0.1135\n",
      "Epoch: 7/20... Training loss: 0.1225\n",
      "Epoch: 7/20... Training loss: 0.1181\n",
      "Epoch: 7/20... Training loss: 0.1148\n",
      "Epoch: 7/20... Training loss: 0.1176\n",
      "Epoch: 7/20... Training loss: 0.1157\n",
      "Epoch: 7/20... Training loss: 0.1140\n",
      "Epoch: 7/20... Training loss: 0.1177\n",
      "Epoch: 7/20... Training loss: 0.1192\n",
      "Epoch: 7/20... Training loss: 0.1195\n",
      "Epoch: 7/20... Training loss: 0.1185\n",
      "Epoch: 7/20... Training loss: 0.1166\n",
      "Epoch: 7/20... Training loss: 0.1190\n",
      "Epoch: 7/20... Training loss: 0.1167\n",
      "Epoch: 7/20... Training loss: 0.1183\n",
      "Epoch: 7/20... Training loss: 0.1176\n",
      "Epoch: 7/20... Training loss: 0.1134\n",
      "Epoch: 7/20... Training loss: 0.1134\n",
      "Epoch: 7/20... Training loss: 0.1208\n",
      "Epoch: 7/20... Training loss: 0.1203\n",
      "Epoch: 7/20... Training loss: 0.1118\n",
      "Epoch: 7/20... Training loss: 0.1127\n",
      "Epoch: 7/20... Training loss: 0.1157\n",
      "Epoch: 7/20... Training loss: 0.1153\n",
      "Epoch: 7/20... Training loss: 0.1196\n",
      "Epoch: 7/20... Training loss: 0.1139\n",
      "Epoch: 7/20... Training loss: 0.1234\n",
      "Epoch: 7/20... Training loss: 0.1145\n",
      "Epoch: 7/20... Training loss: 0.1221\n",
      "Epoch: 7/20... Training loss: 0.1195\n",
      "Epoch: 7/20... Training loss: 0.1186\n",
      "Epoch: 7/20... Training loss: 0.1125\n",
      "Epoch: 7/20... Training loss: 0.1173\n",
      "Epoch: 7/20... Training loss: 0.1168\n",
      "Epoch: 7/20... Training loss: 0.1135\n",
      "Epoch: 7/20... Training loss: 0.1094\n",
      "Epoch: 7/20... Training loss: 0.1118\n",
      "Epoch: 7/20... Training loss: 0.1144\n",
      "Epoch: 7/20... Training loss: 0.1164\n",
      "Epoch: 7/20... Training loss: 0.1179\n",
      "Epoch: 7/20... Training loss: 0.1172\n",
      "Epoch: 7/20... Training loss: 0.1168\n",
      "Epoch: 7/20... Training loss: 0.1097\n",
      "Epoch: 7/20... Training loss: 0.1148\n",
      "Epoch: 7/20... Training loss: 0.1101\n",
      "Epoch: 7/20... Training loss: 0.1168\n",
      "Epoch: 7/20... Training loss: 0.1154\n",
      "Epoch: 7/20... Training loss: 0.1153\n",
      "Epoch: 7/20... Training loss: 0.1120\n",
      "Epoch: 7/20... Training loss: 0.1166\n",
      "Epoch: 7/20... Training loss: 0.1193\n",
      "Epoch: 7/20... Training loss: 0.1198\n",
      "Epoch: 7/20... Training loss: 0.1124\n",
      "Epoch: 7/20... Training loss: 0.1157\n",
      "Epoch: 7/20... Training loss: 0.1090\n",
      "Epoch: 7/20... Training loss: 0.1160\n",
      "Epoch: 7/20... Training loss: 0.1153\n",
      "Epoch: 7/20... Training loss: 0.1109\n",
      "Epoch: 7/20... Training loss: 0.1128\n",
      "Epoch: 7/20... Training loss: 0.1155\n",
      "Epoch: 7/20... Training loss: 0.1158\n",
      "Epoch: 7/20... Training loss: 0.1138\n",
      "Epoch: 7/20... Training loss: 0.1121\n",
      "Epoch: 7/20... Training loss: 0.1187\n",
      "Epoch: 7/20... Training loss: 0.1126\n",
      "Epoch: 7/20... Training loss: 0.1105\n",
      "Epoch: 7/20... Training loss: 0.1142\n",
      "Epoch: 7/20... Training loss: 0.1178\n",
      "Epoch: 7/20... Training loss: 0.1177\n",
      "Epoch: 7/20... Training loss: 0.1128\n",
      "Epoch: 7/20... Training loss: 0.1160\n",
      "Epoch: 7/20... Training loss: 0.1148\n",
      "Epoch: 7/20... Training loss: 0.1212\n",
      "Epoch: 7/20... Training loss: 0.1164\n",
      "Epoch: 7/20... Training loss: 0.1122\n",
      "Epoch: 7/20... Training loss: 0.1259\n",
      "Epoch: 7/20... Training loss: 0.1157\n",
      "Epoch: 7/20... Training loss: 0.1220\n",
      "Epoch: 7/20... Training loss: 0.1176\n",
      "Epoch: 7/20... Training loss: 0.1133\n",
      "Epoch: 7/20... Training loss: 0.1153\n",
      "Epoch: 8/20... Training loss: 0.1127\n",
      "Epoch: 8/20... Training loss: 0.1105\n",
      "Epoch: 8/20... Training loss: 0.1133\n",
      "Epoch: 8/20... Training loss: 0.1147\n",
      "Epoch: 8/20... Training loss: 0.1127\n",
      "Epoch: 8/20... Training loss: 0.1168\n",
      "Epoch: 8/20... Training loss: 0.1126\n",
      "Epoch: 8/20... Training loss: 0.1163\n",
      "Epoch: 8/20... Training loss: 0.1134\n",
      "Epoch: 8/20... Training loss: 0.1113\n",
      "Epoch: 8/20... Training loss: 0.1095\n",
      "Epoch: 8/20... Training loss: 0.1178\n",
      "Epoch: 8/20... Training loss: 0.1147\n",
      "Epoch: 8/20... Training loss: 0.1160\n",
      "Epoch: 8/20... Training loss: 0.1121\n",
      "Epoch: 8/20... Training loss: 0.1184\n",
      "Epoch: 8/20... Training loss: 0.1079\n",
      "Epoch: 8/20... Training loss: 0.1120\n",
      "Epoch: 8/20... Training loss: 0.1235\n",
      "Epoch: 8/20... Training loss: 0.1151\n",
      "Epoch: 8/20... Training loss: 0.1100\n",
      "Epoch: 8/20... Training loss: 0.1157\n",
      "Epoch: 8/20... Training loss: 0.1135\n",
      "Epoch: 8/20... Training loss: 0.1191\n",
      "Epoch: 8/20... Training loss: 0.1169\n",
      "Epoch: 8/20... Training loss: 0.1166\n",
      "Epoch: 8/20... Training loss: 0.1164\n",
      "Epoch: 8/20... Training loss: 0.1117\n",
      "Epoch: 8/20... Training loss: 0.1144\n",
      "Epoch: 8/20... Training loss: 0.1114\n",
      "Epoch: 8/20... Training loss: 0.1139\n",
      "Epoch: 8/20... Training loss: 0.1084\n",
      "Epoch: 8/20... Training loss: 0.1104\n",
      "Epoch: 8/20... Training loss: 0.1099\n",
      "Epoch: 8/20... Training loss: 0.1137\n",
      "Epoch: 8/20... Training loss: 0.1132\n",
      "Epoch: 8/20... Training loss: 0.1184\n",
      "Epoch: 8/20... Training loss: 0.1098\n",
      "Epoch: 8/20... Training loss: 0.1143\n",
      "Epoch: 8/20... Training loss: 0.1148\n",
      "Epoch: 8/20... Training loss: 0.1113\n",
      "Epoch: 8/20... Training loss: 0.1140\n",
      "Epoch: 8/20... Training loss: 0.1097\n",
      "Epoch: 8/20... Training loss: 0.1154\n",
      "Epoch: 8/20... Training loss: 0.1085\n",
      "Epoch: 8/20... Training loss: 0.1160\n",
      "Epoch: 8/20... Training loss: 0.1156\n",
      "Epoch: 8/20... Training loss: 0.1182\n",
      "Epoch: 8/20... Training loss: 0.1174\n",
      "Epoch: 8/20... Training loss: 0.1165\n",
      "Epoch: 8/20... Training loss: 0.1121\n",
      "Epoch: 8/20... Training loss: 0.1111\n",
      "Epoch: 8/20... Training loss: 0.1147\n",
      "Epoch: 8/20... Training loss: 0.1157\n",
      "Epoch: 8/20... Training loss: 0.1083\n",
      "Epoch: 8/20... Training loss: 0.1112\n",
      "Epoch: 8/20... Training loss: 0.1075\n",
      "Epoch: 8/20... Training loss: 0.1102\n",
      "Epoch: 8/20... Training loss: 0.1073\n",
      "Epoch: 8/20... Training loss: 0.1087\n",
      "Epoch: 8/20... Training loss: 0.1081\n",
      "Epoch: 8/20... Training loss: 0.1139\n",
      "Epoch: 8/20... Training loss: 0.1196\n",
      "Epoch: 8/20... Training loss: 0.1197\n",
      "Epoch: 8/20... Training loss: 0.1187\n",
      "Epoch: 8/20... Training loss: 0.1135\n",
      "Epoch: 8/20... Training loss: 0.1176\n",
      "Epoch: 8/20... Training loss: 0.1162\n",
      "Epoch: 8/20... Training loss: 0.1121\n",
      "Epoch: 8/20... Training loss: 0.1188\n",
      "Epoch: 8/20... Training loss: 0.1141\n",
      "Epoch: 8/20... Training loss: 0.1132\n",
      "Epoch: 8/20... Training loss: 0.1162\n",
      "Epoch: 8/20... Training loss: 0.1161\n",
      "Epoch: 8/20... Training loss: 0.1104\n",
      "Epoch: 8/20... Training loss: 0.1151\n",
      "Epoch: 8/20... Training loss: 0.1157\n",
      "Epoch: 8/20... Training loss: 0.1155\n",
      "Epoch: 8/20... Training loss: 0.1224\n",
      "Epoch: 8/20... Training loss: 0.1114\n",
      "Epoch: 8/20... Training loss: 0.1117\n",
      "Epoch: 8/20... Training loss: 0.1089\n",
      "Epoch: 8/20... Training loss: 0.1122\n",
      "Epoch: 8/20... Training loss: 0.1159\n",
      "Epoch: 8/20... Training loss: 0.1154\n",
      "Epoch: 8/20... Training loss: 0.1157\n",
      "Epoch: 8/20... Training loss: 0.1208\n",
      "Epoch: 8/20... Training loss: 0.1195\n",
      "Epoch: 8/20... Training loss: 0.1156\n",
      "Epoch: 8/20... Training loss: 0.1068\n",
      "Epoch: 8/20... Training loss: 0.1047\n",
      "Epoch: 8/20... Training loss: 0.1070\n",
      "Epoch: 8/20... Training loss: 0.1137\n",
      "Epoch: 8/20... Training loss: 0.1201\n",
      "Epoch: 8/20... Training loss: 0.1114\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.1222\n",
      "Epoch: 8/20... Training loss: 0.1101\n",
      "Epoch: 8/20... Training loss: 0.1105\n",
      "Epoch: 8/20... Training loss: 0.1188\n",
      "Epoch: 8/20... Training loss: 0.1156\n",
      "Epoch: 8/20... Training loss: 0.1125\n",
      "Epoch: 8/20... Training loss: 0.1100\n",
      "Epoch: 8/20... Training loss: 0.1094\n",
      "Epoch: 8/20... Training loss: 0.1148\n",
      "Epoch: 8/20... Training loss: 0.1120\n",
      "Epoch: 8/20... Training loss: 0.1167\n",
      "Epoch: 8/20... Training loss: 0.1144\n",
      "Epoch: 8/20... Training loss: 0.1119\n",
      "Epoch: 8/20... Training loss: 0.1131\n",
      "Epoch: 8/20... Training loss: 0.1256\n",
      "Epoch: 8/20... Training loss: 0.1161\n",
      "Epoch: 8/20... Training loss: 0.1129\n",
      "Epoch: 8/20... Training loss: 0.1148\n",
      "Epoch: 8/20... Training loss: 0.1144\n",
      "Epoch: 8/20... Training loss: 0.1133\n",
      "Epoch: 8/20... Training loss: 0.1087\n",
      "Epoch: 8/20... Training loss: 0.1122\n",
      "Epoch: 8/20... Training loss: 0.1192\n",
      "Epoch: 8/20... Training loss: 0.1181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/20... Training loss: 0.1039\n",
      "Epoch: 8/20... Training loss: 0.1097\n",
      "Epoch: 8/20... Training loss: 0.1176\n",
      "Epoch: 8/20... Training loss: 0.1080\n",
      "Epoch: 8/20... Training loss: 0.1046\n",
      "Epoch: 8/20... Training loss: 0.1145\n",
      "Epoch: 8/20... Training loss: 0.1150\n",
      "Epoch: 8/20... Training loss: 0.1080\n",
      "Epoch: 8/20... Training loss: 0.1096\n",
      "Epoch: 8/20... Training loss: 0.1114\n",
      "Epoch: 8/20... Training loss: 0.1092\n",
      "Epoch: 8/20... Training loss: 0.1104\n",
      "Epoch: 8/20... Training loss: 0.1125\n",
      "Epoch: 8/20... Training loss: 0.1150\n",
      "Epoch: 8/20... Training loss: 0.1092\n",
      "Epoch: 8/20... Training loss: 0.1216\n",
      "Epoch: 8/20... Training loss: 0.1206\n",
      "Epoch: 8/20... Training loss: 0.1133\n",
      "Epoch: 8/20... Training loss: 0.1147\n",
      "Epoch: 8/20... Training loss: 0.1124\n",
      "Epoch: 8/20... Training loss: 0.1092\n",
      "Epoch: 8/20... Training loss: 0.1137\n",
      "Epoch: 8/20... Training loss: 0.1079\n",
      "Epoch: 8/20... Training loss: 0.1128\n",
      "Epoch: 8/20... Training loss: 0.1183\n",
      "Epoch: 8/20... Training loss: 0.1238\n",
      "Epoch: 8/20... Training loss: 0.1132\n",
      "Epoch: 8/20... Training loss: 0.1070\n",
      "Epoch: 8/20... Training loss: 0.1130\n",
      "Epoch: 8/20... Training loss: 0.1081\n",
      "Epoch: 8/20... Training loss: 0.1146\n",
      "Epoch: 8/20... Training loss: 0.1154\n",
      "Epoch: 8/20... Training loss: 0.1157\n",
      "Epoch: 8/20... Training loss: 0.1153\n",
      "Epoch: 8/20... Training loss: 0.1146\n",
      "Epoch: 8/20... Training loss: 0.1128\n",
      "Epoch: 8/20... Training loss: 0.1111\n",
      "Epoch: 8/20... Training loss: 0.1143\n",
      "Epoch: 8/20... Training loss: 0.1177\n",
      "Epoch: 8/20... Training loss: 0.1125\n",
      "Epoch: 8/20... Training loss: 0.1157\n",
      "Epoch: 8/20... Training loss: 0.1122\n",
      "Epoch: 8/20... Training loss: 0.1102\n",
      "Epoch: 8/20... Training loss: 0.1188\n",
      "Epoch: 8/20... Training loss: 0.1136\n",
      "Epoch: 8/20... Training loss: 0.1104\n",
      "Epoch: 8/20... Training loss: 0.1151\n",
      "Epoch: 8/20... Training loss: 0.1124\n",
      "Epoch: 8/20... Training loss: 0.1063\n",
      "Epoch: 8/20... Training loss: 0.1065\n",
      "Epoch: 8/20... Training loss: 0.1148\n",
      "Epoch: 8/20... Training loss: 0.1124\n",
      "Epoch: 8/20... Training loss: 0.1132\n",
      "Epoch: 8/20... Training loss: 0.1153\n",
      "Epoch: 8/20... Training loss: 0.1120\n",
      "Epoch: 8/20... Training loss: 0.1166\n",
      "Epoch: 8/20... Training loss: 0.1101\n",
      "Epoch: 8/20... Training loss: 0.1171\n",
      "Epoch: 8/20... Training loss: 0.1154\n",
      "Epoch: 8/20... Training loss: 0.1154\n",
      "Epoch: 8/20... Training loss: 0.1153\n",
      "Epoch: 8/20... Training loss: 0.1179\n",
      "Epoch: 8/20... Training loss: 0.1178\n",
      "Epoch: 8/20... Training loss: 0.1153\n",
      "Epoch: 8/20... Training loss: 0.1136\n",
      "Epoch: 8/20... Training loss: 0.1092\n",
      "Epoch: 8/20... Training loss: 0.1144\n",
      "Epoch: 8/20... Training loss: 0.1194\n",
      "Epoch: 8/20... Training loss: 0.1178\n",
      "Epoch: 8/20... Training loss: 0.1137\n",
      "Epoch: 8/20... Training loss: 0.1144\n",
      "Epoch: 8/20... Training loss: 0.1154\n",
      "Epoch: 8/20... Training loss: 0.1098\n",
      "Epoch: 8/20... Training loss: 0.1192\n",
      "Epoch: 8/20... Training loss: 0.1123\n",
      "Epoch: 8/20... Training loss: 0.1078\n",
      "Epoch: 8/20... Training loss: 0.1118\n",
      "Epoch: 8/20... Training loss: 0.1042\n",
      "Epoch: 8/20... Training loss: 0.1121\n",
      "Epoch: 8/20... Training loss: 0.1171\n",
      "Epoch: 8/20... Training loss: 0.1128\n",
      "Epoch: 8/20... Training loss: 0.1112\n",
      "Epoch: 8/20... Training loss: 0.1149\n",
      "Epoch: 8/20... Training loss: 0.1124\n",
      "Epoch: 8/20... Training loss: 0.1121\n",
      "Epoch: 8/20... Training loss: 0.1154\n",
      "Epoch: 8/20... Training loss: 0.1209\n",
      "Epoch: 8/20... Training loss: 0.1147\n",
      "Epoch: 8/20... Training loss: 0.1110\n",
      "Epoch: 8/20... Training loss: 0.1098\n",
      "Epoch: 8/20... Training loss: 0.1059\n",
      "Epoch: 8/20... Training loss: 0.1127\n",
      "Epoch: 8/20... Training loss: 0.1144\n",
      "Epoch: 8/20... Training loss: 0.1147\n",
      "Epoch: 8/20... Training loss: 0.1166\n",
      "Epoch: 8/20... Training loss: 0.1072\n",
      "Epoch: 8/20... Training loss: 0.1117\n",
      "Epoch: 8/20... Training loss: 0.1143\n",
      "Epoch: 8/20... Training loss: 0.1104\n",
      "Epoch: 8/20... Training loss: 0.1116\n",
      "Epoch: 8/20... Training loss: 0.1206\n",
      "Epoch: 8/20... Training loss: 0.1162\n",
      "Epoch: 8/20... Training loss: 0.1129\n",
      "Epoch: 8/20... Training loss: 0.1155\n",
      "Epoch: 8/20... Training loss: 0.1138\n",
      "Epoch: 8/20... Training loss: 0.1121\n",
      "Epoch: 8/20... Training loss: 0.1155\n",
      "Epoch: 8/20... Training loss: 0.1172\n",
      "Epoch: 8/20... Training loss: 0.1178\n",
      "Epoch: 8/20... Training loss: 0.1167\n",
      "Epoch: 8/20... Training loss: 0.1142\n",
      "Epoch: 8/20... Training loss: 0.1170\n",
      "Epoch: 8/20... Training loss: 0.1148\n",
      "Epoch: 8/20... Training loss: 0.1164\n",
      "Epoch: 8/20... Training loss: 0.1155\n",
      "Epoch: 8/20... Training loss: 0.1115\n",
      "Epoch: 8/20... Training loss: 0.1114\n",
      "Epoch: 8/20... Training loss: 0.1188\n",
      "Epoch: 8/20... Training loss: 0.1180\n",
      "Epoch: 8/20... Training loss: 0.1100\n",
      "Epoch: 8/20... Training loss: 0.1105\n",
      "Epoch: 8/20... Training loss: 0.1135\n",
      "Epoch: 8/20... Training loss: 0.1132\n",
      "Epoch: 8/20... Training loss: 0.1173\n",
      "Epoch: 8/20... Training loss: 0.1118\n",
      "Epoch: 8/20... Training loss: 0.1214\n",
      "Epoch: 8/20... Training loss: 0.1125\n",
      "Epoch: 8/20... Training loss: 0.1199\n",
      "Epoch: 8/20... Training loss: 0.1172\n",
      "Epoch: 8/20... Training loss: 0.1167\n",
      "Epoch: 8/20... Training loss: 0.1105\n",
      "Epoch: 8/20... Training loss: 0.1152\n",
      "Epoch: 8/20... Training loss: 0.1152\n",
      "Epoch: 8/20... Training loss: 0.1115\n",
      "Epoch: 8/20... Training loss: 0.1075\n",
      "Epoch: 8/20... Training loss: 0.1099\n",
      "Epoch: 8/20... Training loss: 0.1128\n",
      "Epoch: 8/20... Training loss: 0.1141\n",
      "Epoch: 8/20... Training loss: 0.1158\n",
      "Epoch: 8/20... Training loss: 0.1153\n",
      "Epoch: 8/20... Training loss: 0.1148\n",
      "Epoch: 8/20... Training loss: 0.1080\n",
      "Epoch: 8/20... Training loss: 0.1126\n",
      "Epoch: 8/20... Training loss: 0.1084\n",
      "Epoch: 8/20... Training loss: 0.1148\n",
      "Epoch: 8/20... Training loss: 0.1136\n",
      "Epoch: 8/20... Training loss: 0.1133\n",
      "Epoch: 8/20... Training loss: 0.1100\n",
      "Epoch: 8/20... Training loss: 0.1147\n",
      "Epoch: 8/20... Training loss: 0.1174\n",
      "Epoch: 8/20... Training loss: 0.1177\n",
      "Epoch: 8/20... Training loss: 0.1106\n",
      "Epoch: 8/20... Training loss: 0.1138\n",
      "Epoch: 8/20... Training loss: 0.1071\n",
      "Epoch: 8/20... Training loss: 0.1141\n",
      "Epoch: 8/20... Training loss: 0.1135\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.1110\n",
      "Epoch: 8/20... Training loss: 0.1135\n",
      "Epoch: 8/20... Training loss: 0.1138\n",
      "Epoch: 8/20... Training loss: 0.1120\n",
      "Epoch: 8/20... Training loss: 0.1104\n",
      "Epoch: 8/20... Training loss: 0.1169\n",
      "Epoch: 8/20... Training loss: 0.1108\n",
      "Epoch: 8/20... Training loss: 0.1086\n",
      "Epoch: 8/20... Training loss: 0.1124\n",
      "Epoch: 8/20... Training loss: 0.1160\n",
      "Epoch: 8/20... Training loss: 0.1158\n",
      "Epoch: 8/20... Training loss: 0.1114\n",
      "Epoch: 8/20... Training loss: 0.1143\n",
      "Epoch: 8/20... Training loss: 0.1131\n",
      "Epoch: 8/20... Training loss: 0.1189\n",
      "Epoch: 8/20... Training loss: 0.1147\n",
      "Epoch: 8/20... Training loss: 0.1102\n",
      "Epoch: 8/20... Training loss: 0.1235\n",
      "Epoch: 8/20... Training loss: 0.1141\n",
      "Epoch: 8/20... Training loss: 0.1198\n",
      "Epoch: 8/20... Training loss: 0.1154\n",
      "Epoch: 8/20... Training loss: 0.1115\n",
      "Epoch: 8/20... Training loss: 0.1134\n",
      "Epoch: 9/20... Training loss: 0.1106\n",
      "Epoch: 9/20... Training loss: 0.1088\n",
      "Epoch: 9/20... Training loss: 0.1114\n",
      "Epoch: 9/20... Training loss: 0.1127\n",
      "Epoch: 9/20... Training loss: 0.1108\n",
      "Epoch: 9/20... Training loss: 0.1149\n",
      "Epoch: 9/20... Training loss: 0.1105\n",
      "Epoch: 9/20... Training loss: 0.1144\n",
      "Epoch: 9/20... Training loss: 0.1113\n",
      "Epoch: 9/20... Training loss: 0.1093\n",
      "Epoch: 9/20... Training loss: 0.1076\n",
      "Epoch: 9/20... Training loss: 0.1158\n",
      "Epoch: 9/20... Training loss: 0.1128\n",
      "Epoch: 9/20... Training loss: 0.1142\n",
      "Epoch: 9/20... Training loss: 0.1103\n",
      "Epoch: 9/20... Training loss: 0.1163\n",
      "Epoch: 9/20... Training loss: 0.1062\n",
      "Epoch: 9/20... Training loss: 0.1101\n",
      "Epoch: 9/20... Training loss: 0.1215\n",
      "Epoch: 9/20... Training loss: 0.1133\n",
      "Epoch: 9/20... Training loss: 0.1084\n",
      "Epoch: 9/20... Training loss: 0.1139\n",
      "Epoch: 9/20... Training loss: 0.1115\n",
      "Epoch: 9/20... Training loss: 0.1173\n",
      "Epoch: 9/20... Training loss: 0.1150\n",
      "Epoch: 9/20... Training loss: 0.1152\n",
      "Epoch: 9/20... Training loss: 0.1147\n",
      "Epoch: 9/20... Training loss: 0.1101\n",
      "Epoch: 9/20... Training loss: 0.1126\n",
      "Epoch: 9/20... Training loss: 0.1097\n",
      "Epoch: 9/20... Training loss: 0.1120\n",
      "Epoch: 9/20... Training loss: 0.1067\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1082\n",
      "Epoch: 9/20... Training loss: 0.1119\n",
      "Epoch: 9/20... Training loss: 0.1117\n",
      "Epoch: 9/20... Training loss: 0.1165\n",
      "Epoch: 9/20... Training loss: 0.1077\n",
      "Epoch: 9/20... Training loss: 0.1126\n",
      "Epoch: 9/20... Training loss: 0.1128\n",
      "Epoch: 9/20... Training loss: 0.1094\n",
      "Epoch: 9/20... Training loss: 0.1121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/20... Training loss: 0.1079\n",
      "Epoch: 9/20... Training loss: 0.1136\n",
      "Epoch: 9/20... Training loss: 0.1067\n",
      "Epoch: 9/20... Training loss: 0.1143\n",
      "Epoch: 9/20... Training loss: 0.1137\n",
      "Epoch: 9/20... Training loss: 0.1164\n",
      "Epoch: 9/20... Training loss: 0.1155\n",
      "Epoch: 9/20... Training loss: 0.1145\n",
      "Epoch: 9/20... Training loss: 0.1101\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1125\n",
      "Epoch: 9/20... Training loss: 0.1137\n",
      "Epoch: 9/20... Training loss: 0.1064\n",
      "Epoch: 9/20... Training loss: 0.1093\n",
      "Epoch: 9/20... Training loss: 0.1056\n",
      "Epoch: 9/20... Training loss: 0.1084\n",
      "Epoch: 9/20... Training loss: 0.1057\n",
      "Epoch: 9/20... Training loss: 0.1066\n",
      "Epoch: 9/20... Training loss: 0.1062\n",
      "Epoch: 9/20... Training loss: 0.1118\n",
      "Epoch: 9/20... Training loss: 0.1176\n",
      "Epoch: 9/20... Training loss: 0.1176\n",
      "Epoch: 9/20... Training loss: 0.1166\n",
      "Epoch: 9/20... Training loss: 0.1119\n",
      "Epoch: 9/20... Training loss: 0.1154\n",
      "Epoch: 9/20... Training loss: 0.1140\n",
      "Epoch: 9/20... Training loss: 0.1103\n",
      "Epoch: 9/20... Training loss: 0.1170\n",
      "Epoch: 9/20... Training loss: 0.1120\n",
      "Epoch: 9/20... Training loss: 0.1112\n",
      "Epoch: 9/20... Training loss: 0.1144\n",
      "Epoch: 9/20... Training loss: 0.1143\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1132\n",
      "Epoch: 9/20... Training loss: 0.1135\n",
      "Epoch: 9/20... Training loss: 0.1139\n",
      "Epoch: 9/20... Training loss: 0.1205\n",
      "Epoch: 9/20... Training loss: 0.1100\n",
      "Epoch: 9/20... Training loss: 0.1099\n",
      "Epoch: 9/20... Training loss: 0.1073\n",
      "Epoch: 9/20... Training loss: 0.1104\n",
      "Epoch: 9/20... Training loss: 0.1139\n",
      "Epoch: 9/20... Training loss: 0.1134\n",
      "Epoch: 9/20... Training loss: 0.1138\n",
      "Epoch: 9/20... Training loss: 0.1187\n",
      "Epoch: 9/20... Training loss: 0.1176\n",
      "Epoch: 9/20... Training loss: 0.1139\n",
      "Epoch: 9/20... Training loss: 0.1050\n",
      "Epoch: 9/20... Training loss: 0.1028\n",
      "Epoch: 9/20... Training loss: 0.1049\n",
      "Epoch: 9/20... Training loss: 0.1118\n",
      "Epoch: 9/20... Training loss: 0.1183\n",
      "Epoch: 9/20... Training loss: 0.1095\n",
      "Epoch: 9/20... Training loss: 0.1078\n",
      "Epoch: 9/20... Training loss: 0.1204\n",
      "Epoch: 9/20... Training loss: 0.1079\n",
      "Epoch: 9/20... Training loss: 0.1085\n",
      "Epoch: 9/20... Training loss: 0.1168\n",
      "Epoch: 9/20... Training loss: 0.1136\n",
      "Epoch: 9/20... Training loss: 0.1108\n",
      "Epoch: 9/20... Training loss: 0.1084\n",
      "Epoch: 9/20... Training loss: 0.1075\n",
      "Epoch: 9/20... Training loss: 0.1127\n",
      "Epoch: 9/20... Training loss: 0.1106\n",
      "Epoch: 9/20... Training loss: 0.1150\n",
      "Epoch: 9/20... Training loss: 0.1122\n",
      "Epoch: 9/20... Training loss: 0.1102\n",
      "Epoch: 9/20... Training loss: 0.1108\n",
      "Epoch: 9/20... Training loss: 0.1233\n",
      "Epoch: 9/20... Training loss: 0.1142\n",
      "Epoch: 9/20... Training loss: 0.1114\n",
      "Epoch: 9/20... Training loss: 0.1125\n",
      "Epoch: 9/20... Training loss: 0.1124\n",
      "Epoch: 9/20... Training loss: 0.1116\n",
      "Epoch: 9/20... Training loss: 0.1064\n",
      "Epoch: 9/20... Training loss: 0.1105\n",
      "Epoch: 9/20... Training loss: 0.1176\n",
      "Epoch: 9/20... Training loss: 0.1161\n",
      "Epoch: 9/20... Training loss: 0.1024\n",
      "Epoch: 9/20... Training loss: 0.1081\n",
      "Epoch: 9/20... Training loss: 0.1155\n",
      "Epoch: 9/20... Training loss: 0.1064\n",
      "Epoch: 9/20... Training loss: 0.1032\n",
      "Epoch: 9/20... Training loss: 0.1126\n",
      "Epoch: 9/20... Training loss: 0.1128\n",
      "Epoch: 9/20... Training loss: 0.1062\n",
      "Epoch: 9/20... Training loss: 0.1078\n",
      "Epoch: 9/20... Training loss: 0.1100\n",
      "Epoch: 9/20... Training loss: 0.1075\n",
      "Epoch: 9/20... Training loss: 0.1085\n",
      "Epoch: 9/20... Training loss: 0.1108\n",
      "Epoch: 9/20... Training loss: 0.1130\n",
      "Epoch: 9/20... Training loss: 0.1076\n",
      "Epoch: 9/20... Training loss: 0.1198\n",
      "Epoch: 9/20... Training loss: 0.1186\n",
      "Epoch: 9/20... Training loss: 0.1115\n",
      "Epoch: 9/20... Training loss: 0.1129\n",
      "Epoch: 9/20... Training loss: 0.1106\n",
      "Epoch: 9/20... Training loss: 0.1072\n",
      "Epoch: 9/20... Training loss: 0.1120\n",
      "Epoch: 9/20... Training loss: 0.1060\n",
      "Epoch: 9/20... Training loss: 0.1111\n",
      "Epoch: 9/20... Training loss: 0.1164\n",
      "Epoch: 9/20... Training loss: 0.1219\n",
      "Epoch: 9/20... Training loss: 0.1113\n",
      "Epoch: 9/20... Training loss: 0.1050\n",
      "Epoch: 9/20... Training loss: 0.1112\n",
      "Epoch: 9/20... Training loss: 0.1063\n",
      "Epoch: 9/20... Training loss: 0.1127\n",
      "Epoch: 9/20... Training loss: 0.1131\n",
      "Epoch: 9/20... Training loss: 0.1140\n",
      "Epoch: 9/20... Training loss: 0.1137\n",
      "Epoch: 9/20... Training loss: 0.1125\n",
      "Epoch: 9/20... Training loss: 0.1109\n",
      "Epoch: 9/20... Training loss: 0.1096\n",
      "Epoch: 9/20... Training loss: 0.1125\n",
      "Epoch: 9/20... Training loss: 0.1160\n",
      "Epoch: 9/20... Training loss: 0.1108\n",
      "Epoch: 9/20... Training loss: 0.1138\n",
      "Epoch: 9/20... Training loss: 0.1105\n",
      "Epoch: 9/20... Training loss: 0.1086\n",
      "Epoch: 9/20... Training loss: 0.1171\n",
      "Epoch: 9/20... Training loss: 0.1118\n",
      "Epoch: 9/20... Training loss: 0.1086\n",
      "Epoch: 9/20... Training loss: 0.1133\n",
      "Epoch: 9/20... Training loss: 0.1108\n",
      "Epoch: 9/20... Training loss: 0.1047\n",
      "Epoch: 9/20... Training loss: 0.1047\n",
      "Epoch: 9/20... Training loss: 0.1132\n",
      "Epoch: 9/20... Training loss: 0.1106\n",
      "Epoch: 9/20... Training loss: 0.1114\n",
      "Epoch: 9/20... Training loss: 0.1138\n",
      "Epoch: 9/20... Training loss: 0.1104\n",
      "Epoch: 9/20... Training loss: 0.1146\n",
      "Epoch: 9/20... Training loss: 0.1085\n",
      "Epoch: 9/20... Training loss: 0.1154\n",
      "Epoch: 9/20... Training loss: 0.1136\n",
      "Epoch: 9/20... Training loss: 0.1136\n",
      "Epoch: 9/20... Training loss: 0.1133\n",
      "Epoch: 9/20... Training loss: 0.1160\n",
      "Epoch: 9/20... Training loss: 0.1156\n",
      "Epoch: 9/20... Training loss: 0.1133\n",
      "Epoch: 9/20... Training loss: 0.1124\n",
      "Epoch: 9/20... Training loss: 0.1075\n",
      "Epoch: 9/20... Training loss: 0.1125\n",
      "Epoch: 9/20... Training loss: 0.1175\n",
      "Epoch: 9/20... Training loss: 0.1159\n",
      "Epoch: 9/20... Training loss: 0.1121\n",
      "Epoch: 9/20... Training loss: 0.1126\n",
      "Epoch: 9/20... Training loss: 0.1137\n",
      "Epoch: 9/20... Training loss: 0.1082\n",
      "Epoch: 9/20... Training loss: 0.1174\n",
      "Epoch: 9/20... Training loss: 0.1105\n",
      "Epoch: 9/20... Training loss: 0.1062\n",
      "Epoch: 9/20... Training loss: 0.1103\n",
      "Epoch: 9/20... Training loss: 0.1024\n",
      "Epoch: 9/20... Training loss: 0.1103\n",
      "Epoch: 9/20... Training loss: 0.1155\n",
      "Epoch: 9/20... Training loss: 0.1112\n",
      "Epoch: 9/20... Training loss: 0.1093\n",
      "Epoch: 9/20... Training loss: 0.1132\n",
      "Epoch: 9/20... Training loss: 0.1106\n",
      "Epoch: 9/20... Training loss: 0.1105\n",
      "Epoch: 9/20... Training loss: 0.1137\n",
      "Epoch: 9/20... Training loss: 0.1185\n",
      "Epoch: 9/20... Training loss: 0.1128\n",
      "Epoch: 9/20... Training loss: 0.1095\n",
      "Epoch: 9/20... Training loss: 0.1081\n",
      "Epoch: 9/20... Training loss: 0.1043\n",
      "Epoch: 9/20... Training loss: 0.1109\n",
      "Epoch: 9/20... Training loss: 0.1124\n",
      "Epoch: 9/20... Training loss: 0.1125\n",
      "Epoch: 9/20... Training loss: 0.1148\n",
      "Epoch: 9/20... Training loss: 0.1056\n",
      "Epoch: 9/20... Training loss: 0.1100\n",
      "Epoch: 9/20... Training loss: 0.1128\n",
      "Epoch: 9/20... Training loss: 0.1088\n",
      "Epoch: 9/20... Training loss: 0.1101\n",
      "Epoch: 9/20... Training loss: 0.1189\n",
      "Epoch: 9/20... Training loss: 0.1147\n",
      "Epoch: 9/20... Training loss: 0.1112\n",
      "Epoch: 9/20... Training loss: 0.1137\n",
      "Epoch: 9/20... Training loss: 0.1120\n",
      "Epoch: 9/20... Training loss: 0.1105\n",
      "Epoch: 9/20... Training loss: 0.1136\n",
      "Epoch: 9/20... Training loss: 0.1155\n",
      "Epoch: 9/20... Training loss: 0.1162\n",
      "Epoch: 9/20... Training loss: 0.1151\n",
      "Epoch: 9/20... Training loss: 0.1122\n",
      "Epoch: 9/20... Training loss: 0.1155\n",
      "Epoch: 9/20... Training loss: 0.1133\n",
      "Epoch: 9/20... Training loss: 0.1146\n",
      "Epoch: 9/20... Training loss: 0.1138\n",
      "Epoch: 9/20... Training loss: 0.1098\n",
      "Epoch: 9/20... Training loss: 0.1098\n",
      "Epoch: 9/20... Training loss: 0.1171\n",
      "Epoch: 9/20... Training loss: 0.1163\n",
      "Epoch: 9/20... Training loss: 0.1088\n",
      "Epoch: 9/20... Training loss: 0.1086\n",
      "Epoch: 9/20... Training loss: 0.1118\n",
      "Epoch: 9/20... Training loss: 0.1114\n",
      "Epoch: 9/20... Training loss: 0.1156\n",
      "Epoch: 9/20... Training loss: 0.1100\n",
      "Epoch: 9/20... Training loss: 0.1198\n",
      "Epoch: 9/20... Training loss: 0.1109\n",
      "Epoch: 9/20... Training loss: 0.1180\n",
      "Epoch: 9/20... Training loss: 0.1154\n",
      "Epoch: 9/20... Training loss: 0.1149\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1132\n",
      "Epoch: 9/20... Training loss: 0.1139\n",
      "Epoch: 9/20... Training loss: 0.1097\n",
      "Epoch: 9/20... Training loss: 0.1058\n",
      "Epoch: 9/20... Training loss: 0.1082\n",
      "Epoch: 9/20... Training loss: 0.1111\n",
      "Epoch: 9/20... Training loss: 0.1121\n",
      "Epoch: 9/20... Training loss: 0.1140\n",
      "Epoch: 9/20... Training loss: 0.1136\n",
      "Epoch: 9/20... Training loss: 0.1130\n",
      "Epoch: 9/20... Training loss: 0.1066\n",
      "Epoch: 9/20... Training loss: 0.1107\n",
      "Epoch: 9/20... Training loss: 0.1069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/20... Training loss: 0.1133\n",
      "Epoch: 9/20... Training loss: 0.1120\n",
      "Epoch: 9/20... Training loss: 0.1116\n",
      "Epoch: 9/20... Training loss: 0.1085\n",
      "Epoch: 9/20... Training loss: 0.1132\n",
      "Epoch: 9/20... Training loss: 0.1157\n",
      "Epoch: 9/20... Training loss: 0.1159\n",
      "Epoch: 9/20... Training loss: 0.1091\n",
      "Epoch: 9/20... Training loss: 0.1120\n",
      "Epoch: 9/20... Training loss: 0.1054\n",
      "Epoch: 9/20... Training loss: 0.1123\n",
      "Epoch: 9/20... Training loss: 0.1118\n",
      "Epoch: 9/20... Training loss: 0.1077\n",
      "Epoch: 9/20... Training loss: 0.1092\n",
      "Epoch: 9/20... Training loss: 0.1118\n",
      "Epoch: 9/20... Training loss: 0.1120\n",
      "Epoch: 9/20... Training loss: 0.1102\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1152\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1071\n",
      "Epoch: 9/20... Training loss: 0.1108\n",
      "Epoch: 9/20... Training loss: 0.1141\n",
      "Epoch: 9/20... Training loss: 0.1142\n",
      "Epoch: 9/20... Training loss: 0.1101\n",
      "Epoch: 9/20... Training loss: 0.1125\n",
      "Epoch: 9/20... Training loss: 0.1116\n",
      "Epoch: 9/20... Training loss: 0.1169\n",
      "Epoch: 9/20... Training loss: 0.1132\n",
      "Epoch: 9/20... Training loss: 0.1083\n",
      "Epoch: 9/20... Training loss: 0.1211\n",
      "Epoch: 9/20... Training loss: 0.1125\n",
      "Epoch: 9/20... Training loss: 0.1173\n",
      "Epoch: 9/20... Training loss: 0.1136\n",
      "Epoch: 9/20... Training loss: 0.1093\n",
      "Epoch: 9/20... Training loss: 0.1116\n",
      "Epoch: 10/20... Training loss: 0.1085\n",
      "Epoch: 10/20... Training loss: 0.1072\n",
      "Epoch: 10/20... Training loss: 0.1098\n",
      "Epoch: 10/20... Training loss: 0.1108\n",
      "Epoch: 10/20... Training loss: 0.1092\n",
      "Epoch: 10/20... Training loss: 0.1129\n",
      "Epoch: 10/20... Training loss: 0.1087\n",
      "Epoch: 10/20... Training loss: 0.1127\n",
      "Epoch: 10/20... Training loss: 0.1094\n",
      "Epoch: 10/20... Training loss: 0.1075\n",
      "Epoch: 10/20... Training loss: 0.1061\n",
      "Epoch: 10/20... Training loss: 0.1143\n",
      "Epoch: 10/20... Training loss: 0.1111\n",
      "Epoch: 10/20... Training loss: 0.1126\n",
      "Epoch: 10/20... Training loss: 0.1088\n",
      "Epoch: 10/20... Training loss: 0.1145\n",
      "Epoch: 10/20... Training loss: 0.1050\n",
      "Epoch: 10/20... Training loss: 0.1083\n",
      "Epoch: 10/20... Training loss: 0.1196\n",
      "Epoch: 10/20... Training loss: 0.1116\n",
      "Epoch: 10/20... Training loss: 0.1069\n",
      "Epoch: 10/20... Training loss: 0.1122\n",
      "Epoch: 10/20... Training loss: 0.1097\n",
      "Epoch: 10/20... Training loss: 0.1155\n",
      "Epoch: 10/20... Training loss: 0.1130\n",
      "Epoch: 10/20... Training loss: 0.1138\n",
      "Epoch: 10/20... Training loss: 0.1131\n",
      "Epoch: 10/20... Training loss: 0.1084\n",
      "Epoch: 10/20... Training loss: 0.1109\n",
      "Epoch: 10/20... Training loss: 0.1083\n",
      "Epoch: 10/20... Training loss: 0.1102\n",
      "Epoch: 10/20... Training loss: 0.1050\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1066\n",
      "Epoch: 10/20... Training loss: 0.1104\n",
      "Epoch: 10/20... Training loss: 0.1100\n",
      "Epoch: 10/20... Training loss: 0.1149\n",
      "Epoch: 10/20... Training loss: 0.1060\n",
      "Epoch: 10/20... Training loss: 0.1109\n",
      "Epoch: 10/20... Training loss: 0.1109\n",
      "Epoch: 10/20... Training loss: 0.1077\n",
      "Epoch: 10/20... Training loss: 0.1104\n",
      "Epoch: 10/20... Training loss: 0.1060\n",
      "Epoch: 10/20... Training loss: 0.1119\n",
      "Epoch: 10/20... Training loss: 0.1050\n",
      "Epoch: 10/20... Training loss: 0.1128\n",
      "Epoch: 10/20... Training loss: 0.1122\n",
      "Epoch: 10/20... Training loss: 0.1146\n",
      "Epoch: 10/20... Training loss: 0.1139\n",
      "Epoch: 10/20... Training loss: 0.1126\n",
      "Epoch: 10/20... Training loss: 0.1083\n",
      "Epoch: 10/20... Training loss: 0.1072\n",
      "Epoch: 10/20... Training loss: 0.1107\n",
      "Epoch: 10/20... Training loss: 0.1120\n",
      "Epoch: 10/20... Training loss: 0.1045\n",
      "Epoch: 10/20... Training loss: 0.1078\n",
      "Epoch: 10/20... Training loss: 0.1042\n",
      "Epoch: 10/20... Training loss: 0.1065\n",
      "Epoch: 10/20... Training loss: 0.1041\n",
      "Epoch: 10/20... Training loss: 0.1047\n",
      "Epoch: 10/20... Training loss: 0.1045\n",
      "Epoch: 10/20... Training loss: 0.1099\n",
      "Epoch: 10/20... Training loss: 0.1156\n",
      "Epoch: 10/20... Training loss: 0.1155\n",
      "Epoch: 10/20... Training loss: 0.1147\n",
      "Epoch: 10/20... Training loss: 0.1103\n",
      "Epoch: 10/20... Training loss: 0.1134\n",
      "Epoch: 10/20... Training loss: 0.1120\n",
      "Epoch: 10/20... Training loss: 0.1088\n",
      "Epoch: 10/20... Training loss: 0.1153\n",
      "Epoch: 10/20... Training loss: 0.1102\n",
      "Epoch: 10/20... Training loss: 0.1096\n",
      "Epoch: 10/20... Training loss: 0.1125\n",
      "Epoch: 10/20... Training loss: 0.1126\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1117\n",
      "Epoch: 10/20... Training loss: 0.1116\n",
      "Epoch: 10/20... Training loss: 0.1123\n",
      "Epoch: 10/20... Training loss: 0.1187\n",
      "Epoch: 10/20... Training loss: 0.1086\n",
      "Epoch: 10/20... Training loss: 0.1083\n",
      "Epoch: 10/20... Training loss: 0.1059\n",
      "Epoch: 10/20... Training loss: 0.1087\n",
      "Epoch: 10/20... Training loss: 0.1121\n",
      "Epoch: 10/20... Training loss: 0.1117\n",
      "Epoch: 10/20... Training loss: 0.1120\n",
      "Epoch: 10/20... Training loss: 0.1168\n",
      "Epoch: 10/20... Training loss: 0.1158\n",
      "Epoch: 10/20... Training loss: 0.1124\n",
      "Epoch: 10/20... Training loss: 0.1034\n",
      "Epoch: 10/20... Training loss: 0.1013\n",
      "Epoch: 10/20... Training loss: 0.1031\n",
      "Epoch: 10/20... Training loss: 0.1102\n",
      "Epoch: 10/20... Training loss: 0.1167\n",
      "Epoch: 10/20... Training loss: 0.1077\n",
      "Epoch: 10/20... Training loss: 0.1066\n",
      "Epoch: 10/20... Training loss: 0.1187\n",
      "Epoch: 10/20... Training loss: 0.1060\n",
      "Epoch: 10/20... Training loss: 0.1067\n",
      "Epoch: 10/20... Training loss: 0.1152\n",
      "Epoch: 10/20... Training loss: 0.1115\n",
      "Epoch: 10/20... Training loss: 0.1092\n",
      "Epoch: 10/20... Training loss: 0.1069\n",
      "Epoch: 10/20... Training loss: 0.1053\n",
      "Epoch: 10/20... Training loss: 0.1111\n",
      "Epoch: 10/20... Training loss: 0.1093\n",
      "Epoch: 10/20... Training loss: 0.1132\n",
      "Epoch: 10/20... Training loss: 0.1104\n",
      "Epoch: 10/20... Training loss: 0.1088\n",
      "Epoch: 10/20... Training loss: 0.1088\n",
      "Epoch: 10/20... Training loss: 0.1214\n",
      "Epoch: 10/20... Training loss: 0.1127\n",
      "Epoch: 10/20... Training loss: 0.1096\n",
      "Epoch: 10/20... Training loss: 0.1106\n",
      "Epoch: 10/20... Training loss: 0.1108\n",
      "Epoch: 10/20... Training loss: 0.1097\n",
      "Epoch: 10/20... Training loss: 0.1046\n",
      "Epoch: 10/20... Training loss: 0.1091\n",
      "Epoch: 10/20... Training loss: 0.1161\n",
      "Epoch: 10/20... Training loss: 0.1145\n",
      "Epoch: 10/20... Training loss: 0.1011\n",
      "Epoch: 10/20... Training loss: 0.1063\n",
      "Epoch: 10/20... Training loss: 0.1136\n",
      "Epoch: 10/20... Training loss: 0.1051\n",
      "Epoch: 10/20... Training loss: 0.1019\n",
      "Epoch: 10/20... Training loss: 0.1111\n",
      "Epoch: 10/20... Training loss: 0.1113\n",
      "Epoch: 10/20... Training loss: 0.1045\n",
      "Epoch: 10/20... Training loss: 0.1065\n",
      "Epoch: 10/20... Training loss: 0.1087\n",
      "Epoch: 10/20... Training loss: 0.1059\n",
      "Epoch: 10/20... Training loss: 0.1070\n",
      "Epoch: 10/20... Training loss: 0.1095\n",
      "Epoch: 10/20... Training loss: 0.1115\n",
      "Epoch: 10/20... Training loss: 0.1062\n",
      "Epoch: 10/20... Training loss: 0.1182\n",
      "Epoch: 10/20... Training loss: 0.1170\n",
      "Epoch: 10/20... Training loss: 0.1099\n",
      "Epoch: 10/20... Training loss: 0.1113\n",
      "Epoch: 10/20... Training loss: 0.1091\n",
      "Epoch: 10/20... Training loss: 0.1055\n",
      "Epoch: 10/20... Training loss: 0.1105\n",
      "Epoch: 10/20... Training loss: 0.1042\n",
      "Epoch: 10/20... Training loss: 0.1097\n",
      "Epoch: 10/20... Training loss: 0.1147\n",
      "Epoch: 10/20... Training loss: 0.1203\n",
      "Epoch: 10/20... Training loss: 0.1096\n",
      "Epoch: 10/20... Training loss: 0.1033\n",
      "Epoch: 10/20... Training loss: 0.1097\n",
      "Epoch: 10/20... Training loss: 0.1049\n",
      "Epoch: 10/20... Training loss: 0.1110\n",
      "Epoch: 10/20... Training loss: 0.1112\n",
      "Epoch: 10/20... Training loss: 0.1124\n",
      "Epoch: 10/20... Training loss: 0.1121\n",
      "Epoch: 10/20... Training loss: 0.1108\n",
      "Epoch: 10/20... Training loss: 0.1095\n",
      "Epoch: 10/20... Training loss: 0.1079\n",
      "Epoch: 10/20... Training loss: 0.1110\n",
      "Epoch: 10/20... Training loss: 0.1143\n",
      "Epoch: 10/20... Training loss: 0.1091\n",
      "Epoch: 10/20... Training loss: 0.1121\n",
      "Epoch: 10/20... Training loss: 0.1091\n",
      "Epoch: 10/20... Training loss: 0.1069\n",
      "Epoch: 10/20... Training loss: 0.1154\n",
      "Epoch: 10/20... Training loss: 0.1103\n",
      "Epoch: 10/20... Training loss: 0.1071\n",
      "Epoch: 10/20... Training loss: 0.1117\n",
      "Epoch: 10/20... Training loss: 0.1093\n",
      "Epoch: 10/20... Training loss: 0.1033\n",
      "Epoch: 10/20... Training loss: 0.1033\n",
      "Epoch: 10/20... Training loss: 0.1116\n",
      "Epoch: 10/20... Training loss: 0.1091\n",
      "Epoch: 10/20... Training loss: 0.1098\n",
      "Epoch: 10/20... Training loss: 0.1126\n",
      "Epoch: 10/20... Training loss: 0.1088\n",
      "Epoch: 10/20... Training loss: 0.1129\n",
      "Epoch: 10/20... Training loss: 0.1069\n",
      "Epoch: 10/20... Training loss: 0.1138\n",
      "Epoch: 10/20... Training loss: 0.1117\n",
      "Epoch: 10/20... Training loss: 0.1121\n",
      "Epoch: 10/20... Training loss: 0.1115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/20... Training loss: 0.1141\n",
      "Epoch: 10/20... Training loss: 0.1138\n",
      "Epoch: 10/20... Training loss: 0.1117\n",
      "Epoch: 10/20... Training loss: 0.1110\n",
      "Epoch: 10/20... Training loss: 0.1056\n",
      "Epoch: 10/20... Training loss: 0.1106\n",
      "Epoch: 10/20... Training loss: 0.1160\n",
      "Epoch: 10/20... Training loss: 0.1142\n",
      "Epoch: 10/20... Training loss: 0.1103\n",
      "Epoch: 10/20... Training loss: 0.1110\n",
      "Epoch: 10/20... Training loss: 0.1120\n",
      "Epoch: 10/20... Training loss: 0.1065\n",
      "Epoch: 10/20... Training loss: 0.1155\n",
      "Epoch: 10/20... Training loss: 0.1090\n",
      "Epoch: 10/20... Training loss: 0.1047\n",
      "Epoch: 10/20... Training loss: 0.1088\n",
      "Epoch: 10/20... Training loss: 0.1010\n",
      "Epoch: 10/20... Training loss: 0.1091\n",
      "Epoch: 10/20... Training loss: 0.1139\n",
      "Epoch: 10/20... Training loss: 0.1096\n",
      "Epoch: 10/20... Training loss: 0.1077\n",
      "Epoch: 10/20... Training loss: 0.1118\n",
      "Epoch: 10/20... Training loss: 0.1090\n",
      "Epoch: 10/20... Training loss: 0.1090\n",
      "Epoch: 10/20... Training loss: 0.1124\n",
      "Epoch: 10/20... Training loss: 0.1164\n",
      "Epoch: 10/20... Training loss: 0.1112\n",
      "Epoch: 10/20... Training loss: 0.1079\n",
      "Epoch: 10/20... Training loss: 0.1064\n",
      "Epoch: 10/20... Training loss: 0.1028\n",
      "Epoch: 10/20... Training loss: 0.1091\n",
      "Epoch: 10/20... Training loss: 0.1107\n",
      "Epoch: 10/20... Training loss: 0.1108\n",
      "Epoch: 10/20... Training loss: 0.1132\n",
      "Epoch: 10/20... Training loss: 0.1041\n",
      "Epoch: 10/20... Training loss: 0.1083\n",
      "Epoch: 10/20... Training loss: 0.1113\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1088\n",
      "Epoch: 10/20... Training loss: 0.1173\n",
      "Epoch: 10/20... Training loss: 0.1133\n",
      "Epoch: 10/20... Training loss: 0.1097\n",
      "Epoch: 10/20... Training loss: 0.1122\n",
      "Epoch: 10/20... Training loss: 0.1107\n",
      "Epoch: 10/20... Training loss: 0.1088\n",
      "Epoch: 10/20... Training loss: 0.1117\n",
      "Epoch: 10/20... Training loss: 0.1139\n",
      "Epoch: 10/20... Training loss: 0.1147\n",
      "Epoch: 10/20... Training loss: 0.1138\n",
      "Epoch: 10/20... Training loss: 0.1105\n",
      "Epoch: 10/20... Training loss: 0.1141\n",
      "Epoch: 10/20... Training loss: 0.1118\n",
      "Epoch: 10/20... Training loss: 0.1131\n",
      "Epoch: 10/20... Training loss: 0.1121\n",
      "Epoch: 10/20... Training loss: 0.1084\n",
      "Epoch: 10/20... Training loss: 0.1084\n",
      "Epoch: 10/20... Training loss: 0.1154\n",
      "Epoch: 10/20... Training loss: 0.1148\n",
      "Epoch: 10/20... Training loss: 0.1073\n",
      "Epoch: 10/20... Training loss: 0.1071\n",
      "Epoch: 10/20... Training loss: 0.1106\n",
      "Epoch: 10/20... Training loss: 0.1099\n",
      "Epoch: 10/20... Training loss: 0.1139\n",
      "Epoch: 10/20... Training loss: 0.1087\n",
      "Epoch: 10/20... Training loss: 0.1186\n",
      "Epoch: 10/20... Training loss: 0.1093\n",
      "Epoch: 10/20... Training loss: 0.1165\n",
      "Epoch: 10/20... Training loss: 0.1138\n",
      "Epoch: 10/20... Training loss: 0.1133\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1117\n",
      "Epoch: 10/20... Training loss: 0.1124\n",
      "Epoch: 10/20... Training loss: 0.1082\n",
      "Epoch: 10/20... Training loss: 0.1044\n",
      "Epoch: 10/20... Training loss: 0.1069\n",
      "Epoch: 10/20... Training loss: 0.1095\n",
      "Epoch: 10/20... Training loss: 0.1104\n",
      "Epoch: 10/20... Training loss: 0.1126\n",
      "Epoch: 10/20... Training loss: 0.1119\n",
      "Epoch: 10/20... Training loss: 0.1114\n",
      "Epoch: 10/20... Training loss: 0.1051\n",
      "Epoch: 10/20... Training loss: 0.1091\n",
      "Epoch: 10/20... Training loss: 0.1054\n",
      "Epoch: 10/20... Training loss: 0.1118\n",
      "Epoch: 10/20... Training loss: 0.1104\n",
      "Epoch: 10/20... Training loss: 0.1101\n",
      "Epoch: 10/20... Training loss: 0.1071\n",
      "Epoch: 10/20... Training loss: 0.1117\n",
      "Epoch: 10/20... Training loss: 0.1141\n",
      "Epoch: 10/20... Training loss: 0.1143\n",
      "Epoch: 10/20... Training loss: 0.1077\n",
      "Epoch: 10/20... Training loss: 0.1104\n",
      "Epoch: 10/20... Training loss: 0.1038\n",
      "Epoch: 10/20... Training loss: 0.1109\n",
      "Epoch: 10/20... Training loss: 0.1101\n",
      "Epoch: 10/20... Training loss: 0.1063\n",
      "Epoch: 10/20... Training loss: 0.1076\n",
      "Epoch: 10/20... Training loss: 0.1104\n",
      "Epoch: 10/20... Training loss: 0.1105\n",
      "Epoch: 10/20... Training loss: 0.1088\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1138\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1057\n",
      "Epoch: 10/20... Training loss: 0.1095\n",
      "Epoch: 10/20... Training loss: 0.1124\n",
      "Epoch: 10/20... Training loss: 0.1129\n",
      "Epoch: 10/20... Training loss: 0.1091\n",
      "Epoch: 10/20... Training loss: 0.1111\n",
      "Epoch: 10/20... Training loss: 0.1103\n",
      "Epoch: 10/20... Training loss: 0.1153\n",
      "Epoch: 10/20... Training loss: 0.1117\n",
      "Epoch: 10/20... Training loss: 0.1071\n",
      "Epoch: 10/20... Training loss: 0.1192\n",
      "Epoch: 10/20... Training loss: 0.1111\n",
      "Epoch: 10/20... Training loss: 0.1157\n",
      "Epoch: 10/20... Training loss: 0.1122\n",
      "Epoch: 10/20... Training loss: 0.1078\n",
      "Epoch: 10/20... Training loss: 0.1103\n",
      "Epoch: 11/20... Training loss: 0.1069\n",
      "Epoch: 11/20... Training loss: 0.1061\n",
      "Epoch: 11/20... Training loss: 0.1085\n",
      "Epoch: 11/20... Training loss: 0.1094\n",
      "Epoch: 11/20... Training loss: 0.1079\n",
      "Epoch: 11/20... Training loss: 0.1113\n",
      "Epoch: 11/20... Training loss: 0.1073\n",
      "Epoch: 11/20... Training loss: 0.1113\n",
      "Epoch: 11/20... Training loss: 0.1080\n",
      "Epoch: 11/20... Training loss: 0.1062\n",
      "Epoch: 11/20... Training loss: 0.1049\n",
      "Epoch: 11/20... Training loss: 0.1129\n",
      "Epoch: 11/20... Training loss: 0.1096\n",
      "Epoch: 11/20... Training loss: 0.1114\n",
      "Epoch: 11/20... Training loss: 0.1075\n",
      "Epoch: 11/20... Training loss: 0.1130\n",
      "Epoch: 11/20... Training loss: 0.1037\n",
      "Epoch: 11/20... Training loss: 0.1070\n",
      "Epoch: 11/20... Training loss: 0.1180\n",
      "Epoch: 11/20... Training loss: 0.1104\n",
      "Epoch: 11/20... Training loss: 0.1056\n",
      "Epoch: 11/20... Training loss: 0.1108\n",
      "Epoch: 11/20... Training loss: 0.1082\n",
      "Epoch: 11/20... Training loss: 0.1138\n",
      "Epoch: 11/20... Training loss: 0.1114\n",
      "Epoch: 11/20... Training loss: 0.1126\n",
      "Epoch: 11/20... Training loss: 0.1116\n",
      "Epoch: 11/20... Training loss: 0.1069\n",
      "Epoch: 11/20... Training loss: 0.1095\n",
      "Epoch: 11/20... Training loss: 0.1073\n",
      "Epoch: 11/20... Training loss: 0.1088\n",
      "Epoch: 11/20... Training loss: 0.1037\n",
      "Epoch: 11/20... Training loss: 0.1062\n",
      "Epoch: 11/20... Training loss: 0.1053\n",
      "Epoch: 11/20... Training loss: 0.1091\n",
      "Epoch: 11/20... Training loss: 0.1088\n",
      "Epoch: 11/20... Training loss: 0.1137\n",
      "Epoch: 11/20... Training loss: 0.1045\n",
      "Epoch: 11/20... Training loss: 0.1096\n",
      "Epoch: 11/20... Training loss: 0.1095\n",
      "Epoch: 11/20... Training loss: 0.1065\n",
      "Epoch: 11/20... Training loss: 0.1090\n",
      "Epoch: 11/20... Training loss: 0.1046\n",
      "Epoch: 11/20... Training loss: 0.1103\n",
      "Epoch: 11/20... Training loss: 0.1037\n",
      "Epoch: 11/20... Training loss: 0.1112\n",
      "Epoch: 11/20... Training loss: 0.1109\n",
      "Epoch: 11/20... Training loss: 0.1130\n",
      "Epoch: 11/20... Training loss: 0.1124\n",
      "Epoch: 11/20... Training loss: 0.1110\n",
      "Epoch: 11/20... Training loss: 0.1067\n",
      "Epoch: 11/20... Training loss: 0.1057\n",
      "Epoch: 11/20... Training loss: 0.1092\n",
      "Epoch: 11/20... Training loss: 0.1105\n",
      "Epoch: 11/20... Training loss: 0.1031\n",
      "Epoch: 11/20... Training loss: 0.1065\n",
      "Epoch: 11/20... Training loss: 0.1029\n",
      "Epoch: 11/20... Training loss: 0.1050\n",
      "Epoch: 11/20... Training loss: 0.1028\n",
      "Epoch: 11/20... Training loss: 0.1033\n",
      "Epoch: 11/20... Training loss: 0.1032\n",
      "Epoch: 11/20... Training loss: 0.1084\n",
      "Epoch: 11/20... Training loss: 0.1140\n",
      "Epoch: 11/20... Training loss: 0.1137\n",
      "Epoch: 11/20... Training loss: 0.1133\n",
      "Epoch: 11/20... Training loss: 0.1089\n",
      "Epoch: 11/20... Training loss: 0.1118\n",
      "Epoch: 11/20... Training loss: 0.1106\n",
      "Epoch: 11/20... Training loss: 0.1076\n",
      "Epoch: 11/20... Training loss: 0.1139\n",
      "Epoch: 11/20... Training loss: 0.1089\n",
      "Epoch: 11/20... Training loss: 0.1082\n",
      "Epoch: 11/20... Training loss: 0.1109\n",
      "Epoch: 11/20... Training loss: 0.1113\n",
      "Epoch: 11/20... Training loss: 0.1061\n",
      "Epoch: 11/20... Training loss: 0.1104\n",
      "Epoch: 11/20... Training loss: 0.1099\n",
      "Epoch: 11/20... Training loss: 0.1109\n",
      "Epoch: 11/20... Training loss: 0.1173\n",
      "Epoch: 11/20... Training loss: 0.1072\n",
      "Epoch: 11/20... Training loss: 0.1069\n",
      "Epoch: 11/20... Training loss: 0.1046\n",
      "Epoch: 11/20... Training loss: 0.1074\n",
      "Epoch: 11/20... Training loss: 0.1107\n",
      "Epoch: 11/20... Training loss: 0.1103\n",
      "Epoch: 11/20... Training loss: 0.1105\n",
      "Epoch: 11/20... Training loss: 0.1154\n",
      "Epoch: 11/20... Training loss: 0.1143\n",
      "Epoch: 11/20... Training loss: 0.1109\n",
      "Epoch: 11/20... Training loss: 0.1021\n",
      "Epoch: 11/20... Training loss: 0.0998\n",
      "Epoch: 11/20... Training loss: 0.1017\n",
      "Epoch: 11/20... Training loss: 0.1087\n",
      "Epoch: 11/20... Training loss: 0.1152\n",
      "Epoch: 11/20... Training loss: 0.1062\n",
      "Epoch: 11/20... Training loss: 0.1054\n",
      "Epoch: 11/20... Training loss: 0.1171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/20... Training loss: 0.1045\n",
      "Epoch: 11/20... Training loss: 0.1053\n",
      "Epoch: 11/20... Training loss: 0.1136\n",
      "Epoch: 11/20... Training loss: 0.1100\n",
      "Epoch: 11/20... Training loss: 0.1079\n",
      "Epoch: 11/20... Training loss: 0.1056\n",
      "Epoch: 11/20... Training loss: 0.1038\n",
      "Epoch: 11/20... Training loss: 0.1098\n",
      "Epoch: 11/20... Training loss: 0.1078\n",
      "Epoch: 11/20... Training loss: 0.1118\n",
      "Epoch: 11/20... Training loss: 0.1091\n",
      "Epoch: 11/20... Training loss: 0.1073\n",
      "Epoch: 11/20... Training loss: 0.1072\n",
      "Epoch: 11/20... Training loss: 0.1201\n",
      "Epoch: 11/20... Training loss: 0.1116\n",
      "Epoch: 11/20... Training loss: 0.1080\n",
      "Epoch: 11/20... Training loss: 0.1092\n",
      "Epoch: 11/20... Training loss: 0.1094\n",
      "Epoch: 11/20... Training loss: 0.1082\n",
      "Epoch: 11/20... Training loss: 0.1034\n",
      "Epoch: 11/20... Training loss: 0.1078\n",
      "Epoch: 11/20... Training loss: 0.1145\n",
      "Epoch: 11/20... Training loss: 0.1131\n",
      "Epoch: 11/20... Training loss: 0.1000\n",
      "Epoch: 11/20... Training loss: 0.1050\n",
      "Epoch: 11/20... Training loss: 0.1120\n",
      "Epoch: 11/20... Training loss: 0.1038\n",
      "Epoch: 11/20... Training loss: 0.1008\n",
      "Epoch: 11/20... Training loss: 0.1098\n",
      "Epoch: 11/20... Training loss: 0.1098\n",
      "Epoch: 11/20... Training loss: 0.1032\n",
      "Epoch: 11/20... Training loss: 0.1054\n",
      "Epoch: 11/20... Training loss: 0.1075\n",
      "Epoch: 11/20... Training loss: 0.1047\n",
      "Epoch: 11/20... Training loss: 0.1059\n",
      "Epoch: 11/20... Training loss: 0.1083\n",
      "Epoch: 11/20... Training loss: 0.1103\n",
      "Epoch: 11/20... Training loss: 0.1050\n",
      "Epoch: 11/20... Training loss: 0.1169\n",
      "Epoch: 11/20... Training loss: 0.1155\n",
      "Epoch: 11/20... Training loss: 0.1087\n",
      "Epoch: 11/20... Training loss: 0.1099\n",
      "Epoch: 11/20... Training loss: 0.1078\n",
      "Epoch: 11/20... Training loss: 0.1040\n",
      "Epoch: 11/20... Training loss: 0.1090\n",
      "Epoch: 11/20... Training loss: 0.1029\n",
      "Epoch: 11/20... Training loss: 0.1084\n",
      "Epoch: 11/20... Training loss: 0.1131\n",
      "Epoch: 11/20... Training loss: 0.1188\n",
      "Epoch: 11/20... Training loss: 0.1083\n",
      "Epoch: 11/20... Training loss: 0.1020\n",
      "Epoch: 11/20... Training loss: 0.1085\n",
      "Epoch: 11/20... Training loss: 0.1038\n",
      "Epoch: 11/20... Training loss: 0.1098\n",
      "Epoch: 11/20... Training loss: 0.1097\n",
      "Epoch: 11/20... Training loss: 0.1111\n",
      "Epoch: 11/20... Training loss: 0.1107\n",
      "Epoch: 11/20... Training loss: 0.1095\n",
      "Epoch: 11/20... Training loss: 0.1084\n",
      "Epoch: 11/20... Training loss: 0.1067\n",
      "Epoch: 11/20... Training loss: 0.1097\n",
      "Epoch: 11/20... Training loss: 0.1131\n",
      "Epoch: 11/20... Training loss: 0.1079\n",
      "Epoch: 11/20... Training loss: 0.1107\n",
      "Epoch: 11/20... Training loss: 0.1080\n",
      "Epoch: 11/20... Training loss: 0.1056\n",
      "Epoch: 11/20... Training loss: 0.1140\n",
      "Epoch: 11/20... Training loss: 0.1089\n",
      "Epoch: 11/20... Training loss: 0.1058\n",
      "Epoch: 11/20... Training loss: 0.1105\n",
      "Epoch: 11/20... Training loss: 0.1081\n",
      "Epoch: 11/20... Training loss: 0.1022\n",
      "Epoch: 11/20... Training loss: 0.1022\n",
      "Epoch: 11/20... Training loss: 0.1104\n",
      "Epoch: 11/20... Training loss: 0.1079\n",
      "Epoch: 11/20... Training loss: 0.1085\n",
      "Epoch: 11/20... Training loss: 0.1114\n",
      "Epoch: 11/20... Training loss: 0.1075\n",
      "Epoch: 11/20... Training loss: 0.1117\n",
      "Epoch: 11/20... Training loss: 0.1056\n",
      "Epoch: 11/20... Training loss: 0.1124\n",
      "Epoch: 11/20... Training loss: 0.1102\n",
      "Epoch: 11/20... Training loss: 0.1109\n",
      "Epoch: 11/20... Training loss: 0.1101\n",
      "Epoch: 11/20... Training loss: 0.1125\n",
      "Epoch: 11/20... Training loss: 0.1124\n",
      "Epoch: 11/20... Training loss: 0.1104\n",
      "Epoch: 11/20... Training loss: 0.1097\n",
      "Epoch: 11/20... Training loss: 0.1042\n",
      "Epoch: 11/20... Training loss: 0.1092\n",
      "Epoch: 11/20... Training loss: 0.1148\n",
      "Epoch: 11/20... Training loss: 0.1127\n",
      "Epoch: 11/20... Training loss: 0.1088\n",
      "Epoch: 11/20... Training loss: 0.1099\n",
      "Epoch: 11/20... Training loss: 0.1105\n",
      "Epoch: 11/20... Training loss: 0.1051\n",
      "Epoch: 11/20... Training loss: 0.1141\n",
      "Epoch: 11/20... Training loss: 0.1078\n",
      "Epoch: 11/20... Training loss: 0.1034\n",
      "Epoch: 11/20... Training loss: 0.1076\n",
      "Epoch: 11/20... Training loss: 0.1000\n",
      "Epoch: 11/20... Training loss: 0.1079\n",
      "Epoch: 11/20... Training loss: 0.1123\n",
      "Epoch: 11/20... Training loss: 0.1083\n",
      "Epoch: 11/20... Training loss: 0.1066\n",
      "Epoch: 11/20... Training loss: 0.1101\n",
      "Epoch: 11/20... Training loss: 0.1079\n",
      "Epoch: 11/20... Training loss: 0.1080\n",
      "Epoch: 11/20... Training loss: 0.1109\n",
      "Epoch: 11/20... Training loss: 0.1147\n",
      "Epoch: 11/20... Training loss: 0.1099\n",
      "Epoch: 11/20... Training loss: 0.1064\n",
      "Epoch: 11/20... Training loss: 0.1051\n",
      "Epoch: 11/20... Training loss: 0.1017\n",
      "Epoch: 11/20... Training loss: 0.1078\n",
      "Epoch: 11/20... Training loss: 0.1095\n",
      "Epoch: 11/20... Training loss: 0.1096\n",
      "Epoch: 11/20... Training loss: 0.1117\n",
      "Epoch: 11/20... Training loss: 0.1032\n",
      "Epoch: 11/20... Training loss: 0.1070\n",
      "Epoch: 11/20... Training loss: 0.1100\n",
      "Epoch: 11/20... Training loss: 0.1062\n",
      "Epoch: 11/20... Training loss: 0.1075\n",
      "Epoch: 11/20... Training loss: 0.1159\n",
      "Epoch: 11/20... Training loss: 0.1121\n",
      "Epoch: 11/20... Training loss: 0.1083\n",
      "Epoch: 11/20... Training loss: 0.1109\n",
      "Epoch: 11/20... Training loss: 0.1095\n",
      "Epoch: 11/20... Training loss: 0.1073\n",
      "Epoch: 11/20... Training loss: 0.1102\n",
      "Epoch: 11/20... Training loss: 0.1124\n",
      "Epoch: 11/20... Training loss: 0.1133\n",
      "Epoch: 11/20... Training loss: 0.1129\n",
      "Epoch: 11/20... Training loss: 0.1091\n",
      "Epoch: 11/20... Training loss: 0.1129\n",
      "Epoch: 11/20... Training loss: 0.1105\n",
      "Epoch: 11/20... Training loss: 0.1115\n",
      "Epoch: 11/20... Training loss: 0.1106\n",
      "Epoch: 11/20... Training loss: 0.1072\n",
      "Epoch: 11/20... Training loss: 0.1073\n",
      "Epoch: 11/20... Training loss: 0.1141\n",
      "Epoch: 11/20... Training loss: 0.1134\n",
      "Epoch: 11/20... Training loss: 0.1058\n",
      "Epoch: 11/20... Training loss: 0.1061\n",
      "Epoch: 11/20... Training loss: 0.1092\n",
      "Epoch: 11/20... Training loss: 0.1085\n",
      "Epoch: 11/20... Training loss: 0.1125\n",
      "Epoch: 11/20... Training loss: 0.1075\n",
      "Epoch: 11/20... Training loss: 0.1173\n",
      "Epoch: 11/20... Training loss: 0.1080\n",
      "Epoch: 11/20... Training loss: 0.1154\n",
      "Epoch: 11/20... Training loss: 0.1126\n",
      "Epoch: 11/20... Training loss: 0.1118\n",
      "Epoch: 11/20... Training loss: 0.1061\n",
      "Epoch: 11/20... Training loss: 0.1106\n",
      "Epoch: 11/20... Training loss: 0.1111\n",
      "Epoch: 11/20... Training loss: 0.1068\n",
      "Epoch: 11/20... Training loss: 0.1034\n",
      "Epoch: 11/20... Training loss: 0.1056\n",
      "Epoch: 11/20... Training loss: 0.1087\n",
      "Epoch: 11/20... Training loss: 0.1092\n",
      "Epoch: 11/20... Training loss: 0.1114\n",
      "Epoch: 11/20... Training loss: 0.1106\n",
      "Epoch: 11/20... Training loss: 0.1102\n",
      "Epoch: 11/20... Training loss: 0.1040\n",
      "Epoch: 11/20... Training loss: 0.1078\n",
      "Epoch: 11/20... Training loss: 0.1040\n",
      "Epoch: 11/20... Training loss: 0.1105\n",
      "Epoch: 11/20... Training loss: 0.1091\n",
      "Epoch: 11/20... Training loss: 0.1086\n",
      "Epoch: 11/20... Training loss: 0.1060\n",
      "Epoch: 11/20... Training loss: 0.1105\n",
      "Epoch: 11/20... Training loss: 0.1126\n",
      "Epoch: 11/20... Training loss: 0.1130\n",
      "Epoch: 11/20... Training loss: 0.1064\n",
      "Epoch: 11/20... Training loss: 0.1089\n",
      "Epoch: 11/20... Training loss: 0.1026\n",
      "Epoch: 11/20... Training loss: 0.1095\n",
      "Epoch: 11/20... Training loss: 0.1088\n",
      "Epoch: 11/20... Training loss: 0.1050\n",
      "Epoch: 11/20... Training loss: 0.1061\n",
      "Epoch: 11/20... Training loss: 0.1092\n",
      "Epoch: 11/20... Training loss: 0.1094\n",
      "Epoch: 11/20... Training loss: 0.1074\n",
      "Epoch: 11/20... Training loss: 0.1061\n",
      "Epoch: 11/20... Training loss: 0.1125\n",
      "Epoch: 11/20... Training loss: 0.1061\n",
      "Epoch: 11/20... Training loss: 0.1047\n",
      "Epoch: 11/20... Training loss: 0.1082\n",
      "Epoch: 11/20... Training loss: 0.1109\n",
      "Epoch: 11/20... Training loss: 0.1118\n",
      "Epoch: 11/20... Training loss: 0.1081\n",
      "Epoch: 11/20... Training loss: 0.1094\n",
      "Epoch: 11/20... Training loss: 0.1093\n",
      "Epoch: 11/20... Training loss: 0.1139\n",
      "Epoch: 11/20... Training loss: 0.1103\n",
      "Epoch: 11/20... Training loss: 0.1061\n",
      "Epoch: 11/20... Training loss: 0.1177\n",
      "Epoch: 11/20... Training loss: 0.1101\n",
      "Epoch: 11/20... Training loss: 0.1141\n",
      "Epoch: 11/20... Training loss: 0.1109\n",
      "Epoch: 11/20... Training loss: 0.1064\n",
      "Epoch: 11/20... Training loss: 0.1091\n",
      "Epoch: 12/20... Training loss: 0.1056\n",
      "Epoch: 12/20... Training loss: 0.1051\n",
      "Epoch: 12/20... Training loss: 0.1073\n",
      "Epoch: 12/20... Training loss: 0.1082\n",
      "Epoch: 12/20... Training loss: 0.1068\n",
      "Epoch: 12/20... Training loss: 0.1100\n",
      "Epoch: 12/20... Training loss: 0.1062\n",
      "Epoch: 12/20... Training loss: 0.1102\n",
      "Epoch: 12/20... Training loss: 0.1068\n",
      "Epoch: 12/20... Training loss: 0.1053\n",
      "Epoch: 12/20... Training loss: 0.1038\n",
      "Epoch: 12/20... Training loss: 0.1118\n",
      "Epoch: 12/20... Training loss: 0.1084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/20... Training loss: 0.1102\n",
      "Epoch: 12/20... Training loss: 0.1066\n",
      "Epoch: 12/20... Training loss: 0.1119\n",
      "Epoch: 12/20... Training loss: 0.1027\n",
      "Epoch: 12/20... Training loss: 0.1058\n",
      "Epoch: 12/20... Training loss: 0.1169\n",
      "Epoch: 12/20... Training loss: 0.1091\n",
      "Epoch: 12/20... Training loss: 0.1046\n",
      "Epoch: 12/20... Training loss: 0.1096\n",
      "Epoch: 12/20... Training loss: 0.1069\n",
      "Epoch: 12/20... Training loss: 0.1125\n",
      "Epoch: 12/20... Training loss: 0.1101\n",
      "Epoch: 12/20... Training loss: 0.1115\n",
      "Epoch: 12/20... Training loss: 0.1102\n",
      "Epoch: 12/20... Training loss: 0.1059\n",
      "Epoch: 12/20... Training loss: 0.1081\n",
      "Epoch: 12/20... Training loss: 0.1065\n",
      "Epoch: 12/20... Training loss: 0.1076\n",
      "Epoch: 12/20... Training loss: 0.1026\n",
      "Epoch: 12/20... Training loss: 0.1051\n",
      "Epoch: 12/20... Training loss: 0.1042\n",
      "Epoch: 12/20... Training loss: 0.1082\n",
      "Epoch: 12/20... Training loss: 0.1077\n",
      "Epoch: 12/20... Training loss: 0.1126\n",
      "Epoch: 12/20... Training loss: 0.1033\n",
      "Epoch: 12/20... Training loss: 0.1085\n",
      "Epoch: 12/20... Training loss: 0.1083\n",
      "Epoch: 12/20... Training loss: 0.1054\n",
      "Epoch: 12/20... Training loss: 0.1079\n",
      "Epoch: 12/20... Training loss: 0.1035\n",
      "Epoch: 12/20... Training loss: 0.1090\n",
      "Epoch: 12/20... Training loss: 0.1025\n",
      "Epoch: 12/20... Training loss: 0.1099\n",
      "Epoch: 12/20... Training loss: 0.1096\n",
      "Epoch: 12/20... Training loss: 0.1115\n",
      "Epoch: 12/20... Training loss: 0.1111\n",
      "Epoch: 12/20... Training loss: 0.1098\n",
      "Epoch: 12/20... Training loss: 0.1054\n",
      "Epoch: 12/20... Training loss: 0.1044\n",
      "Epoch: 12/20... Training loss: 0.1078\n",
      "Epoch: 12/20... Training loss: 0.1093\n",
      "Epoch: 12/20... Training loss: 0.1019\n",
      "Epoch: 12/20... Training loss: 0.1053\n",
      "Epoch: 12/20... Training loss: 0.1017\n",
      "Epoch: 12/20... Training loss: 0.1036\n",
      "Epoch: 12/20... Training loss: 0.1017\n",
      "Epoch: 12/20... Training loss: 0.1021\n",
      "Epoch: 12/20... Training loss: 0.1023\n",
      "Epoch: 12/20... Training loss: 0.1072\n",
      "Epoch: 12/20... Training loss: 0.1124\n",
      "Epoch: 12/20... Training loss: 0.1121\n",
      "Epoch: 12/20... Training loss: 0.1121\n",
      "Epoch: 12/20... Training loss: 0.1077\n",
      "Epoch: 12/20... Training loss: 0.1107\n",
      "Epoch: 12/20... Training loss: 0.1092\n",
      "Epoch: 12/20... Training loss: 0.1066\n",
      "Epoch: 12/20... Training loss: 0.1125\n",
      "Epoch: 12/20... Training loss: 0.1071\n",
      "Epoch: 12/20... Training loss: 0.1068\n",
      "Epoch: 12/20... Training loss: 0.1093\n",
      "Epoch: 12/20... Training loss: 0.1097\n",
      "Epoch: 12/20... Training loss: 0.1048\n",
      "Epoch: 12/20... Training loss: 0.1090\n",
      "Epoch: 12/20... Training loss: 0.1086\n",
      "Epoch: 12/20... Training loss: 0.1093\n",
      "Epoch: 12/20... Training loss: 0.1159\n",
      "Epoch: 12/20... Training loss: 0.1060\n",
      "Epoch: 12/20... Training loss: 0.1056\n",
      "Epoch: 12/20... Training loss: 0.1035\n",
      "Epoch: 12/20... Training loss: 0.1061\n",
      "Epoch: 12/20... Training loss: 0.1096\n",
      "Epoch: 12/20... Training loss: 0.1089\n",
      "Epoch: 12/20... Training loss: 0.1093\n",
      "Epoch: 12/20... Training loss: 0.1140\n",
      "Epoch: 12/20... Training loss: 0.1129\n",
      "Epoch: 12/20... Training loss: 0.1096\n",
      "Epoch: 12/20... Training loss: 0.1010\n",
      "Epoch: 12/20... Training loss: 0.0987\n",
      "Epoch: 12/20... Training loss: 0.1004\n",
      "Epoch: 12/20... Training loss: 0.1074\n",
      "Epoch: 12/20... Training loss: 0.1139\n",
      "Epoch: 12/20... Training loss: 0.1049\n",
      "Epoch: 12/20... Training loss: 0.1042\n",
      "Epoch: 12/20... Training loss: 0.1155\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.1041\n",
      "Epoch: 12/20... Training loss: 0.1119\n",
      "Epoch: 12/20... Training loss: 0.1085\n",
      "Epoch: 12/20... Training loss: 0.1066\n",
      "Epoch: 12/20... Training loss: 0.1043\n",
      "Epoch: 12/20... Training loss: 0.1028\n",
      "Epoch: 12/20... Training loss: 0.1083\n",
      "Epoch: 12/20... Training loss: 0.1066\n",
      "Epoch: 12/20... Training loss: 0.1105\n",
      "Epoch: 12/20... Training loss: 0.1077\n",
      "Epoch: 12/20... Training loss: 0.1058\n",
      "Epoch: 12/20... Training loss: 0.1060\n",
      "Epoch: 12/20... Training loss: 0.1184\n",
      "Epoch: 12/20... Training loss: 0.1101\n",
      "Epoch: 12/20... Training loss: 0.1067\n",
      "Epoch: 12/20... Training loss: 0.1077\n",
      "Epoch: 12/20... Training loss: 0.1081\n",
      "Epoch: 12/20... Training loss: 0.1070\n",
      "Epoch: 12/20... Training loss: 0.1021\n",
      "Epoch: 12/20... Training loss: 0.1067\n",
      "Epoch: 12/20... Training loss: 0.1132\n",
      "Epoch: 12/20... Training loss: 0.1119\n",
      "Epoch: 12/20... Training loss: 0.0992\n",
      "Epoch: 12/20... Training loss: 0.1036\n",
      "Epoch: 12/20... Training loss: 0.1106\n",
      "Epoch: 12/20... Training loss: 0.1028\n",
      "Epoch: 12/20... Training loss: 0.1000\n",
      "Epoch: 12/20... Training loss: 0.1087\n",
      "Epoch: 12/20... Training loss: 0.1085\n",
      "Epoch: 12/20... Training loss: 0.1020\n",
      "Epoch: 12/20... Training loss: 0.1043\n",
      "Epoch: 12/20... Training loss: 0.1064\n",
      "Epoch: 12/20... Training loss: 0.1036\n",
      "Epoch: 12/20... Training loss: 0.1050\n",
      "Epoch: 12/20... Training loss: 0.1072\n",
      "Epoch: 12/20... Training loss: 0.1093\n",
      "Epoch: 12/20... Training loss: 0.1039\n",
      "Epoch: 12/20... Training loss: 0.1155\n",
      "Epoch: 12/20... Training loss: 0.1141\n",
      "Epoch: 12/20... Training loss: 0.1075\n",
      "Epoch: 12/20... Training loss: 0.1088\n",
      "Epoch: 12/20... Training loss: 0.1066\n",
      "Epoch: 12/20... Training loss: 0.1026\n",
      "Epoch: 12/20... Training loss: 0.1076\n",
      "Epoch: 12/20... Training loss: 0.1017\n",
      "Epoch: 12/20... Training loss: 0.1072\n",
      "Epoch: 12/20... Training loss: 0.1117\n",
      "Epoch: 12/20... Training loss: 0.1176\n",
      "Epoch: 12/20... Training loss: 0.1071\n",
      "Epoch: 12/20... Training loss: 0.1008\n",
      "Epoch: 12/20... Training loss: 0.1073\n",
      "Epoch: 12/20... Training loss: 0.1027\n",
      "Epoch: 12/20... Training loss: 0.1087\n",
      "Epoch: 12/20... Training loss: 0.1082\n",
      "Epoch: 12/20... Training loss: 0.1097\n",
      "Epoch: 12/20... Training loss: 0.1094\n",
      "Epoch: 12/20... Training loss: 0.1083\n",
      "Epoch: 12/20... Training loss: 0.1075\n",
      "Epoch: 12/20... Training loss: 0.1054\n",
      "Epoch: 12/20... Training loss: 0.1086\n",
      "Epoch: 12/20... Training loss: 0.1118\n",
      "Epoch: 12/20... Training loss: 0.1064\n",
      "Epoch: 12/20... Training loss: 0.1093\n",
      "Epoch: 12/20... Training loss: 0.1068\n",
      "Epoch: 12/20... Training loss: 0.1043\n",
      "Epoch: 12/20... Training loss: 0.1125\n",
      "Epoch: 12/20... Training loss: 0.1074\n",
      "Epoch: 12/20... Training loss: 0.1046\n",
      "Epoch: 12/20... Training loss: 0.1094\n",
      "Epoch: 12/20... Training loss: 0.1068\n",
      "Epoch: 12/20... Training loss: 0.1012\n",
      "Epoch: 12/20... Training loss: 0.1011\n",
      "Epoch: 12/20... Training loss: 0.1089\n",
      "Epoch: 12/20... Training loss: 0.1069\n",
      "Epoch: 12/20... Training loss: 0.1071\n",
      "Epoch: 12/20... Training loss: 0.1102\n",
      "Epoch: 12/20... Training loss: 0.1063\n",
      "Epoch: 12/20... Training loss: 0.1106\n",
      "Epoch: 12/20... Training loss: 0.1044\n",
      "Epoch: 12/20... Training loss: 0.1109\n",
      "Epoch: 12/20... Training loss: 0.1086\n",
      "Epoch: 12/20... Training loss: 0.1100\n",
      "Epoch: 12/20... Training loss: 0.1086\n",
      "Epoch: 12/20... Training loss: 0.1109\n",
      "Epoch: 12/20... Training loss: 0.1111\n",
      "Epoch: 12/20... Training loss: 0.1091\n",
      "Epoch: 12/20... Training loss: 0.1085\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.1080\n",
      "Epoch: 12/20... Training loss: 0.1136\n",
      "Epoch: 12/20... Training loss: 0.1112\n",
      "Epoch: 12/20... Training loss: 0.1077\n",
      "Epoch: 12/20... Training loss: 0.1086\n",
      "Epoch: 12/20... Training loss: 0.1091\n",
      "Epoch: 12/20... Training loss: 0.1039\n",
      "Epoch: 12/20... Training loss: 0.1127\n",
      "Epoch: 12/20... Training loss: 0.1067\n",
      "Epoch: 12/20... Training loss: 0.1022\n",
      "Epoch: 12/20... Training loss: 0.1066\n",
      "Epoch: 12/20... Training loss: 0.0989\n",
      "Epoch: 12/20... Training loss: 0.1068\n",
      "Epoch: 12/20... Training loss: 0.1109\n",
      "Epoch: 12/20... Training loss: 0.1072\n",
      "Epoch: 12/20... Training loss: 0.1055\n",
      "Epoch: 12/20... Training loss: 0.1088\n",
      "Epoch: 12/20... Training loss: 0.1068\n",
      "Epoch: 12/20... Training loss: 0.1068\n",
      "Epoch: 12/20... Training loss: 0.1096\n",
      "Epoch: 12/20... Training loss: 0.1133\n",
      "Epoch: 12/20... Training loss: 0.1084\n",
      "Epoch: 12/20... Training loss: 0.1051\n",
      "Epoch: 12/20... Training loss: 0.1039\n",
      "Epoch: 12/20... Training loss: 0.1005\n",
      "Epoch: 12/20... Training loss: 0.1063\n",
      "Epoch: 12/20... Training loss: 0.1081\n",
      "Epoch: 12/20... Training loss: 0.1085\n",
      "Epoch: 12/20... Training loss: 0.1105\n",
      "Epoch: 12/20... Training loss: 0.1023\n",
      "Epoch: 12/20... Training loss: 0.1057\n",
      "Epoch: 12/20... Training loss: 0.1090\n",
      "Epoch: 12/20... Training loss: 0.1051\n",
      "Epoch: 12/20... Training loss: 0.1063\n",
      "Epoch: 12/20... Training loss: 0.1147\n",
      "Epoch: 12/20... Training loss: 0.1109\n",
      "Epoch: 12/20... Training loss: 0.1069\n",
      "Epoch: 12/20... Training loss: 0.1098\n",
      "Epoch: 12/20... Training loss: 0.1083\n",
      "Epoch: 12/20... Training loss: 0.1059\n",
      "Epoch: 12/20... Training loss: 0.1086\n",
      "Epoch: 12/20... Training loss: 0.1111\n",
      "Epoch: 12/20... Training loss: 0.1121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/20... Training loss: 0.1118\n",
      "Epoch: 12/20... Training loss: 0.1079\n",
      "Epoch: 12/20... Training loss: 0.1116\n",
      "Epoch: 12/20... Training loss: 0.1091\n",
      "Epoch: 12/20... Training loss: 0.1101\n",
      "Epoch: 12/20... Training loss: 0.1091\n",
      "Epoch: 12/20... Training loss: 0.1059\n",
      "Epoch: 12/20... Training loss: 0.1061\n",
      "Epoch: 12/20... Training loss: 0.1129\n",
      "Epoch: 12/20... Training loss: 0.1120\n",
      "Epoch: 12/20... Training loss: 0.1046\n",
      "Epoch: 12/20... Training loss: 0.1050\n",
      "Epoch: 12/20... Training loss: 0.1080\n",
      "Epoch: 12/20... Training loss: 0.1072\n",
      "Epoch: 12/20... Training loss: 0.1112\n",
      "Epoch: 12/20... Training loss: 0.1063\n",
      "Epoch: 12/20... Training loss: 0.1160\n",
      "Epoch: 12/20... Training loss: 0.1068\n",
      "Epoch: 12/20... Training loss: 0.1143\n",
      "Epoch: 12/20... Training loss: 0.1113\n",
      "Epoch: 12/20... Training loss: 0.1105\n",
      "Epoch: 12/20... Training loss: 0.1050\n",
      "Epoch: 12/20... Training loss: 0.1094\n",
      "Epoch: 12/20... Training loss: 0.1098\n",
      "Epoch: 12/20... Training loss: 0.1059\n",
      "Epoch: 12/20... Training loss: 0.1023\n",
      "Epoch: 12/20... Training loss: 0.1047\n",
      "Epoch: 12/20... Training loss: 0.1075\n",
      "Epoch: 12/20... Training loss: 0.1082\n",
      "Epoch: 12/20... Training loss: 0.1103\n",
      "Epoch: 12/20... Training loss: 0.1091\n",
      "Epoch: 12/20... Training loss: 0.1091\n",
      "Epoch: 12/20... Training loss: 0.1030\n",
      "Epoch: 12/20... Training loss: 0.1065\n",
      "Epoch: 12/20... Training loss: 0.1025\n",
      "Epoch: 12/20... Training loss: 0.1093\n",
      "Epoch: 12/20... Training loss: 0.1078\n",
      "Epoch: 12/20... Training loss: 0.1072\n",
      "Epoch: 12/20... Training loss: 0.1049\n",
      "Epoch: 12/20... Training loss: 0.1092\n",
      "Epoch: 12/20... Training loss: 0.1113\n",
      "Epoch: 12/20... Training loss: 0.1118\n",
      "Epoch: 12/20... Training loss: 0.1052\n",
      "Epoch: 12/20... Training loss: 0.1074\n",
      "Epoch: 12/20... Training loss: 0.1012\n",
      "Epoch: 12/20... Training loss: 0.1082\n",
      "Epoch: 12/20... Training loss: 0.1074\n",
      "Epoch: 12/20... Training loss: 0.1037\n",
      "Epoch: 12/20... Training loss: 0.1046\n",
      "Epoch: 12/20... Training loss: 0.1079\n",
      "Epoch: 12/20... Training loss: 0.1081\n",
      "Epoch: 12/20... Training loss: 0.1062\n",
      "Epoch: 12/20... Training loss: 0.1050\n",
      "Epoch: 12/20... Training loss: 0.1108\n",
      "Epoch: 12/20... Training loss: 0.1049\n",
      "Epoch: 12/20... Training loss: 0.1035\n",
      "Epoch: 12/20... Training loss: 0.1070\n",
      "Epoch: 12/20... Training loss: 0.1097\n",
      "Epoch: 12/20... Training loss: 0.1106\n",
      "Epoch: 12/20... Training loss: 0.1071\n",
      "Epoch: 12/20... Training loss: 0.1083\n",
      "Epoch: 12/20... Training loss: 0.1082\n",
      "Epoch: 12/20... Training loss: 0.1125\n",
      "Epoch: 12/20... Training loss: 0.1089\n",
      "Epoch: 12/20... Training loss: 0.1050\n",
      "Epoch: 12/20... Training loss: 0.1164\n",
      "Epoch: 12/20... Training loss: 0.1088\n",
      "Epoch: 12/20... Training loss: 0.1127\n",
      "Epoch: 12/20... Training loss: 0.1096\n",
      "Epoch: 12/20... Training loss: 0.1052\n",
      "Epoch: 12/20... Training loss: 0.1080\n",
      "Epoch: 13/20... Training loss: 0.1044\n",
      "Epoch: 13/20... Training loss: 0.1040\n",
      "Epoch: 13/20... Training loss: 0.1062\n",
      "Epoch: 13/20... Training loss: 0.1071\n",
      "Epoch: 13/20... Training loss: 0.1057\n",
      "Epoch: 13/20... Training loss: 0.1087\n",
      "Epoch: 13/20... Training loss: 0.1051\n",
      "Epoch: 13/20... Training loss: 0.1089\n",
      "Epoch: 13/20... Training loss: 0.1058\n",
      "Epoch: 13/20... Training loss: 0.1042\n",
      "Epoch: 13/20... Training loss: 0.1027\n",
      "Epoch: 13/20... Training loss: 0.1105\n",
      "Epoch: 13/20... Training loss: 0.1072\n",
      "Epoch: 13/20... Training loss: 0.1090\n",
      "Epoch: 13/20... Training loss: 0.1056\n",
      "Epoch: 13/20... Training loss: 0.1105\n",
      "Epoch: 13/20... Training loss: 0.1017\n",
      "Epoch: 13/20... Training loss: 0.1046\n",
      "Epoch: 13/20... Training loss: 0.1156\n",
      "Epoch: 13/20... Training loss: 0.1080\n",
      "Epoch: 13/20... Training loss: 0.1034\n",
      "Epoch: 13/20... Training loss: 0.1082\n",
      "Epoch: 13/20... Training loss: 0.1055\n",
      "Epoch: 13/20... Training loss: 0.1111\n",
      "Epoch: 13/20... Training loss: 0.1088\n",
      "Epoch: 13/20... Training loss: 0.1103\n",
      "Epoch: 13/20... Training loss: 0.1091\n",
      "Epoch: 13/20... Training loss: 0.1048\n",
      "Epoch: 13/20... Training loss: 0.1068\n",
      "Epoch: 13/20... Training loss: 0.1054\n",
      "Epoch: 13/20... Training loss: 0.1065\n",
      "Epoch: 13/20... Training loss: 0.1015\n",
      "Epoch: 13/20... Training loss: 0.1040\n",
      "Epoch: 13/20... Training loss: 0.1032\n",
      "Epoch: 13/20... Training loss: 0.1072\n",
      "Epoch: 13/20... Training loss: 0.1066\n",
      "Epoch: 13/20... Training loss: 0.1113\n",
      "Epoch: 13/20... Training loss: 0.1024\n",
      "Epoch: 13/20... Training loss: 0.1073\n",
      "Epoch: 13/20... Training loss: 0.1070\n",
      "Epoch: 13/20... Training loss: 0.1041\n",
      "Epoch: 13/20... Training loss: 0.1068\n",
      "Epoch: 13/20... Training loss: 0.1024\n",
      "Epoch: 13/20... Training loss: 0.1076\n",
      "Epoch: 13/20... Training loss: 0.1013\n",
      "Epoch: 13/20... Training loss: 0.1087\n",
      "Epoch: 13/20... Training loss: 0.1083\n",
      "Epoch: 13/20... Training loss: 0.1100\n",
      "Epoch: 13/20... Training loss: 0.1101\n",
      "Epoch: 13/20... Training loss: 0.1084\n",
      "Epoch: 13/20... Training loss: 0.1042\n",
      "Epoch: 13/20... Training loss: 0.1030\n",
      "Epoch: 13/20... Training loss: 0.1066\n",
      "Epoch: 13/20... Training loss: 0.1082\n",
      "Epoch: 13/20... Training loss: 0.1007\n",
      "Epoch: 13/20... Training loss: 0.1041\n",
      "Epoch: 13/20... Training loss: 0.1006\n",
      "Epoch: 13/20... Training loss: 0.1023\n",
      "Epoch: 13/20... Training loss: 0.1006\n",
      "Epoch: 13/20... Training loss: 0.1011\n",
      "Epoch: 13/20... Training loss: 0.1013\n",
      "Epoch: 13/20... Training loss: 0.1061\n",
      "Epoch: 13/20... Training loss: 0.1109\n",
      "Epoch: 13/20... Training loss: 0.1108\n",
      "Epoch: 13/20... Training loss: 0.1108\n",
      "Epoch: 13/20... Training loss: 0.1067\n",
      "Epoch: 13/20... Training loss: 0.1094\n",
      "Epoch: 13/20... Training loss: 0.1079\n",
      "Epoch: 13/20... Training loss: 0.1056\n",
      "Epoch: 13/20... Training loss: 0.1111\n",
      "Epoch: 13/20... Training loss: 0.1060\n",
      "Epoch: 13/20... Training loss: 0.1058\n",
      "Epoch: 13/20... Training loss: 0.1082\n",
      "Epoch: 13/20... Training loss: 0.1088\n",
      "Epoch: 13/20... Training loss: 0.1038\n",
      "Epoch: 13/20... Training loss: 0.1083\n",
      "Epoch: 13/20... Training loss: 0.1075\n",
      "Epoch: 13/20... Training loss: 0.1083\n",
      "Epoch: 13/20... Training loss: 0.1148\n",
      "Epoch: 13/20... Training loss: 0.1050\n",
      "Epoch: 13/20... Training loss: 0.1046\n",
      "Epoch: 13/20... Training loss: 0.1024\n",
      "Epoch: 13/20... Training loss: 0.1052\n",
      "Epoch: 13/20... Training loss: 0.1087\n",
      "Epoch: 13/20... Training loss: 0.1078\n",
      "Epoch: 13/20... Training loss: 0.1081\n",
      "Epoch: 13/20... Training loss: 0.1129\n",
      "Epoch: 13/20... Training loss: 0.1115\n",
      "Epoch: 13/20... Training loss: 0.1084\n",
      "Epoch: 13/20... Training loss: 0.1000\n",
      "Epoch: 13/20... Training loss: 0.0977\n",
      "Epoch: 13/20... Training loss: 0.0995\n",
      "Epoch: 13/20... Training loss: 0.1062\n",
      "Epoch: 13/20... Training loss: 0.1127\n",
      "Epoch: 13/20... Training loss: 0.1039\n",
      "Epoch: 13/20... Training loss: 0.1032\n",
      "Epoch: 13/20... Training loss: 0.1141\n",
      "Epoch: 13/20... Training loss: 0.1020\n",
      "Epoch: 13/20... Training loss: 0.1031\n",
      "Epoch: 13/20... Training loss: 0.1106\n",
      "Epoch: 13/20... Training loss: 0.1075\n",
      "Epoch: 13/20... Training loss: 0.1055\n",
      "Epoch: 13/20... Training loss: 0.1033\n",
      "Epoch: 13/20... Training loss: 0.1018\n",
      "Epoch: 13/20... Training loss: 0.1074\n",
      "Epoch: 13/20... Training loss: 0.1055\n",
      "Epoch: 13/20... Training loss: 0.1094\n",
      "Epoch: 13/20... Training loss: 0.1067\n",
      "Epoch: 13/20... Training loss: 0.1048\n",
      "Epoch: 13/20... Training loss: 0.1048\n",
      "Epoch: 13/20... Training loss: 0.1173\n",
      "Epoch: 13/20... Training loss: 0.1091\n",
      "Epoch: 13/20... Training loss: 0.1054\n",
      "Epoch: 13/20... Training loss: 0.1065\n",
      "Epoch: 13/20... Training loss: 0.1070\n",
      "Epoch: 13/20... Training loss: 0.1059\n",
      "Epoch: 13/20... Training loss: 0.1010\n",
      "Epoch: 13/20... Training loss: 0.1055\n",
      "Epoch: 13/20... Training loss: 0.1121\n",
      "Epoch: 13/20... Training loss: 0.1108\n",
      "Epoch: 13/20... Training loss: 0.0984\n",
      "Epoch: 13/20... Training loss: 0.1025\n",
      "Epoch: 13/20... Training loss: 0.1093\n",
      "Epoch: 13/20... Training loss: 0.1017\n",
      "Epoch: 13/20... Training loss: 0.0990\n",
      "Epoch: 13/20... Training loss: 0.1076\n",
      "Epoch: 13/20... Training loss: 0.1073\n",
      "Epoch: 13/20... Training loss: 0.1010\n",
      "Epoch: 13/20... Training loss: 0.1033\n",
      "Epoch: 13/20... Training loss: 0.1054\n",
      "Epoch: 13/20... Training loss: 0.1027\n",
      "Epoch: 13/20... Training loss: 0.1040\n",
      "Epoch: 13/20... Training loss: 0.1064\n",
      "Epoch: 13/20... Training loss: 0.1082\n",
      "Epoch: 13/20... Training loss: 0.1029\n",
      "Epoch: 13/20... Training loss: 0.1145\n",
      "Epoch: 13/20... Training loss: 0.1126\n",
      "Epoch: 13/20... Training loss: 0.1064\n",
      "Epoch: 13/20... Training loss: 0.1079\n",
      "Epoch: 13/20... Training loss: 0.1055\n",
      "Epoch: 13/20... Training loss: 0.1015\n",
      "Epoch: 13/20... Training loss: 0.1064\n",
      "Epoch: 13/20... Training loss: 0.1008\n",
      "Epoch: 13/20... Training loss: 0.1061\n",
      "Epoch: 13/20... Training loss: 0.1107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/20... Training loss: 0.1165\n",
      "Epoch: 13/20... Training loss: 0.1061\n",
      "Epoch: 13/20... Training loss: 0.0999\n",
      "Epoch: 13/20... Training loss: 0.1065\n",
      "Epoch: 13/20... Training loss: 0.1018\n",
      "Epoch: 13/20... Training loss: 0.1077\n",
      "Epoch: 13/20... Training loss: 0.1071\n",
      "Epoch: 13/20... Training loss: 0.1087\n",
      "Epoch: 13/20... Training loss: 0.1084\n",
      "Epoch: 13/20... Training loss: 0.1073\n",
      "Epoch: 13/20... Training loss: 0.1067\n",
      "Epoch: 13/20... Training loss: 0.1044\n",
      "Epoch: 13/20... Training loss: 0.1077\n",
      "Epoch: 13/20... Training loss: 0.1108\n",
      "Epoch: 13/20... Training loss: 0.1053\n",
      "Epoch: 13/20... Training loss: 0.1081\n",
      "Epoch: 13/20... Training loss: 0.1058\n",
      "Epoch: 13/20... Training loss: 0.1033\n",
      "Epoch: 13/20... Training loss: 0.1112\n",
      "Epoch: 13/20... Training loss: 0.1063\n",
      "Epoch: 13/20... Training loss: 0.1036\n",
      "Epoch: 13/20... Training loss: 0.1082\n",
      "Epoch: 13/20... Training loss: 0.1060\n",
      "Epoch: 13/20... Training loss: 0.1003\n",
      "Epoch: 13/20... Training loss: 0.1002\n",
      "Epoch: 13/20... Training loss: 0.1078\n",
      "Epoch: 13/20... Training loss: 0.1059\n",
      "Epoch: 13/20... Training loss: 0.1058\n",
      "Epoch: 13/20... Training loss: 0.1093\n",
      "Epoch: 13/20... Training loss: 0.1052\n",
      "Epoch: 13/20... Training loss: 0.1094\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.1094\n",
      "Epoch: 13/20... Training loss: 0.1075\n",
      "Epoch: 13/20... Training loss: 0.1090\n",
      "Epoch: 13/20... Training loss: 0.1074\n",
      "Epoch: 13/20... Training loss: 0.1096\n",
      "Epoch: 13/20... Training loss: 0.1099\n",
      "Epoch: 13/20... Training loss: 0.1079\n",
      "Epoch: 13/20... Training loss: 0.1071\n",
      "Epoch: 13/20... Training loss: 0.1019\n",
      "Epoch: 13/20... Training loss: 0.1069\n",
      "Epoch: 13/20... Training loss: 0.1126\n",
      "Epoch: 13/20... Training loss: 0.1103\n",
      "Epoch: 13/20... Training loss: 0.1066\n",
      "Epoch: 13/20... Training loss: 0.1077\n",
      "Epoch: 13/20... Training loss: 0.1079\n",
      "Epoch: 13/20... Training loss: 0.1029\n",
      "Epoch: 13/20... Training loss: 0.1115\n",
      "Epoch: 13/20... Training loss: 0.1057\n",
      "Epoch: 13/20... Training loss: 0.1012\n",
      "Epoch: 13/20... Training loss: 0.1058\n",
      "Epoch: 13/20... Training loss: 0.0980\n",
      "Epoch: 13/20... Training loss: 0.1058\n",
      "Epoch: 13/20... Training loss: 0.1099\n",
      "Epoch: 13/20... Training loss: 0.1062\n",
      "Epoch: 13/20... Training loss: 0.1047\n",
      "Epoch: 13/20... Training loss: 0.1077\n",
      "Epoch: 13/20... Training loss: 0.1058\n",
      "Epoch: 13/20... Training loss: 0.1060\n",
      "Epoch: 13/20... Training loss: 0.1087\n",
      "Epoch: 13/20... Training loss: 0.1123\n",
      "Epoch: 13/20... Training loss: 0.1075\n",
      "Epoch: 13/20... Training loss: 0.1040\n",
      "Epoch: 13/20... Training loss: 0.1031\n",
      "Epoch: 13/20... Training loss: 0.0997\n",
      "Epoch: 13/20... Training loss: 0.1053\n",
      "Epoch: 13/20... Training loss: 0.1071\n",
      "Epoch: 13/20... Training loss: 0.1074\n",
      "Epoch: 13/20... Training loss: 0.1096\n",
      "Epoch: 13/20... Training loss: 0.1015\n",
      "Epoch: 13/20... Training loss: 0.1047\n",
      "Epoch: 13/20... Training loss: 0.1081\n",
      "Epoch: 13/20... Training loss: 0.1041\n",
      "Epoch: 13/20... Training loss: 0.1053\n",
      "Epoch: 13/20... Training loss: 0.1137\n",
      "Epoch: 13/20... Training loss: 0.1098\n",
      "Epoch: 13/20... Training loss: 0.1059\n",
      "Epoch: 13/20... Training loss: 0.1089\n",
      "Epoch: 13/20... Training loss: 0.1074\n",
      "Epoch: 13/20... Training loss: 0.1049\n",
      "Epoch: 13/20... Training loss: 0.1074\n",
      "Epoch: 13/20... Training loss: 0.1100\n",
      "Epoch: 13/20... Training loss: 0.1111\n",
      "Epoch: 13/20... Training loss: 0.1108\n",
      "Epoch: 13/20... Training loss: 0.1070\n",
      "Epoch: 13/20... Training loss: 0.1107\n",
      "Epoch: 13/20... Training loss: 0.1079\n",
      "Epoch: 13/20... Training loss: 0.1090\n",
      "Epoch: 13/20... Training loss: 0.1080\n",
      "Epoch: 13/20... Training loss: 0.1051\n",
      "Epoch: 13/20... Training loss: 0.1053\n",
      "Epoch: 13/20... Training loss: 0.1118\n",
      "Epoch: 13/20... Training loss: 0.1108\n",
      "Epoch: 13/20... Training loss: 0.1038\n",
      "Epoch: 13/20... Training loss: 0.1039\n",
      "Epoch: 13/20... Training loss: 0.1070\n",
      "Epoch: 13/20... Training loss: 0.1062\n",
      "Epoch: 13/20... Training loss: 0.1103\n",
      "Epoch: 13/20... Training loss: 0.1053\n",
      "Epoch: 13/20... Training loss: 0.1149\n",
      "Epoch: 13/20... Training loss: 0.1059\n",
      "Epoch: 13/20... Training loss: 0.1134\n",
      "Epoch: 13/20... Training loss: 0.1103\n",
      "Epoch: 13/20... Training loss: 0.1096\n",
      "Epoch: 13/20... Training loss: 0.1042\n",
      "Epoch: 13/20... Training loss: 0.1081\n",
      "Epoch: 13/20... Training loss: 0.1089\n",
      "Epoch: 13/20... Training loss: 0.1051\n",
      "Epoch: 13/20... Training loss: 0.1013\n",
      "Epoch: 13/20... Training loss: 0.1040\n",
      "Epoch: 13/20... Training loss: 0.1064\n",
      "Epoch: 13/20... Training loss: 0.1072\n",
      "Epoch: 13/20... Training loss: 0.1093\n",
      "Epoch: 13/20... Training loss: 0.1079\n",
      "Epoch: 13/20... Training loss: 0.1081\n",
      "Epoch: 13/20... Training loss: 0.1021\n",
      "Epoch: 13/20... Training loss: 0.1055\n",
      "Epoch: 13/20... Training loss: 0.1014\n",
      "Epoch: 13/20... Training loss: 0.1083\n",
      "Epoch: 13/20... Training loss: 0.1069\n",
      "Epoch: 13/20... Training loss: 0.1062\n",
      "Epoch: 13/20... Training loss: 0.1039\n",
      "Epoch: 13/20... Training loss: 0.1083\n",
      "Epoch: 13/20... Training loss: 0.1102\n",
      "Epoch: 13/20... Training loss: 0.1108\n",
      "Epoch: 13/20... Training loss: 0.1043\n",
      "Epoch: 13/20... Training loss: 0.1063\n",
      "Epoch: 13/20... Training loss: 0.1003\n",
      "Epoch: 13/20... Training loss: 0.1071\n",
      "Epoch: 13/20... Training loss: 0.1064\n",
      "Epoch: 13/20... Training loss: 0.1027\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.1069\n",
      "Epoch: 13/20... Training loss: 0.1071\n",
      "Epoch: 13/20... Training loss: 0.1052\n",
      "Epoch: 13/20... Training loss: 0.1039\n",
      "Epoch: 13/20... Training loss: 0.1097\n",
      "Epoch: 13/20... Training loss: 0.1040\n",
      "Epoch: 13/20... Training loss: 0.1025\n",
      "Epoch: 13/20... Training loss: 0.1060\n",
      "Epoch: 13/20... Training loss: 0.1088\n",
      "Epoch: 13/20... Training loss: 0.1097\n",
      "Epoch: 13/20... Training loss: 0.1064\n",
      "Epoch: 13/20... Training loss: 0.1072\n",
      "Epoch: 13/20... Training loss: 0.1072\n",
      "Epoch: 13/20... Training loss: 0.1115\n",
      "Epoch: 13/20... Training loss: 0.1078\n",
      "Epoch: 13/20... Training loss: 0.1041\n",
      "Epoch: 13/20... Training loss: 0.1153\n",
      "Epoch: 13/20... Training loss: 0.1079\n",
      "Epoch: 13/20... Training loss: 0.1116\n",
      "Epoch: 13/20... Training loss: 0.1085\n",
      "Epoch: 13/20... Training loss: 0.1041\n",
      "Epoch: 13/20... Training loss: 0.1070\n",
      "Epoch: 14/20... Training loss: 0.1035\n",
      "Epoch: 14/20... Training loss: 0.1030\n",
      "Epoch: 14/20... Training loss: 0.1055\n",
      "Epoch: 14/20... Training loss: 0.1064\n",
      "Epoch: 14/20... Training loss: 0.1049\n",
      "Epoch: 14/20... Training loss: 0.1076\n",
      "Epoch: 14/20... Training loss: 0.1042\n",
      "Epoch: 14/20... Training loss: 0.1080\n",
      "Epoch: 14/20... Training loss: 0.1049\n",
      "Epoch: 14/20... Training loss: 0.1036\n",
      "Epoch: 14/20... Training loss: 0.1019\n",
      "Epoch: 14/20... Training loss: 0.1095\n",
      "Epoch: 14/20... Training loss: 0.1063\n",
      "Epoch: 14/20... Training loss: 0.1082\n",
      "Epoch: 14/20... Training loss: 0.1049\n",
      "Epoch: 14/20... Training loss: 0.1095\n",
      "Epoch: 14/20... Training loss: 0.1010\n",
      "Epoch: 14/20... Training loss: 0.1036\n",
      "Epoch: 14/20... Training loss: 0.1147\n",
      "Epoch: 14/20... Training loss: 0.1071\n",
      "Epoch: 14/20... Training loss: 0.1023\n",
      "Epoch: 14/20... Training loss: 0.1073\n",
      "Epoch: 14/20... Training loss: 0.1043\n",
      "Epoch: 14/20... Training loss: 0.1100\n",
      "Epoch: 14/20... Training loss: 0.1077\n",
      "Epoch: 14/20... Training loss: 0.1092\n",
      "Epoch: 14/20... Training loss: 0.1083\n",
      "Epoch: 14/20... Training loss: 0.1040\n",
      "Epoch: 14/20... Training loss: 0.1058\n",
      "Epoch: 14/20... Training loss: 0.1043\n",
      "Epoch: 14/20... Training loss: 0.1056\n",
      "Epoch: 14/20... Training loss: 0.1005\n",
      "Epoch: 14/20... Training loss: 0.1029\n",
      "Epoch: 14/20... Training loss: 0.1026\n",
      "Epoch: 14/20... Training loss: 0.1065\n",
      "Epoch: 14/20... Training loss: 0.1057\n",
      "Epoch: 14/20... Training loss: 0.1102\n",
      "Epoch: 14/20... Training loss: 0.1016\n",
      "Epoch: 14/20... Training loss: 0.1064\n",
      "Epoch: 14/20... Training loss: 0.1059\n",
      "Epoch: 14/20... Training loss: 0.1032\n",
      "Epoch: 14/20... Training loss: 0.1059\n",
      "Epoch: 14/20... Training loss: 0.1014\n",
      "Epoch: 14/20... Training loss: 0.1065\n",
      "Epoch: 14/20... Training loss: 0.1004\n",
      "Epoch: 14/20... Training loss: 0.1078\n",
      "Epoch: 14/20... Training loss: 0.1072\n",
      "Epoch: 14/20... Training loss: 0.1088\n",
      "Epoch: 14/20... Training loss: 0.1092\n",
      "Epoch: 14/20... Training loss: 0.1073\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1019\n",
      "Epoch: 14/20... Training loss: 0.1057\n",
      "Epoch: 14/20... Training loss: 0.1071\n",
      "Epoch: 14/20... Training loss: 0.0997\n",
      "Epoch: 14/20... Training loss: 0.1031\n",
      "Epoch: 14/20... Training loss: 0.0998\n",
      "Epoch: 14/20... Training loss: 0.1013\n",
      "Epoch: 14/20... Training loss: 0.0996\n",
      "Epoch: 14/20... Training loss: 0.1003\n",
      "Epoch: 14/20... Training loss: 0.1004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/20... Training loss: 0.1052\n",
      "Epoch: 14/20... Training loss: 0.1099\n",
      "Epoch: 14/20... Training loss: 0.1098\n",
      "Epoch: 14/20... Training loss: 0.1099\n",
      "Epoch: 14/20... Training loss: 0.1058\n",
      "Epoch: 14/20... Training loss: 0.1083\n",
      "Epoch: 14/20... Training loss: 0.1069\n",
      "Epoch: 14/20... Training loss: 0.1046\n",
      "Epoch: 14/20... Training loss: 0.1099\n",
      "Epoch: 14/20... Training loss: 0.1049\n",
      "Epoch: 14/20... Training loss: 0.1048\n",
      "Epoch: 14/20... Training loss: 0.1072\n",
      "Epoch: 14/20... Training loss: 0.1080\n",
      "Epoch: 14/20... Training loss: 0.1027\n",
      "Epoch: 14/20... Training loss: 0.1075\n",
      "Epoch: 14/20... Training loss: 0.1065\n",
      "Epoch: 14/20... Training loss: 0.1073\n",
      "Epoch: 14/20... Training loss: 0.1139\n",
      "Epoch: 14/20... Training loss: 0.1041\n",
      "Epoch: 14/20... Training loss: 0.1037\n",
      "Epoch: 14/20... Training loss: 0.1014\n",
      "Epoch: 14/20... Training loss: 0.1044\n",
      "Epoch: 14/20... Training loss: 0.1078\n",
      "Epoch: 14/20... Training loss: 0.1068\n",
      "Epoch: 14/20... Training loss: 0.1071\n",
      "Epoch: 14/20... Training loss: 0.1119\n",
      "Epoch: 14/20... Training loss: 0.1104\n",
      "Epoch: 14/20... Training loss: 0.1073\n",
      "Epoch: 14/20... Training loss: 0.0992\n",
      "Epoch: 14/20... Training loss: 0.0970\n",
      "Epoch: 14/20... Training loss: 0.0987\n",
      "Epoch: 14/20... Training loss: 0.1052\n",
      "Epoch: 14/20... Training loss: 0.1118\n",
      "Epoch: 14/20... Training loss: 0.1029\n",
      "Epoch: 14/20... Training loss: 0.1024\n",
      "Epoch: 14/20... Training loss: 0.1128\n",
      "Epoch: 14/20... Training loss: 0.1011\n",
      "Epoch: 14/20... Training loss: 0.1022\n",
      "Epoch: 14/20... Training loss: 0.1094\n",
      "Epoch: 14/20... Training loss: 0.1064\n",
      "Epoch: 14/20... Training loss: 0.1045\n",
      "Epoch: 14/20... Training loss: 0.1022\n",
      "Epoch: 14/20... Training loss: 0.1010\n",
      "Epoch: 14/20... Training loss: 0.1063\n",
      "Epoch: 14/20... Training loss: 0.1045\n",
      "Epoch: 14/20... Training loss: 0.1084\n",
      "Epoch: 14/20... Training loss: 0.1059\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1162\n",
      "Epoch: 14/20... Training loss: 0.1081\n",
      "Epoch: 14/20... Training loss: 0.1044\n",
      "Epoch: 14/20... Training loss: 0.1055\n",
      "Epoch: 14/20... Training loss: 0.1060\n",
      "Epoch: 14/20... Training loss: 0.1048\n",
      "Epoch: 14/20... Training loss: 0.1001\n",
      "Epoch: 14/20... Training loss: 0.1046\n",
      "Epoch: 14/20... Training loss: 0.1110\n",
      "Epoch: 14/20... Training loss: 0.1100\n",
      "Epoch: 14/20... Training loss: 0.0977\n",
      "Epoch: 14/20... Training loss: 0.1014\n",
      "Epoch: 14/20... Training loss: 0.1082\n",
      "Epoch: 14/20... Training loss: 0.1009\n",
      "Epoch: 14/20... Training loss: 0.0981\n",
      "Epoch: 14/20... Training loss: 0.1065\n",
      "Epoch: 14/20... Training loss: 0.1064\n",
      "Epoch: 14/20... Training loss: 0.1000\n",
      "Epoch: 14/20... Training loss: 0.1024\n",
      "Epoch: 14/20... Training loss: 0.1045\n",
      "Epoch: 14/20... Training loss: 0.1017\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1056\n",
      "Epoch: 14/20... Training loss: 0.1071\n",
      "Epoch: 14/20... Training loss: 0.1020\n",
      "Epoch: 14/20... Training loss: 0.1135\n",
      "Epoch: 14/20... Training loss: 0.1115\n",
      "Epoch: 14/20... Training loss: 0.1056\n",
      "Epoch: 14/20... Training loss: 0.1070\n",
      "Epoch: 14/20... Training loss: 0.1046\n",
      "Epoch: 14/20... Training loss: 0.1004\n",
      "Epoch: 14/20... Training loss: 0.1055\n",
      "Epoch: 14/20... Training loss: 0.1001\n",
      "Epoch: 14/20... Training loss: 0.1053\n",
      "Epoch: 14/20... Training loss: 0.1099\n",
      "Epoch: 14/20... Training loss: 0.1157\n",
      "Epoch: 14/20... Training loss: 0.1053\n",
      "Epoch: 14/20... Training loss: 0.0991\n",
      "Epoch: 14/20... Training loss: 0.1058\n",
      "Epoch: 14/20... Training loss: 0.1011\n",
      "Epoch: 14/20... Training loss: 0.1069\n",
      "Epoch: 14/20... Training loss: 0.1061\n",
      "Epoch: 14/20... Training loss: 0.1079\n",
      "Epoch: 14/20... Training loss: 0.1076\n",
      "Epoch: 14/20... Training loss: 0.1065\n",
      "Epoch: 14/20... Training loss: 0.1058\n",
      "Epoch: 14/20... Training loss: 0.1034\n",
      "Epoch: 14/20... Training loss: 0.1069\n",
      "Epoch: 14/20... Training loss: 0.1098\n",
      "Epoch: 14/20... Training loss: 0.1044\n",
      "Epoch: 14/20... Training loss: 0.1072\n",
      "Epoch: 14/20... Training loss: 0.1049\n",
      "Epoch: 14/20... Training loss: 0.1026\n",
      "Epoch: 14/20... Training loss: 0.1102\n",
      "Epoch: 14/20... Training loss: 0.1054\n",
      "Epoch: 14/20... Training loss: 0.1026\n",
      "Epoch: 14/20... Training loss: 0.1073\n",
      "Epoch: 14/20... Training loss: 0.1053\n",
      "Epoch: 14/20... Training loss: 0.0994\n",
      "Epoch: 14/20... Training loss: 0.0995\n",
      "Epoch: 14/20... Training loss: 0.1068\n",
      "Epoch: 14/20... Training loss: 0.1051\n",
      "Epoch: 14/20... Training loss: 0.1047\n",
      "Epoch: 14/20... Training loss: 0.1085\n",
      "Epoch: 14/20... Training loss: 0.1043\n",
      "Epoch: 14/20... Training loss: 0.1085\n",
      "Epoch: 14/20... Training loss: 0.1027\n",
      "Epoch: 14/20... Training loss: 0.1083\n",
      "Epoch: 14/20... Training loss: 0.1066\n",
      "Epoch: 14/20... Training loss: 0.1082\n",
      "Epoch: 14/20... Training loss: 0.1064\n",
      "Epoch: 14/20... Training loss: 0.1086\n",
      "Epoch: 14/20... Training loss: 0.1090\n",
      "Epoch: 14/20... Training loss: 0.1068\n",
      "Epoch: 14/20... Training loss: 0.1061\n",
      "Epoch: 14/20... Training loss: 0.1010\n",
      "Epoch: 14/20... Training loss: 0.1059\n",
      "Epoch: 14/20... Training loss: 0.1117\n",
      "Epoch: 14/20... Training loss: 0.1096\n",
      "Epoch: 14/20... Training loss: 0.1056\n",
      "Epoch: 14/20... Training loss: 0.1069\n",
      "Epoch: 14/20... Training loss: 0.1069\n",
      "Epoch: 14/20... Training loss: 0.1021\n",
      "Epoch: 14/20... Training loss: 0.1104\n",
      "Epoch: 14/20... Training loss: 0.1048\n",
      "Epoch: 14/20... Training loss: 0.1003\n",
      "Epoch: 14/20... Training loss: 0.1050\n",
      "Epoch: 14/20... Training loss: 0.0972\n",
      "Epoch: 14/20... Training loss: 0.1049\n",
      "Epoch: 14/20... Training loss: 0.1090\n",
      "Epoch: 14/20... Training loss: 0.1053\n",
      "Epoch: 14/20... Training loss: 0.1040\n",
      "Epoch: 14/20... Training loss: 0.1067\n",
      "Epoch: 14/20... Training loss: 0.1048\n",
      "Epoch: 14/20... Training loss: 0.1051\n",
      "Epoch: 14/20... Training loss: 0.1079\n",
      "Epoch: 14/20... Training loss: 0.1114\n",
      "Epoch: 14/20... Training loss: 0.1067\n",
      "Epoch: 14/20... Training loss: 0.1030\n",
      "Epoch: 14/20... Training loss: 0.1025\n",
      "Epoch: 14/20... Training loss: 0.0990\n",
      "Epoch: 14/20... Training loss: 0.1045\n",
      "Epoch: 14/20... Training loss: 0.1062\n",
      "Epoch: 14/20... Training loss: 0.1063\n",
      "Epoch: 14/20... Training loss: 0.1088\n",
      "Epoch: 14/20... Training loss: 0.1006\n",
      "Epoch: 14/20... Training loss: 0.1037\n",
      "Epoch: 14/20... Training loss: 0.1073\n",
      "Epoch: 14/20... Training loss: 0.1031\n",
      "Epoch: 14/20... Training loss: 0.1045\n",
      "Epoch: 14/20... Training loss: 0.1129\n",
      "Epoch: 14/20... Training loss: 0.1089\n",
      "Epoch: 14/20... Training loss: 0.1051\n",
      "Epoch: 14/20... Training loss: 0.1081\n",
      "Epoch: 14/20... Training loss: 0.1067\n",
      "Epoch: 14/20... Training loss: 0.1040\n",
      "Epoch: 14/20... Training loss: 0.1065\n",
      "Epoch: 14/20... Training loss: 0.1092\n",
      "Epoch: 14/20... Training loss: 0.1103\n",
      "Epoch: 14/20... Training loss: 0.1098\n",
      "Epoch: 14/20... Training loss: 0.1062\n",
      "Epoch: 14/20... Training loss: 0.1097\n",
      "Epoch: 14/20... Training loss: 0.1068\n",
      "Epoch: 14/20... Training loss: 0.1080\n",
      "Epoch: 14/20... Training loss: 0.1069\n",
      "Epoch: 14/20... Training loss: 0.1043\n",
      "Epoch: 14/20... Training loss: 0.1044\n",
      "Epoch: 14/20... Training loss: 0.1109\n",
      "Epoch: 14/20... Training loss: 0.1099\n",
      "Epoch: 14/20... Training loss: 0.1030\n",
      "Epoch: 14/20... Training loss: 0.1029\n",
      "Epoch: 14/20... Training loss: 0.1061\n",
      "Epoch: 14/20... Training loss: 0.1052\n",
      "Epoch: 14/20... Training loss: 0.1094\n",
      "Epoch: 14/20... Training loss: 0.1045\n",
      "Epoch: 14/20... Training loss: 0.1136\n",
      "Epoch: 14/20... Training loss: 0.1052\n",
      "Epoch: 14/20... Training loss: 0.1123\n",
      "Epoch: 14/20... Training loss: 0.1095\n",
      "Epoch: 14/20... Training loss: 0.1086\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1071\n",
      "Epoch: 14/20... Training loss: 0.1081\n",
      "Epoch: 14/20... Training loss: 0.1043\n",
      "Epoch: 14/20... Training loss: 0.1004\n",
      "Epoch: 14/20... Training loss: 0.1031\n",
      "Epoch: 14/20... Training loss: 0.1054\n",
      "Epoch: 14/20... Training loss: 0.1063\n",
      "Epoch: 14/20... Training loss: 0.1082\n",
      "Epoch: 14/20... Training loss: 0.1067\n",
      "Epoch: 14/20... Training loss: 0.1071\n",
      "Epoch: 14/20... Training loss: 0.1011\n",
      "Epoch: 14/20... Training loss: 0.1045\n",
      "Epoch: 14/20... Training loss: 0.1004\n",
      "Epoch: 14/20... Training loss: 0.1075\n",
      "Epoch: 14/20... Training loss: 0.1058\n",
      "Epoch: 14/20... Training loss: 0.1053\n",
      "Epoch: 14/20... Training loss: 0.1029\n",
      "Epoch: 14/20... Training loss: 0.1075\n",
      "Epoch: 14/20... Training loss: 0.1091\n",
      "Epoch: 14/20... Training loss: 0.1099\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1051\n",
      "Epoch: 14/20... Training loss: 0.0995\n",
      "Epoch: 14/20... Training loss: 0.1062\n",
      "Epoch: 14/20... Training loss: 0.1054\n",
      "Epoch: 14/20... Training loss: 0.1019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/20... Training loss: 0.1025\n",
      "Epoch: 14/20... Training loss: 0.1059\n",
      "Epoch: 14/20... Training loss: 0.1060\n",
      "Epoch: 14/20... Training loss: 0.1043\n",
      "Epoch: 14/20... Training loss: 0.1030\n",
      "Epoch: 14/20... Training loss: 0.1087\n",
      "Epoch: 14/20... Training loss: 0.1031\n",
      "Epoch: 14/20... Training loss: 0.1016\n",
      "Epoch: 14/20... Training loss: 0.1051\n",
      "Epoch: 14/20... Training loss: 0.1079\n",
      "Epoch: 14/20... Training loss: 0.1089\n",
      "Epoch: 14/20... Training loss: 0.1057\n",
      "Epoch: 14/20... Training loss: 0.1064\n",
      "Epoch: 14/20... Training loss: 0.1064\n",
      "Epoch: 14/20... Training loss: 0.1104\n",
      "Epoch: 14/20... Training loss: 0.1069\n",
      "Epoch: 14/20... Training loss: 0.1032\n",
      "Epoch: 14/20... Training loss: 0.1144\n",
      "Epoch: 14/20... Training loss: 0.1071\n",
      "Epoch: 14/20... Training loss: 0.1107\n",
      "Epoch: 14/20... Training loss: 0.1076\n",
      "Epoch: 14/20... Training loss: 0.1032\n",
      "Epoch: 14/20... Training loss: 0.1063\n",
      "Epoch: 15/20... Training loss: 0.1026\n",
      "Epoch: 15/20... Training loss: 0.1021\n",
      "Epoch: 15/20... Training loss: 0.1049\n",
      "Epoch: 15/20... Training loss: 0.1057\n",
      "Epoch: 15/20... Training loss: 0.1040\n",
      "Epoch: 15/20... Training loss: 0.1066\n",
      "Epoch: 15/20... Training loss: 0.1037\n",
      "Epoch: 15/20... Training loss: 0.1073\n",
      "Epoch: 15/20... Training loss: 0.1040\n",
      "Epoch: 15/20... Training loss: 0.1031\n",
      "Epoch: 15/20... Training loss: 0.1010\n",
      "Epoch: 15/20... Training loss: 0.1084\n",
      "Epoch: 15/20... Training loss: 0.1056\n",
      "Epoch: 15/20... Training loss: 0.1072\n",
      "Epoch: 15/20... Training loss: 0.1042\n",
      "Epoch: 15/20... Training loss: 0.1086\n",
      "Epoch: 15/20... Training loss: 0.1003\n",
      "Epoch: 15/20... Training loss: 0.1028\n",
      "Epoch: 15/20... Training loss: 0.1140\n",
      "Epoch: 15/20... Training loss: 0.1063\n",
      "Epoch: 15/20... Training loss: 0.1012\n",
      "Epoch: 15/20... Training loss: 0.1066\n",
      "Epoch: 15/20... Training loss: 0.1033\n",
      "Epoch: 15/20... Training loss: 0.1092\n",
      "Epoch: 15/20... Training loss: 0.1067\n",
      "Epoch: 15/20... Training loss: 0.1083\n",
      "Epoch: 15/20... Training loss: 0.1076\n",
      "Epoch: 15/20... Training loss: 0.1033\n",
      "Epoch: 15/20... Training loss: 0.1049\n",
      "Epoch: 15/20... Training loss: 0.1036\n",
      "Epoch: 15/20... Training loss: 0.1052\n",
      "Epoch: 15/20... Training loss: 0.0997\n",
      "Epoch: 15/20... Training loss: 0.1021\n",
      "Epoch: 15/20... Training loss: 0.1020\n",
      "Epoch: 15/20... Training loss: 0.1058\n",
      "Epoch: 15/20... Training loss: 0.1050\n",
      "Epoch: 15/20... Training loss: 0.1092\n",
      "Epoch: 15/20... Training loss: 0.1010\n",
      "Epoch: 15/20... Training loss: 0.1056\n",
      "Epoch: 15/20... Training loss: 0.1051\n",
      "Epoch: 15/20... Training loss: 0.1024\n",
      "Epoch: 15/20... Training loss: 0.1051\n",
      "Epoch: 15/20... Training loss: 0.1005\n",
      "Epoch: 15/20... Training loss: 0.1055\n",
      "Epoch: 15/20... Training loss: 0.0995\n",
      "Epoch: 15/20... Training loss: 0.1069\n",
      "Epoch: 15/20... Training loss: 0.1063\n",
      "Epoch: 15/20... Training loss: 0.1078\n",
      "Epoch: 15/20... Training loss: 0.1084\n",
      "Epoch: 15/20... Training loss: 0.1063\n",
      "Epoch: 15/20... Training loss: 0.1023\n",
      "Epoch: 15/20... Training loss: 0.1010\n",
      "Epoch: 15/20... Training loss: 0.1048\n",
      "Epoch: 15/20... Training loss: 0.1063\n",
      "Epoch: 15/20... Training loss: 0.0988\n",
      "Epoch: 15/20... Training loss: 0.1023\n",
      "Epoch: 15/20... Training loss: 0.0990\n",
      "Epoch: 15/20... Training loss: 0.1005\n",
      "Epoch: 15/20... Training loss: 0.0986\n",
      "Epoch: 15/20... Training loss: 0.0995\n",
      "Epoch: 15/20... Training loss: 0.0996\n",
      "Epoch: 15/20... Training loss: 0.1043\n",
      "Epoch: 15/20... Training loss: 0.1089\n",
      "Epoch: 15/20... Training loss: 0.1088\n",
      "Epoch: 15/20... Training loss: 0.1091\n",
      "Epoch: 15/20... Training loss: 0.1050\n",
      "Epoch: 15/20... Training loss: 0.1074\n",
      "Epoch: 15/20... Training loss: 0.1060\n",
      "Epoch: 15/20... Training loss: 0.1037\n",
      "Epoch: 15/20... Training loss: 0.1088\n",
      "Epoch: 15/20... Training loss: 0.1040\n",
      "Epoch: 15/20... Training loss: 0.1038\n",
      "Epoch: 15/20... Training loss: 0.1064\n",
      "Epoch: 15/20... Training loss: 0.1072\n",
      "Epoch: 15/20... Training loss: 0.1018\n",
      "Epoch: 15/20... Training loss: 0.1068\n",
      "Epoch: 15/20... Training loss: 0.1057\n",
      "Epoch: 15/20... Training loss: 0.1064\n",
      "Epoch: 15/20... Training loss: 0.1130\n",
      "Epoch: 15/20... Training loss: 0.1033\n",
      "Epoch: 15/20... Training loss: 0.1028\n",
      "Epoch: 15/20... Training loss: 0.1005\n",
      "Epoch: 15/20... Training loss: 0.1036\n",
      "Epoch: 15/20... Training loss: 0.1069\n",
      "Epoch: 15/20... Training loss: 0.1060\n",
      "Epoch: 15/20... Training loss: 0.1063\n",
      "Epoch: 15/20... Training loss: 0.1109\n",
      "Epoch: 15/20... Training loss: 0.1093\n",
      "Epoch: 15/20... Training loss: 0.1063\n",
      "Epoch: 15/20... Training loss: 0.0985\n",
      "Epoch: 15/20... Training loss: 0.0963\n",
      "Epoch: 15/20... Training loss: 0.0981\n",
      "Epoch: 15/20... Training loss: 0.1044\n",
      "Epoch: 15/20... Training loss: 0.1110\n",
      "Epoch: 15/20... Training loss: 0.1020\n",
      "Epoch: 15/20... Training loss: 0.1018\n",
      "Epoch: 15/20... Training loss: 0.1116\n",
      "Epoch: 15/20... Training loss: 0.1002\n",
      "Epoch: 15/20... Training loss: 0.1016\n",
      "Epoch: 15/20... Training loss: 0.1083\n",
      "Epoch: 15/20... Training loss: 0.1055\n",
      "Epoch: 15/20... Training loss: 0.1036\n",
      "Epoch: 15/20... Training loss: 0.1013\n",
      "Epoch: 15/20... Training loss: 0.1002\n",
      "Epoch: 15/20... Training loss: 0.1054\n",
      "Epoch: 15/20... Training loss: 0.1038\n",
      "Epoch: 15/20... Training loss: 0.1076\n",
      "Epoch: 15/20... Training loss: 0.1051\n",
      "Epoch: 15/20... Training loss: 0.1031\n",
      "Epoch: 15/20... Training loss: 0.1030\n",
      "Epoch: 15/20... Training loss: 0.1153\n",
      "Epoch: 15/20... Training loss: 0.1075\n",
      "Epoch: 15/20... Training loss: 0.1036\n",
      "Epoch: 15/20... Training loss: 0.1047\n",
      "Epoch: 15/20... Training loss: 0.1052\n",
      "Epoch: 15/20... Training loss: 0.1039\n",
      "Epoch: 15/20... Training loss: 0.0995\n",
      "Epoch: 15/20... Training loss: 0.1038\n",
      "Epoch: 15/20... Training loss: 0.1101\n",
      "Epoch: 15/20... Training loss: 0.1093\n",
      "Epoch: 15/20... Training loss: 0.0970\n",
      "Epoch: 15/20... Training loss: 0.1005\n",
      "Epoch: 15/20... Training loss: 0.1074\n",
      "Epoch: 15/20... Training loss: 0.1001\n",
      "Epoch: 15/20... Training loss: 0.0973\n",
      "Epoch: 15/20... Training loss: 0.1057\n",
      "Epoch: 15/20... Training loss: 0.1055\n",
      "Epoch: 15/20... Training loss: 0.0992\n",
      "Epoch: 15/20... Training loss: 0.1016\n",
      "Epoch: 15/20... Training loss: 0.1037\n",
      "Epoch: 15/20... Training loss: 0.1011\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.1048\n",
      "Epoch: 15/20... Training loss: 0.1062\n",
      "Epoch: 15/20... Training loss: 0.1012\n",
      "Epoch: 15/20... Training loss: 0.1126\n",
      "Epoch: 15/20... Training loss: 0.1104\n",
      "Epoch: 15/20... Training loss: 0.1048\n",
      "Epoch: 15/20... Training loss: 0.1062\n",
      "Epoch: 15/20... Training loss: 0.1038\n",
      "Epoch: 15/20... Training loss: 0.0997\n",
      "Epoch: 15/20... Training loss: 0.1046\n",
      "Epoch: 15/20... Training loss: 0.0995\n",
      "Epoch: 15/20... Training loss: 0.1044\n",
      "Epoch: 15/20... Training loss: 0.1091\n",
      "Epoch: 15/20... Training loss: 0.1148\n",
      "Epoch: 15/20... Training loss: 0.1045\n",
      "Epoch: 15/20... Training loss: 0.0985\n",
      "Epoch: 15/20... Training loss: 0.1050\n",
      "Epoch: 15/20... Training loss: 0.1004\n",
      "Epoch: 15/20... Training loss: 0.1062\n",
      "Epoch: 15/20... Training loss: 0.1051\n",
      "Epoch: 15/20... Training loss: 0.1070\n",
      "Epoch: 15/20... Training loss: 0.1069\n",
      "Epoch: 15/20... Training loss: 0.1057\n",
      "Epoch: 15/20... Training loss: 0.1051\n",
      "Epoch: 15/20... Training loss: 0.1025\n",
      "Epoch: 15/20... Training loss: 0.1061\n",
      "Epoch: 15/20... Training loss: 0.1089\n",
      "Epoch: 15/20... Training loss: 0.1035\n",
      "Epoch: 15/20... Training loss: 0.1064\n",
      "Epoch: 15/20... Training loss: 0.1040\n",
      "Epoch: 15/20... Training loss: 0.1018\n",
      "Epoch: 15/20... Training loss: 0.1092\n",
      "Epoch: 15/20... Training loss: 0.1044\n",
      "Epoch: 15/20... Training loss: 0.1018\n",
      "Epoch: 15/20... Training loss: 0.1064\n",
      "Epoch: 15/20... Training loss: 0.1046\n",
      "Epoch: 15/20... Training loss: 0.0986\n",
      "Epoch: 15/20... Training loss: 0.0988\n",
      "Epoch: 15/20... Training loss: 0.1060\n",
      "Epoch: 15/20... Training loss: 0.1042\n",
      "Epoch: 15/20... Training loss: 0.1037\n",
      "Epoch: 15/20... Training loss: 0.1077\n",
      "Epoch: 15/20... Training loss: 0.1034\n",
      "Epoch: 15/20... Training loss: 0.1075\n",
      "Epoch: 15/20... Training loss: 0.1020\n",
      "Epoch: 15/20... Training loss: 0.1074\n",
      "Epoch: 15/20... Training loss: 0.1058\n",
      "Epoch: 15/20... Training loss: 0.1075\n",
      "Epoch: 15/20... Training loss: 0.1056\n",
      "Epoch: 15/20... Training loss: 0.1077\n",
      "Epoch: 15/20... Training loss: 0.1081\n",
      "Epoch: 15/20... Training loss: 0.1058\n",
      "Epoch: 15/20... Training loss: 0.1053\n",
      "Epoch: 15/20... Training loss: 0.1002\n",
      "Epoch: 15/20... Training loss: 0.1050\n",
      "Epoch: 15/20... Training loss: 0.1109\n",
      "Epoch: 15/20... Training loss: 0.1089\n",
      "Epoch: 15/20... Training loss: 0.1047\n",
      "Epoch: 15/20... Training loss: 0.1062\n",
      "Epoch: 15/20... Training loss: 0.1060\n",
      "Epoch: 15/20... Training loss: 0.1013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/20... Training loss: 0.1096\n",
      "Epoch: 15/20... Training loss: 0.1039\n",
      "Epoch: 15/20... Training loss: 0.0995\n",
      "Epoch: 15/20... Training loss: 0.1042\n",
      "Epoch: 15/20... Training loss: 0.0964\n",
      "Epoch: 15/20... Training loss: 0.1041\n",
      "Epoch: 15/20... Training loss: 0.1082\n",
      "Epoch: 15/20... Training loss: 0.1045\n",
      "Epoch: 15/20... Training loss: 0.1033\n",
      "Epoch: 15/20... Training loss: 0.1056\n",
      "Epoch: 15/20... Training loss: 0.1042\n",
      "Epoch: 15/20... Training loss: 0.1042\n",
      "Epoch: 15/20... Training loss: 0.1071\n",
      "Epoch: 15/20... Training loss: 0.1105\n",
      "Epoch: 15/20... Training loss: 0.1059\n",
      "Epoch: 15/20... Training loss: 0.1022\n",
      "Epoch: 15/20... Training loss: 0.1018\n",
      "Epoch: 15/20... Training loss: 0.0983\n",
      "Epoch: 15/20... Training loss: 0.1038\n",
      "Epoch: 15/20... Training loss: 0.1054\n",
      "Epoch: 15/20... Training loss: 0.1053\n",
      "Epoch: 15/20... Training loss: 0.1081\n",
      "Epoch: 15/20... Training loss: 0.0999\n",
      "Epoch: 15/20... Training loss: 0.1029\n",
      "Epoch: 15/20... Training loss: 0.1066\n",
      "Epoch: 15/20... Training loss: 0.1022\n",
      "Epoch: 15/20... Training loss: 0.1038\n",
      "Epoch: 15/20... Training loss: 0.1121\n",
      "Epoch: 15/20... Training loss: 0.1081\n",
      "Epoch: 15/20... Training loss: 0.1044\n",
      "Epoch: 15/20... Training loss: 0.1074\n",
      "Epoch: 15/20... Training loss: 0.1060\n",
      "Epoch: 15/20... Training loss: 0.1033\n",
      "Epoch: 15/20... Training loss: 0.1058\n",
      "Epoch: 15/20... Training loss: 0.1085\n",
      "Epoch: 15/20... Training loss: 0.1095\n",
      "Epoch: 15/20... Training loss: 0.1091\n",
      "Epoch: 15/20... Training loss: 0.1054\n",
      "Epoch: 15/20... Training loss: 0.1089\n",
      "Epoch: 15/20... Training loss: 0.1059\n",
      "Epoch: 15/20... Training loss: 0.1071\n",
      "Epoch: 15/20... Training loss: 0.1060\n",
      "Epoch: 15/20... Training loss: 0.1037\n",
      "Epoch: 15/20... Training loss: 0.1037\n",
      "Epoch: 15/20... Training loss: 0.1100\n",
      "Epoch: 15/20... Training loss: 0.1090\n",
      "Epoch: 15/20... Training loss: 0.1024\n",
      "Epoch: 15/20... Training loss: 0.1021\n",
      "Epoch: 15/20... Training loss: 0.1053\n",
      "Epoch: 15/20... Training loss: 0.1043\n",
      "Epoch: 15/20... Training loss: 0.1085\n",
      "Epoch: 15/20... Training loss: 0.1037\n",
      "Epoch: 15/20... Training loss: 0.1126\n",
      "Epoch: 15/20... Training loss: 0.1044\n",
      "Epoch: 15/20... Training loss: 0.1113\n",
      "Epoch: 15/20... Training loss: 0.1087\n",
      "Epoch: 15/20... Training loss: 0.1079\n",
      "Epoch: 15/20... Training loss: 0.1025\n",
      "Epoch: 15/20... Training loss: 0.1062\n",
      "Epoch: 15/20... Training loss: 0.1072\n",
      "Epoch: 15/20... Training loss: 0.1035\n",
      "Epoch: 15/20... Training loss: 0.0996\n",
      "Epoch: 15/20... Training loss: 0.1023\n",
      "Epoch: 15/20... Training loss: 0.1045\n",
      "Epoch: 15/20... Training loss: 0.1053\n",
      "Epoch: 15/20... Training loss: 0.1073\n",
      "Epoch: 15/20... Training loss: 0.1058\n",
      "Epoch: 15/20... Training loss: 0.1063\n",
      "Epoch: 15/20... Training loss: 0.1003\n",
      "Epoch: 15/20... Training loss: 0.1036\n",
      "Epoch: 15/20... Training loss: 0.0994\n",
      "Epoch: 15/20... Training loss: 0.1066\n",
      "Epoch: 15/20... Training loss: 0.1050\n",
      "Epoch: 15/20... Training loss: 0.1045\n",
      "Epoch: 15/20... Training loss: 0.1020\n",
      "Epoch: 15/20... Training loss: 0.1068\n",
      "Epoch: 15/20... Training loss: 0.1083\n",
      "Epoch: 15/20... Training loss: 0.1090\n",
      "Epoch: 15/20... Training loss: 0.1026\n",
      "Epoch: 15/20... Training loss: 0.1043\n",
      "Epoch: 15/20... Training loss: 0.0988\n",
      "Epoch: 15/20... Training loss: 0.1055\n",
      "Epoch: 15/20... Training loss: 0.1046\n",
      "Epoch: 15/20... Training loss: 0.1012\n",
      "Epoch: 15/20... Training loss: 0.1015\n",
      "Epoch: 15/20... Training loss: 0.1051\n",
      "Epoch: 15/20... Training loss: 0.1052\n",
      "Epoch: 15/20... Training loss: 0.1035\n",
      "Epoch: 15/20... Training loss: 0.1023\n",
      "Epoch: 15/20... Training loss: 0.1079\n",
      "Epoch: 15/20... Training loss: 0.1023\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.1043\n",
      "Epoch: 15/20... Training loss: 0.1071\n",
      "Epoch: 15/20... Training loss: 0.1082\n",
      "Epoch: 15/20... Training loss: 0.1052\n",
      "Epoch: 15/20... Training loss: 0.1057\n",
      "Epoch: 15/20... Training loss: 0.1056\n",
      "Epoch: 15/20... Training loss: 0.1095\n",
      "Epoch: 15/20... Training loss: 0.1062\n",
      "Epoch: 15/20... Training loss: 0.1024\n",
      "Epoch: 15/20... Training loss: 0.1136\n",
      "Epoch: 15/20... Training loss: 0.1064\n",
      "Epoch: 15/20... Training loss: 0.1098\n",
      "Epoch: 15/20... Training loss: 0.1067\n",
      "Epoch: 15/20... Training loss: 0.1024\n",
      "Epoch: 15/20... Training loss: 0.1055\n",
      "Epoch: 16/20... Training loss: 0.1018\n",
      "Epoch: 16/20... Training loss: 0.1014\n",
      "Epoch: 16/20... Training loss: 0.1043\n",
      "Epoch: 16/20... Training loss: 0.1051\n",
      "Epoch: 16/20... Training loss: 0.1034\n",
      "Epoch: 16/20... Training loss: 0.1059\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.1066\n",
      "Epoch: 16/20... Training loss: 0.1033\n",
      "Epoch: 16/20... Training loss: 0.1025\n",
      "Epoch: 16/20... Training loss: 0.1002\n",
      "Epoch: 16/20... Training loss: 0.1076\n",
      "Epoch: 16/20... Training loss: 0.1050\n",
      "Epoch: 16/20... Training loss: 0.1064\n",
      "Epoch: 16/20... Training loss: 0.1037\n",
      "Epoch: 16/20... Training loss: 0.1078\n",
      "Epoch: 16/20... Training loss: 0.0997\n",
      "Epoch: 16/20... Training loss: 0.1020\n",
      "Epoch: 16/20... Training loss: 0.1132\n",
      "Epoch: 16/20... Training loss: 0.1056\n",
      "Epoch: 16/20... Training loss: 0.1002\n",
      "Epoch: 16/20... Training loss: 0.1060\n",
      "Epoch: 16/20... Training loss: 0.1024\n",
      "Epoch: 16/20... Training loss: 0.1084\n",
      "Epoch: 16/20... Training loss: 0.1060\n",
      "Epoch: 16/20... Training loss: 0.1076\n",
      "Epoch: 16/20... Training loss: 0.1070\n",
      "Epoch: 16/20... Training loss: 0.1027\n",
      "Epoch: 16/20... Training loss: 0.1041\n",
      "Epoch: 16/20... Training loss: 0.1029\n",
      "Epoch: 16/20... Training loss: 0.1046\n",
      "Epoch: 16/20... Training loss: 0.0990\n",
      "Epoch: 16/20... Training loss: 0.1015\n",
      "Epoch: 16/20... Training loss: 0.1015\n",
      "Epoch: 16/20... Training loss: 0.1052\n",
      "Epoch: 16/20... Training loss: 0.1045\n",
      "Epoch: 16/20... Training loss: 0.1083\n",
      "Epoch: 16/20... Training loss: 0.1004\n",
      "Epoch: 16/20... Training loss: 0.1049\n",
      "Epoch: 16/20... Training loss: 0.1044\n",
      "Epoch: 16/20... Training loss: 0.1016\n",
      "Epoch: 16/20... Training loss: 0.1043\n",
      "Epoch: 16/20... Training loss: 0.0998\n",
      "Epoch: 16/20... Training loss: 0.1048\n",
      "Epoch: 16/20... Training loss: 0.0988\n",
      "Epoch: 16/20... Training loss: 0.1062\n",
      "Epoch: 16/20... Training loss: 0.1056\n",
      "Epoch: 16/20... Training loss: 0.1070\n",
      "Epoch: 16/20... Training loss: 0.1079\n",
      "Epoch: 16/20... Training loss: 0.1054\n",
      "Epoch: 16/20... Training loss: 0.1016\n",
      "Epoch: 16/20... Training loss: 0.1003\n",
      "Epoch: 16/20... Training loss: 0.1041\n",
      "Epoch: 16/20... Training loss: 0.1055\n",
      "Epoch: 16/20... Training loss: 0.0980\n",
      "Epoch: 16/20... Training loss: 0.1016\n",
      "Epoch: 16/20... Training loss: 0.0983\n",
      "Epoch: 16/20... Training loss: 0.0998\n",
      "Epoch: 16/20... Training loss: 0.0979\n",
      "Epoch: 16/20... Training loss: 0.0989\n",
      "Epoch: 16/20... Training loss: 0.0989\n",
      "Epoch: 16/20... Training loss: 0.1036\n",
      "Epoch: 16/20... Training loss: 0.1081\n",
      "Epoch: 16/20... Training loss: 0.1080\n",
      "Epoch: 16/20... Training loss: 0.1084\n",
      "Epoch: 16/20... Training loss: 0.1043\n",
      "Epoch: 16/20... Training loss: 0.1066\n",
      "Epoch: 16/20... Training loss: 0.1052\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.1079\n",
      "Epoch: 16/20... Training loss: 0.1032\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.1054\n",
      "Epoch: 16/20... Training loss: 0.1066\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.1060\n",
      "Epoch: 16/20... Training loss: 0.1049\n",
      "Epoch: 16/20... Training loss: 0.1055\n",
      "Epoch: 16/20... Training loss: 0.1122\n",
      "Epoch: 16/20... Training loss: 0.1026\n",
      "Epoch: 16/20... Training loss: 0.1020\n",
      "Epoch: 16/20... Training loss: 0.0997\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.1062\n",
      "Epoch: 16/20... Training loss: 0.1053\n",
      "Epoch: 16/20... Training loss: 0.1056\n",
      "Epoch: 16/20... Training loss: 0.1100\n",
      "Epoch: 16/20... Training loss: 0.1086\n",
      "Epoch: 16/20... Training loss: 0.1055\n",
      "Epoch: 16/20... Training loss: 0.0979\n",
      "Epoch: 16/20... Training loss: 0.0955\n",
      "Epoch: 16/20... Training loss: 0.0975\n",
      "Epoch: 16/20... Training loss: 0.1036\n",
      "Epoch: 16/20... Training loss: 0.1103\n",
      "Epoch: 16/20... Training loss: 0.1013\n",
      "Epoch: 16/20... Training loss: 0.1011\n",
      "Epoch: 16/20... Training loss: 0.1107\n",
      "Epoch: 16/20... Training loss: 0.0995\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.1074\n",
      "Epoch: 16/20... Training loss: 0.1047\n",
      "Epoch: 16/20... Training loss: 0.1029\n",
      "Epoch: 16/20... Training loss: 0.1005\n",
      "Epoch: 16/20... Training loss: 0.0996\n",
      "Epoch: 16/20... Training loss: 0.1047\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.1070\n",
      "Epoch: 16/20... Training loss: 0.1045\n",
      "Epoch: 16/20... Training loss: 0.1023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/20... Training loss: 0.1023\n",
      "Epoch: 16/20... Training loss: 0.1145\n",
      "Epoch: 16/20... Training loss: 0.1068\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.1038\n",
      "Epoch: 16/20... Training loss: 0.1046\n",
      "Epoch: 16/20... Training loss: 0.1032\n",
      "Epoch: 16/20... Training loss: 0.0988\n",
      "Epoch: 16/20... Training loss: 0.1031\n",
      "Epoch: 16/20... Training loss: 0.1094\n",
      "Epoch: 16/20... Training loss: 0.1087\n",
      "Epoch: 16/20... Training loss: 0.0964\n",
      "Epoch: 16/20... Training loss: 0.0999\n",
      "Epoch: 16/20... Training loss: 0.1067\n",
      "Epoch: 16/20... Training loss: 0.0994\n",
      "Epoch: 16/20... Training loss: 0.0966\n",
      "Epoch: 16/20... Training loss: 0.1049\n",
      "Epoch: 16/20... Training loss: 0.1047\n",
      "Epoch: 16/20... Training loss: 0.0985\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.1006\n",
      "Epoch: 16/20... Training loss: 0.1022\n",
      "Epoch: 16/20... Training loss: 0.1041\n",
      "Epoch: 16/20... Training loss: 0.1054\n",
      "Epoch: 16/20... Training loss: 0.1006\n",
      "Epoch: 16/20... Training loss: 0.1118\n",
      "Epoch: 16/20... Training loss: 0.1097\n",
      "Epoch: 16/20... Training loss: 0.1041\n",
      "Epoch: 16/20... Training loss: 0.1056\n",
      "Epoch: 16/20... Training loss: 0.1031\n",
      "Epoch: 16/20... Training loss: 0.0990\n",
      "Epoch: 16/20... Training loss: 0.1038\n",
      "Epoch: 16/20... Training loss: 0.0988\n",
      "Epoch: 16/20... Training loss: 0.1037\n",
      "Epoch: 16/20... Training loss: 0.1083\n",
      "Epoch: 16/20... Training loss: 0.1141\n",
      "Epoch: 16/20... Training loss: 0.1038\n",
      "Epoch: 16/20... Training loss: 0.0980\n",
      "Epoch: 16/20... Training loss: 0.1042\n",
      "Epoch: 16/20... Training loss: 0.0998\n",
      "Epoch: 16/20... Training loss: 0.1055\n",
      "Epoch: 16/20... Training loss: 0.1044\n",
      "Epoch: 16/20... Training loss: 0.1063\n",
      "Epoch: 16/20... Training loss: 0.1063\n",
      "Epoch: 16/20... Training loss: 0.1049\n",
      "Epoch: 16/20... Training loss: 0.1044\n",
      "Epoch: 16/20... Training loss: 0.1018\n",
      "Epoch: 16/20... Training loss: 0.1054\n",
      "Epoch: 16/20... Training loss: 0.1082\n",
      "Epoch: 16/20... Training loss: 0.1028\n",
      "Epoch: 16/20... Training loss: 0.1057\n",
      "Epoch: 16/20... Training loss: 0.1032\n",
      "Epoch: 16/20... Training loss: 0.1013\n",
      "Epoch: 16/20... Training loss: 0.1083\n",
      "Epoch: 16/20... Training loss: 0.1037\n",
      "Epoch: 16/20... Training loss: 0.1011\n",
      "Epoch: 16/20... Training loss: 0.1056\n",
      "Epoch: 16/20... Training loss: 0.1039\n",
      "Epoch: 16/20... Training loss: 0.0980\n",
      "Epoch: 16/20... Training loss: 0.0981\n",
      "Epoch: 16/20... Training loss: 0.1053\n",
      "Epoch: 16/20... Training loss: 0.1035\n",
      "Epoch: 16/20... Training loss: 0.1029\n",
      "Epoch: 16/20... Training loss: 0.1069\n",
      "Epoch: 16/20... Training loss: 0.1026\n",
      "Epoch: 16/20... Training loss: 0.1068\n",
      "Epoch: 16/20... Training loss: 0.1014\n",
      "Epoch: 16/20... Training loss: 0.1065\n",
      "Epoch: 16/20... Training loss: 0.1050\n",
      "Epoch: 16/20... Training loss: 0.1068\n",
      "Epoch: 16/20... Training loss: 0.1049\n",
      "Epoch: 16/20... Training loss: 0.1069\n",
      "Epoch: 16/20... Training loss: 0.1074\n",
      "Epoch: 16/20... Training loss: 0.1050\n",
      "Epoch: 16/20... Training loss: 0.1046\n",
      "Epoch: 16/20... Training loss: 0.0995\n",
      "Epoch: 16/20... Training loss: 0.1044\n",
      "Epoch: 16/20... Training loss: 0.1102\n",
      "Epoch: 16/20... Training loss: 0.1085\n",
      "Epoch: 16/20... Training loss: 0.1040\n",
      "Epoch: 16/20... Training loss: 0.1056\n",
      "Epoch: 16/20... Training loss: 0.1055\n",
      "Epoch: 16/20... Training loss: 0.1005\n",
      "Epoch: 16/20... Training loss: 0.1090\n",
      "Epoch: 16/20... Training loss: 0.1033\n",
      "Epoch: 16/20... Training loss: 0.0988\n",
      "Epoch: 16/20... Training loss: 0.1036\n",
      "Epoch: 16/20... Training loss: 0.0958\n",
      "Epoch: 16/20... Training loss: 0.1035\n",
      "Epoch: 16/20... Training loss: 0.1074\n",
      "Epoch: 16/20... Training loss: 0.1038\n",
      "Epoch: 16/20... Training loss: 0.1027\n",
      "Epoch: 16/20... Training loss: 0.1048\n",
      "Epoch: 16/20... Training loss: 0.1036\n",
      "Epoch: 16/20... Training loss: 0.1034\n",
      "Epoch: 16/20... Training loss: 0.1064\n",
      "Epoch: 16/20... Training loss: 0.1099\n",
      "Epoch: 16/20... Training loss: 0.1052\n",
      "Epoch: 16/20... Training loss: 0.1015\n",
      "Epoch: 16/20... Training loss: 0.1012\n",
      "Epoch: 16/20... Training loss: 0.0977\n",
      "Epoch: 16/20... Training loss: 0.1031\n",
      "Epoch: 16/20... Training loss: 0.1047\n",
      "Epoch: 16/20... Training loss: 0.1046\n",
      "Epoch: 16/20... Training loss: 0.1074\n",
      "Epoch: 16/20... Training loss: 0.0991\n",
      "Epoch: 16/20... Training loss: 0.1022\n",
      "Epoch: 16/20... Training loss: 0.1059\n",
      "Epoch: 16/20... Training loss: 0.1014\n",
      "Epoch: 16/20... Training loss: 0.1032\n",
      "Epoch: 16/20... Training loss: 0.1114\n",
      "Epoch: 16/20... Training loss: 0.1075\n",
      "Epoch: 16/20... Training loss: 0.1037\n",
      "Epoch: 16/20... Training loss: 0.1067\n",
      "Epoch: 16/20... Training loss: 0.1055\n",
      "Epoch: 16/20... Training loss: 0.1025\n",
      "Epoch: 16/20... Training loss: 0.1051\n",
      "Epoch: 16/20... Training loss: 0.1078\n",
      "Epoch: 16/20... Training loss: 0.1088\n",
      "Epoch: 16/20... Training loss: 0.1084\n",
      "Epoch: 16/20... Training loss: 0.1048\n",
      "Epoch: 16/20... Training loss: 0.1082\n",
      "Epoch: 16/20... Training loss: 0.1051\n",
      "Epoch: 16/20... Training loss: 0.1064\n",
      "Epoch: 16/20... Training loss: 0.1052\n",
      "Epoch: 16/20... Training loss: 0.1031\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.1092\n",
      "Epoch: 16/20... Training loss: 0.1083\n",
      "Epoch: 16/20... Training loss: 0.1016\n",
      "Epoch: 16/20... Training loss: 0.1014\n",
      "Epoch: 16/20... Training loss: 0.1045\n",
      "Epoch: 16/20... Training loss: 0.1034\n",
      "Epoch: 16/20... Training loss: 0.1076\n",
      "Epoch: 16/20... Training loss: 0.1031\n",
      "Epoch: 16/20... Training loss: 0.1117\n",
      "Epoch: 16/20... Training loss: 0.1038\n",
      "Epoch: 16/20... Training loss: 0.1105\n",
      "Epoch: 16/20... Training loss: 0.1080\n",
      "Epoch: 16/20... Training loss: 0.1071\n",
      "Epoch: 16/20... Training loss: 0.1019\n",
      "Epoch: 16/20... Training loss: 0.1055\n",
      "Epoch: 16/20... Training loss: 0.1064\n",
      "Epoch: 16/20... Training loss: 0.1028\n",
      "Epoch: 16/20... Training loss: 0.0990\n",
      "Epoch: 16/20... Training loss: 0.1016\n",
      "Epoch: 16/20... Training loss: 0.1038\n",
      "Epoch: 16/20... Training loss: 0.1047\n",
      "Epoch: 16/20... Training loss: 0.1065\n",
      "Epoch: 16/20... Training loss: 0.1051\n",
      "Epoch: 16/20... Training loss: 0.1057\n",
      "Epoch: 16/20... Training loss: 0.0997\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.0988\n",
      "Epoch: 16/20... Training loss: 0.1060\n",
      "Epoch: 16/20... Training loss: 0.1044\n",
      "Epoch: 16/20... Training loss: 0.1040\n",
      "Epoch: 16/20... Training loss: 0.1013\n",
      "Epoch: 16/20... Training loss: 0.1061\n",
      "Epoch: 16/20... Training loss: 0.1076\n",
      "Epoch: 16/20... Training loss: 0.1082\n",
      "Epoch: 16/20... Training loss: 0.1020\n",
      "Epoch: 16/20... Training loss: 0.1036\n",
      "Epoch: 16/20... Training loss: 0.0982\n",
      "Epoch: 16/20... Training loss: 0.1049\n",
      "Epoch: 16/20... Training loss: 0.1040\n",
      "Epoch: 16/20... Training loss: 0.1006\n",
      "Epoch: 16/20... Training loss: 0.1009\n",
      "Epoch: 16/20... Training loss: 0.1043\n",
      "Epoch: 16/20... Training loss: 0.1045\n",
      "Epoch: 16/20... Training loss: 0.1029\n",
      "Epoch: 16/20... Training loss: 0.1017\n",
      "Epoch: 16/20... Training loss: 0.1072\n",
      "Epoch: 16/20... Training loss: 0.1018\n",
      "Epoch: 16/20... Training loss: 0.1002\n",
      "Epoch: 16/20... Training loss: 0.1037\n",
      "Epoch: 16/20... Training loss: 0.1064\n",
      "Epoch: 16/20... Training loss: 0.1075\n",
      "Epoch: 16/20... Training loss: 0.1046\n",
      "Epoch: 16/20... Training loss: 0.1052\n",
      "Epoch: 16/20... Training loss: 0.1051\n",
      "Epoch: 16/20... Training loss: 0.1089\n",
      "Epoch: 16/20... Training loss: 0.1055\n",
      "Epoch: 16/20... Training loss: 0.1017\n",
      "Epoch: 16/20... Training loss: 0.1130\n",
      "Epoch: 16/20... Training loss: 0.1057\n",
      "Epoch: 16/20... Training loss: 0.1092\n",
      "Epoch: 16/20... Training loss: 0.1061\n",
      "Epoch: 16/20... Training loss: 0.1019\n",
      "Epoch: 16/20... Training loss: 0.1048\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.1009\n",
      "Epoch: 17/20... Training loss: 0.1035\n",
      "Epoch: 17/20... Training loss: 0.1045\n",
      "Epoch: 17/20... Training loss: 0.1027\n",
      "Epoch: 17/20... Training loss: 0.1053\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.1058\n",
      "Epoch: 17/20... Training loss: 0.1026\n",
      "Epoch: 17/20... Training loss: 0.1015\n",
      "Epoch: 17/20... Training loss: 0.0995\n",
      "Epoch: 17/20... Training loss: 0.1068\n",
      "Epoch: 17/20... Training loss: 0.1041\n",
      "Epoch: 17/20... Training loss: 0.1059\n",
      "Epoch: 17/20... Training loss: 0.1030\n",
      "Epoch: 17/20... Training loss: 0.1073\n",
      "Epoch: 17/20... Training loss: 0.0988\n",
      "Epoch: 17/20... Training loss: 0.1014\n",
      "Epoch: 17/20... Training loss: 0.1124\n",
      "Epoch: 17/20... Training loss: 0.1050\n",
      "Epoch: 17/20... Training loss: 0.0994\n",
      "Epoch: 17/20... Training loss: 0.1053\n",
      "Epoch: 17/20... Training loss: 0.1018\n",
      "Epoch: 17/20... Training loss: 0.1078\n",
      "Epoch: 17/20... Training loss: 0.1053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/20... Training loss: 0.1070\n",
      "Epoch: 17/20... Training loss: 0.1063\n",
      "Epoch: 17/20... Training loss: 0.1022\n",
      "Epoch: 17/20... Training loss: 0.1034\n",
      "Epoch: 17/20... Training loss: 0.1022\n",
      "Epoch: 17/20... Training loss: 0.1038\n",
      "Epoch: 17/20... Training loss: 0.0983\n",
      "Epoch: 17/20... Training loss: 0.1007\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.1046\n",
      "Epoch: 17/20... Training loss: 0.1038\n",
      "Epoch: 17/20... Training loss: 0.1074\n",
      "Epoch: 17/20... Training loss: 0.0998\n",
      "Epoch: 17/20... Training loss: 0.1041\n",
      "Epoch: 17/20... Training loss: 0.1036\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.1036\n",
      "Epoch: 17/20... Training loss: 0.0991\n",
      "Epoch: 17/20... Training loss: 0.1042\n",
      "Epoch: 17/20... Training loss: 0.0982\n",
      "Epoch: 17/20... Training loss: 0.1056\n",
      "Epoch: 17/20... Training loss: 0.1049\n",
      "Epoch: 17/20... Training loss: 0.1063\n",
      "Epoch: 17/20... Training loss: 0.1074\n",
      "Epoch: 17/20... Training loss: 0.1047\n",
      "Epoch: 17/20... Training loss: 0.1009\n",
      "Epoch: 17/20... Training loss: 0.0996\n",
      "Epoch: 17/20... Training loss: 0.1036\n",
      "Epoch: 17/20... Training loss: 0.1048\n",
      "Epoch: 17/20... Training loss: 0.0974\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.0977\n",
      "Epoch: 17/20... Training loss: 0.0992\n",
      "Epoch: 17/20... Training loss: 0.0973\n",
      "Epoch: 17/20... Training loss: 0.0984\n",
      "Epoch: 17/20... Training loss: 0.0983\n",
      "Epoch: 17/20... Training loss: 0.1030\n",
      "Epoch: 17/20... Training loss: 0.1074\n",
      "Epoch: 17/20... Training loss: 0.1072\n",
      "Epoch: 17/20... Training loss: 0.1079\n",
      "Epoch: 17/20... Training loss: 0.1037\n",
      "Epoch: 17/20... Training loss: 0.1060\n",
      "Epoch: 17/20... Training loss: 0.1045\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.1072\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.1048\n",
      "Epoch: 17/20... Training loss: 0.1060\n",
      "Epoch: 17/20... Training loss: 0.1002\n",
      "Epoch: 17/20... Training loss: 0.1053\n",
      "Epoch: 17/20... Training loss: 0.1043\n",
      "Epoch: 17/20... Training loss: 0.1047\n",
      "Epoch: 17/20... Training loss: 0.1116\n",
      "Epoch: 17/20... Training loss: 0.1020\n",
      "Epoch: 17/20... Training loss: 0.1014\n",
      "Epoch: 17/20... Training loss: 0.0990\n",
      "Epoch: 17/20... Training loss: 0.1025\n",
      "Epoch: 17/20... Training loss: 0.1055\n",
      "Epoch: 17/20... Training loss: 0.1047\n",
      "Epoch: 17/20... Training loss: 0.1050\n",
      "Epoch: 17/20... Training loss: 0.1092\n",
      "Epoch: 17/20... Training loss: 0.1080\n",
      "Epoch: 17/20... Training loss: 0.1048\n",
      "Epoch: 17/20... Training loss: 0.0974\n",
      "Epoch: 17/20... Training loss: 0.0949\n",
      "Epoch: 17/20... Training loss: 0.0971\n",
      "Epoch: 17/20... Training loss: 0.1029\n",
      "Epoch: 17/20... Training loss: 0.1096\n",
      "Epoch: 17/20... Training loss: 0.1007\n",
      "Epoch: 17/20... Training loss: 0.1005\n",
      "Epoch: 17/20... Training loss: 0.1098\n",
      "Epoch: 17/20... Training loss: 0.0989\n",
      "Epoch: 17/20... Training loss: 0.1005\n",
      "Epoch: 17/20... Training loss: 0.1065\n",
      "Epoch: 17/20... Training loss: 0.1039\n",
      "Epoch: 17/20... Training loss: 0.1023\n",
      "Epoch: 17/20... Training loss: 0.0998\n",
      "Epoch: 17/20... Training loss: 0.0990\n",
      "Epoch: 17/20... Training loss: 0.1040\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.1064\n",
      "Epoch: 17/20... Training loss: 0.1039\n",
      "Epoch: 17/20... Training loss: 0.1018\n",
      "Epoch: 17/20... Training loss: 0.1017\n",
      "Epoch: 17/20... Training loss: 0.1139\n",
      "Epoch: 17/20... Training loss: 0.1064\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.1031\n",
      "Epoch: 17/20... Training loss: 0.1040\n",
      "Epoch: 17/20... Training loss: 0.1026\n",
      "Epoch: 17/20... Training loss: 0.0983\n",
      "Epoch: 17/20... Training loss: 0.1025\n",
      "Epoch: 17/20... Training loss: 0.1089\n",
      "Epoch: 17/20... Training loss: 0.1082\n",
      "Epoch: 17/20... Training loss: 0.0959\n",
      "Epoch: 17/20... Training loss: 0.0994\n",
      "Epoch: 17/20... Training loss: 0.1061\n",
      "Epoch: 17/20... Training loss: 0.0988\n",
      "Epoch: 17/20... Training loss: 0.0959\n",
      "Epoch: 17/20... Training loss: 0.1044\n",
      "Epoch: 17/20... Training loss: 0.1042\n",
      "Epoch: 17/20... Training loss: 0.0980\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.1023\n",
      "Epoch: 17/20... Training loss: 0.1002\n",
      "Epoch: 17/20... Training loss: 0.1018\n",
      "Epoch: 17/20... Training loss: 0.1035\n",
      "Epoch: 17/20... Training loss: 0.1048\n",
      "Epoch: 17/20... Training loss: 0.1000\n",
      "Epoch: 17/20... Training loss: 0.1112\n",
      "Epoch: 17/20... Training loss: 0.1090\n",
      "Epoch: 17/20... Training loss: 0.1035\n",
      "Epoch: 17/20... Training loss: 0.1050\n",
      "Epoch: 17/20... Training loss: 0.1026\n",
      "Epoch: 17/20... Training loss: 0.0984\n",
      "Epoch: 17/20... Training loss: 0.1031\n",
      "Epoch: 17/20... Training loss: 0.0983\n",
      "Epoch: 17/20... Training loss: 0.1031\n",
      "Epoch: 17/20... Training loss: 0.1076\n",
      "Epoch: 17/20... Training loss: 0.1134\n",
      "Epoch: 17/20... Training loss: 0.1033\n",
      "Epoch: 17/20... Training loss: 0.0975\n",
      "Epoch: 17/20... Training loss: 0.1037\n",
      "Epoch: 17/20... Training loss: 0.0993\n",
      "Epoch: 17/20... Training loss: 0.1049\n",
      "Epoch: 17/20... Training loss: 0.1037\n",
      "Epoch: 17/20... Training loss: 0.1056\n",
      "Epoch: 17/20... Training loss: 0.1057\n",
      "Epoch: 17/20... Training loss: 0.1042\n",
      "Epoch: 17/20... Training loss: 0.1038\n",
      "Epoch: 17/20... Training loss: 0.1012\n",
      "Epoch: 17/20... Training loss: 0.1048\n",
      "Epoch: 17/20... Training loss: 0.1075\n",
      "Epoch: 17/20... Training loss: 0.1021\n",
      "Epoch: 17/20... Training loss: 0.1051\n",
      "Epoch: 17/20... Training loss: 0.1025\n",
      "Epoch: 17/20... Training loss: 0.1007\n",
      "Epoch: 17/20... Training loss: 0.1076\n",
      "Epoch: 17/20... Training loss: 0.1030\n",
      "Epoch: 17/20... Training loss: 0.1006\n",
      "Epoch: 17/20... Training loss: 0.1049\n",
      "Epoch: 17/20... Training loss: 0.1033\n",
      "Epoch: 17/20... Training loss: 0.0974\n",
      "Epoch: 17/20... Training loss: 0.0975\n",
      "Epoch: 17/20... Training loss: 0.1046\n",
      "Epoch: 17/20... Training loss: 0.1030\n",
      "Epoch: 17/20... Training loss: 0.1021\n",
      "Epoch: 17/20... Training loss: 0.1062\n",
      "Epoch: 17/20... Training loss: 0.1020\n",
      "Epoch: 17/20... Training loss: 0.1061\n",
      "Epoch: 17/20... Training loss: 0.1007\n",
      "Epoch: 17/20... Training loss: 0.1059\n",
      "Epoch: 17/20... Training loss: 0.1043\n",
      "Epoch: 17/20... Training loss: 0.1061\n",
      "Epoch: 17/20... Training loss: 0.1042\n",
      "Epoch: 17/20... Training loss: 0.1062\n",
      "Epoch: 17/20... Training loss: 0.1067\n",
      "Epoch: 17/20... Training loss: 0.1042\n",
      "Epoch: 17/20... Training loss: 0.1039\n",
      "Epoch: 17/20... Training loss: 0.0988\n",
      "Epoch: 17/20... Training loss: 0.1038\n",
      "Epoch: 17/20... Training loss: 0.1095\n",
      "Epoch: 17/20... Training loss: 0.1079\n",
      "Epoch: 17/20... Training loss: 0.1034\n",
      "Epoch: 17/20... Training loss: 0.1050\n",
      "Epoch: 17/20... Training loss: 0.1048\n",
      "Epoch: 17/20... Training loss: 0.1000\n",
      "Epoch: 17/20... Training loss: 0.1082\n",
      "Epoch: 17/20... Training loss: 0.1026\n",
      "Epoch: 17/20... Training loss: 0.0982\n",
      "Epoch: 17/20... Training loss: 0.1030\n",
      "Epoch: 17/20... Training loss: 0.0952\n",
      "Epoch: 17/20... Training loss: 0.1028\n",
      "Epoch: 17/20... Training loss: 0.1067\n",
      "Epoch: 17/20... Training loss: 0.1031\n",
      "Epoch: 17/20... Training loss: 0.1021\n",
      "Epoch: 17/20... Training loss: 0.1041\n",
      "Epoch: 17/20... Training loss: 0.1030\n",
      "Epoch: 17/20... Training loss: 0.1026\n",
      "Epoch: 17/20... Training loss: 0.1059\n",
      "Epoch: 17/20... Training loss: 0.1092\n",
      "Epoch: 17/20... Training loss: 0.1046\n",
      "Epoch: 17/20... Training loss: 0.1009\n",
      "Epoch: 17/20... Training loss: 0.1006\n",
      "Epoch: 17/20... Training loss: 0.0971\n",
      "Epoch: 17/20... Training loss: 0.1025\n",
      "Epoch: 17/20... Training loss: 0.1041\n",
      "Epoch: 17/20... Training loss: 0.1040\n",
      "Epoch: 17/20... Training loss: 0.1068\n",
      "Epoch: 17/20... Training loss: 0.0984\n",
      "Epoch: 17/20... Training loss: 0.1015\n",
      "Epoch: 17/20... Training loss: 0.1054\n",
      "Epoch: 17/20... Training loss: 0.1008\n",
      "Epoch: 17/20... Training loss: 0.1027\n",
      "Epoch: 17/20... Training loss: 0.1107\n",
      "Epoch: 17/20... Training loss: 0.1069\n",
      "Epoch: 17/20... Training loss: 0.1031\n",
      "Epoch: 17/20... Training loss: 0.1062\n",
      "Epoch: 17/20... Training loss: 0.1050\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.1045\n",
      "Epoch: 17/20... Training loss: 0.1072\n",
      "Epoch: 17/20... Training loss: 0.1083\n",
      "Epoch: 17/20... Training loss: 0.1077\n",
      "Epoch: 17/20... Training loss: 0.1042\n",
      "Epoch: 17/20... Training loss: 0.1077\n",
      "Epoch: 17/20... Training loss: 0.1043\n",
      "Epoch: 17/20... Training loss: 0.1057\n",
      "Epoch: 17/20... Training loss: 0.1045\n",
      "Epoch: 17/20... Training loss: 0.1025\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.1086\n",
      "Epoch: 17/20... Training loss: 0.1076\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.1009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/20... Training loss: 0.1038\n",
      "Epoch: 17/20... Training loss: 0.1026\n",
      "Epoch: 17/20... Training loss: 0.1069\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.1110\n",
      "Epoch: 17/20... Training loss: 0.1032\n",
      "Epoch: 17/20... Training loss: 0.1098\n",
      "Epoch: 17/20... Training loss: 0.1074\n",
      "Epoch: 17/20... Training loss: 0.1064\n",
      "Epoch: 17/20... Training loss: 0.1014\n",
      "Epoch: 17/20... Training loss: 0.1048\n",
      "Epoch: 17/20... Training loss: 0.1058\n",
      "Epoch: 17/20... Training loss: 0.1022\n",
      "Epoch: 17/20... Training loss: 0.0983\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.1032\n",
      "Epoch: 17/20... Training loss: 0.1041\n",
      "Epoch: 17/20... Training loss: 0.1058\n",
      "Epoch: 17/20... Training loss: 0.1044\n",
      "Epoch: 17/20... Training loss: 0.1051\n",
      "Epoch: 17/20... Training loss: 0.0991\n",
      "Epoch: 17/20... Training loss: 0.1023\n",
      "Epoch: 17/20... Training loss: 0.0982\n",
      "Epoch: 17/20... Training loss: 0.1054\n",
      "Epoch: 17/20... Training loss: 0.1037\n",
      "Epoch: 17/20... Training loss: 0.1034\n",
      "Epoch: 17/20... Training loss: 0.1007\n",
      "Epoch: 17/20... Training loss: 0.1056\n",
      "Epoch: 17/20... Training loss: 0.1069\n",
      "Epoch: 17/20... Training loss: 0.1076\n",
      "Epoch: 17/20... Training loss: 0.1015\n",
      "Epoch: 17/20... Training loss: 0.1029\n",
      "Epoch: 17/20... Training loss: 0.0977\n",
      "Epoch: 17/20... Training loss: 0.1043\n",
      "Epoch: 17/20... Training loss: 0.1034\n",
      "Epoch: 17/20... Training loss: 0.1001\n",
      "Epoch: 17/20... Training loss: 0.1002\n",
      "Epoch: 17/20... Training loss: 0.1037\n",
      "Epoch: 17/20... Training loss: 0.1039\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.1011\n",
      "Epoch: 17/20... Training loss: 0.1066\n",
      "Epoch: 17/20... Training loss: 0.1013\n",
      "Epoch: 17/20... Training loss: 0.0997\n",
      "Epoch: 17/20... Training loss: 0.1031\n",
      "Epoch: 17/20... Training loss: 0.1058\n",
      "Epoch: 17/20... Training loss: 0.1069\n",
      "Epoch: 17/20... Training loss: 0.1040\n",
      "Epoch: 17/20... Training loss: 0.1047\n",
      "Epoch: 17/20... Training loss: 0.1046\n",
      "Epoch: 17/20... Training loss: 0.1083\n",
      "Epoch: 17/20... Training loss: 0.1050\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.1124\n",
      "Epoch: 17/20... Training loss: 0.1051\n",
      "Epoch: 17/20... Training loss: 0.1085\n",
      "Epoch: 17/20... Training loss: 0.1056\n",
      "Epoch: 17/20... Training loss: 0.1013\n",
      "Epoch: 17/20... Training loss: 0.1042\n",
      "Epoch: 18/20... Training loss: 0.1005\n",
      "Epoch: 18/20... Training loss: 0.1004\n",
      "Epoch: 18/20... Training loss: 0.1030\n",
      "Epoch: 18/20... Training loss: 0.1041\n",
      "Epoch: 18/20... Training loss: 0.1022\n",
      "Epoch: 18/20... Training loss: 0.1048\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.1053\n",
      "Epoch: 18/20... Training loss: 0.1021\n",
      "Epoch: 18/20... Training loss: 0.1011\n",
      "Epoch: 18/20... Training loss: 0.0990\n",
      "Epoch: 18/20... Training loss: 0.1063\n",
      "Epoch: 18/20... Training loss: 0.1035\n",
      "Epoch: 18/20... Training loss: 0.1054\n",
      "Epoch: 18/20... Training loss: 0.1025\n",
      "Epoch: 18/20... Training loss: 0.1067\n",
      "Epoch: 18/20... Training loss: 0.0983\n",
      "Epoch: 18/20... Training loss: 0.1009\n",
      "Epoch: 18/20... Training loss: 0.1118\n",
      "Epoch: 18/20... Training loss: 0.1045\n",
      "Epoch: 18/20... Training loss: 0.0988\n",
      "Epoch: 18/20... Training loss: 0.1047\n",
      "Epoch: 18/20... Training loss: 0.1012\n",
      "Epoch: 18/20... Training loss: 0.1072\n",
      "Epoch: 18/20... Training loss: 0.1048\n",
      "Epoch: 18/20... Training loss: 0.1064\n",
      "Epoch: 18/20... Training loss: 0.1059\n",
      "Epoch: 18/20... Training loss: 0.1018\n",
      "Epoch: 18/20... Training loss: 0.1028\n",
      "Epoch: 18/20... Training loss: 0.1018\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.0979\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.1006\n",
      "Epoch: 18/20... Training loss: 0.1042\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.1069\n",
      "Epoch: 18/20... Training loss: 0.0994\n",
      "Epoch: 18/20... Training loss: 0.1035\n",
      "Epoch: 18/20... Training loss: 0.1031\n",
      "Epoch: 18/20... Training loss: 0.1004\n",
      "Epoch: 18/20... Training loss: 0.1030\n",
      "Epoch: 18/20... Training loss: 0.0986\n",
      "Epoch: 18/20... Training loss: 0.1035\n",
      "Epoch: 18/20... Training loss: 0.0976\n",
      "Epoch: 18/20... Training loss: 0.1049\n",
      "Epoch: 18/20... Training loss: 0.1044\n",
      "Epoch: 18/20... Training loss: 0.1057\n",
      "Epoch: 18/20... Training loss: 0.1069\n",
      "Epoch: 18/20... Training loss: 0.1041\n",
      "Epoch: 18/20... Training loss: 0.1003\n",
      "Epoch: 18/20... Training loss: 0.0991\n",
      "Epoch: 18/20... Training loss: 0.1031\n",
      "Epoch: 18/20... Training loss: 0.1042\n",
      "Epoch: 18/20... Training loss: 0.0969\n",
      "Epoch: 18/20... Training loss: 0.1005\n",
      "Epoch: 18/20... Training loss: 0.0973\n",
      "Epoch: 18/20... Training loss: 0.0987\n",
      "Epoch: 18/20... Training loss: 0.0967\n",
      "Epoch: 18/20... Training loss: 0.0979\n",
      "Epoch: 18/20... Training loss: 0.0977\n",
      "Epoch: 18/20... Training loss: 0.1025\n",
      "Epoch: 18/20... Training loss: 0.1069\n",
      "Epoch: 18/20... Training loss: 0.1066\n",
      "Epoch: 18/20... Training loss: 0.1074\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.1055\n",
      "Epoch: 18/20... Training loss: 0.1039\n",
      "Epoch: 18/20... Training loss: 0.1018\n",
      "Epoch: 18/20... Training loss: 0.1065\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.1042\n",
      "Epoch: 18/20... Training loss: 0.1056\n",
      "Epoch: 18/20... Training loss: 0.0997\n",
      "Epoch: 18/20... Training loss: 0.1048\n",
      "Epoch: 18/20... Training loss: 0.1038\n",
      "Epoch: 18/20... Training loss: 0.1040\n",
      "Epoch: 18/20... Training loss: 0.1111\n",
      "Epoch: 18/20... Training loss: 0.1015\n",
      "Epoch: 18/20... Training loss: 0.1008\n",
      "Epoch: 18/20... Training loss: 0.0984\n",
      "Epoch: 18/20... Training loss: 0.1021\n",
      "Epoch: 18/20... Training loss: 0.1050\n",
      "Epoch: 18/20... Training loss: 0.1042\n",
      "Epoch: 18/20... Training loss: 0.1044\n",
      "Epoch: 18/20... Training loss: 0.1086\n",
      "Epoch: 18/20... Training loss: 0.1074\n",
      "Epoch: 18/20... Training loss: 0.1042\n",
      "Epoch: 18/20... Training loss: 0.0970\n",
      "Epoch: 18/20... Training loss: 0.0944\n",
      "Epoch: 18/20... Training loss: 0.0966\n",
      "Epoch: 18/20... Training loss: 0.1024\n",
      "Epoch: 18/20... Training loss: 0.1090\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.0999\n",
      "Epoch: 18/20... Training loss: 0.1091\n",
      "Epoch: 18/20... Training loss: 0.0984\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.1058\n",
      "Epoch: 18/20... Training loss: 0.1032\n",
      "Epoch: 18/20... Training loss: 0.1018\n",
      "Epoch: 18/20... Training loss: 0.0993\n",
      "Epoch: 18/20... Training loss: 0.0984\n",
      "Epoch: 18/20... Training loss: 0.1034\n",
      "Epoch: 18/20... Training loss: 0.1018\n",
      "Epoch: 18/20... Training loss: 0.1058\n",
      "Epoch: 18/20... Training loss: 0.1032\n",
      "Epoch: 18/20... Training loss: 0.1012\n",
      "Epoch: 18/20... Training loss: 0.1011\n",
      "Epoch: 18/20... Training loss: 0.1133\n",
      "Epoch: 18/20... Training loss: 0.1058\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.1025\n",
      "Epoch: 18/20... Training loss: 0.1034\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.0978\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.1082\n",
      "Epoch: 18/20... Training loss: 0.1078\n",
      "Epoch: 18/20... Training loss: 0.0954\n",
      "Epoch: 18/20... Training loss: 0.0988\n",
      "Epoch: 18/20... Training loss: 0.1056\n",
      "Epoch: 18/20... Training loss: 0.0982\n",
      "Epoch: 18/20... Training loss: 0.0953\n",
      "Epoch: 18/20... Training loss: 0.1037\n",
      "Epoch: 18/20... Training loss: 0.1036\n",
      "Epoch: 18/20... Training loss: 0.0974\n",
      "Epoch: 18/20... Training loss: 0.0999\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.0997\n",
      "Epoch: 18/20... Training loss: 0.1014\n",
      "Epoch: 18/20... Training loss: 0.1030\n",
      "Epoch: 18/20... Training loss: 0.1041\n",
      "Epoch: 18/20... Training loss: 0.0995\n",
      "Epoch: 18/20... Training loss: 0.1107\n",
      "Epoch: 18/20... Training loss: 0.1084\n",
      "Epoch: 18/20... Training loss: 0.1029\n",
      "Epoch: 18/20... Training loss: 0.1045\n",
      "Epoch: 18/20... Training loss: 0.1022\n",
      "Epoch: 18/20... Training loss: 0.0978\n",
      "Epoch: 18/20... Training loss: 0.1027\n",
      "Epoch: 18/20... Training loss: 0.0980\n",
      "Epoch: 18/20... Training loss: 0.1026\n",
      "Epoch: 18/20... Training loss: 0.1072\n",
      "Epoch: 18/20... Training loss: 0.1128\n",
      "Epoch: 18/20... Training loss: 0.1028\n",
      "Epoch: 18/20... Training loss: 0.0972\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.0988\n",
      "Epoch: 18/20... Training loss: 0.1044\n",
      "Epoch: 18/20... Training loss: 0.1032\n",
      "Epoch: 18/20... Training loss: 0.1051\n",
      "Epoch: 18/20... Training loss: 0.1051\n",
      "Epoch: 18/20... Training loss: 0.1036\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.1006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/20... Training loss: 0.1042\n",
      "Epoch: 18/20... Training loss: 0.1070\n",
      "Epoch: 18/20... Training loss: 0.1015\n",
      "Epoch: 18/20... Training loss: 0.1046\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.1003\n",
      "Epoch: 18/20... Training loss: 0.1070\n",
      "Epoch: 18/20... Training loss: 0.1024\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.1043\n",
      "Epoch: 18/20... Training loss: 0.1028\n",
      "Epoch: 18/20... Training loss: 0.0969\n",
      "Epoch: 18/20... Training loss: 0.0969\n",
      "Epoch: 18/20... Training loss: 0.1040\n",
      "Epoch: 18/20... Training loss: 0.1025\n",
      "Epoch: 18/20... Training loss: 0.1014\n",
      "Epoch: 18/20... Training loss: 0.1057\n",
      "Epoch: 18/20... Training loss: 0.1014\n",
      "Epoch: 18/20... Training loss: 0.1055\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.1053\n",
      "Epoch: 18/20... Training loss: 0.1037\n",
      "Epoch: 18/20... Training loss: 0.1056\n",
      "Epoch: 18/20... Training loss: 0.1036\n",
      "Epoch: 18/20... Training loss: 0.1055\n",
      "Epoch: 18/20... Training loss: 0.1061\n",
      "Epoch: 18/20... Training loss: 0.1036\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.0982\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.1090\n",
      "Epoch: 18/20... Training loss: 0.1074\n",
      "Epoch: 18/20... Training loss: 0.1029\n",
      "Epoch: 18/20... Training loss: 0.1044\n",
      "Epoch: 18/20... Training loss: 0.1042\n",
      "Epoch: 18/20... Training loss: 0.0995\n",
      "Epoch: 18/20... Training loss: 0.1075\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.0976\n",
      "Epoch: 18/20... Training loss: 0.1025\n",
      "Epoch: 18/20... Training loss: 0.0948\n",
      "Epoch: 18/20... Training loss: 0.1023\n",
      "Epoch: 18/20... Training loss: 0.1061\n",
      "Epoch: 18/20... Training loss: 0.1026\n",
      "Epoch: 18/20... Training loss: 0.1016\n",
      "Epoch: 18/20... Training loss: 0.1035\n",
      "Epoch: 18/20... Training loss: 0.1025\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.1054\n",
      "Epoch: 18/20... Training loss: 0.1085\n",
      "Epoch: 18/20... Training loss: 0.1040\n",
      "Epoch: 18/20... Training loss: 0.1004\n",
      "Epoch: 18/20... Training loss: 0.1000\n",
      "Epoch: 18/20... Training loss: 0.0966\n",
      "Epoch: 18/20... Training loss: 0.1021\n",
      "Epoch: 18/20... Training loss: 0.1035\n",
      "Epoch: 18/20... Training loss: 0.1034\n",
      "Epoch: 18/20... Training loss: 0.1063\n",
      "Epoch: 18/20... Training loss: 0.0978\n",
      "Epoch: 18/20... Training loss: 0.1010\n",
      "Epoch: 18/20... Training loss: 0.1049\n",
      "Epoch: 18/20... Training loss: 0.1002\n",
      "Epoch: 18/20... Training loss: 0.1022\n",
      "Epoch: 18/20... Training loss: 0.1100\n",
      "Epoch: 18/20... Training loss: 0.1063\n",
      "Epoch: 18/20... Training loss: 0.1026\n",
      "Epoch: 18/20... Training loss: 0.1057\n",
      "Epoch: 18/20... Training loss: 0.1046\n",
      "Epoch: 18/20... Training loss: 0.1012\n",
      "Epoch: 18/20... Training loss: 0.1039\n",
      "Epoch: 18/20... Training loss: 0.1067\n",
      "Epoch: 18/20... Training loss: 0.1077\n",
      "Epoch: 18/20... Training loss: 0.1072\n",
      "Epoch: 18/20... Training loss: 0.1036\n",
      "Epoch: 18/20... Training loss: 0.1072\n",
      "Epoch: 18/20... Training loss: 0.1038\n",
      "Epoch: 18/20... Training loss: 0.1052\n",
      "Epoch: 18/20... Training loss: 0.1039\n",
      "Epoch: 18/20... Training loss: 0.1021\n",
      "Epoch: 18/20... Training loss: 0.1018\n",
      "Epoch: 18/20... Training loss: 0.1081\n",
      "Epoch: 18/20... Training loss: 0.1071\n",
      "Epoch: 18/20... Training loss: 0.1005\n",
      "Epoch: 18/20... Training loss: 0.1004\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.1063\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.1103\n",
      "Epoch: 18/20... Training loss: 0.1026\n",
      "Epoch: 18/20... Training loss: 0.1093\n",
      "Epoch: 18/20... Training loss: 0.1069\n",
      "Epoch: 18/20... Training loss: 0.1059\n",
      "Epoch: 18/20... Training loss: 0.1009\n",
      "Epoch: 18/20... Training loss: 0.1043\n",
      "Epoch: 18/20... Training loss: 0.1053\n",
      "Epoch: 18/20... Training loss: 0.1017\n",
      "Epoch: 18/20... Training loss: 0.0977\n",
      "Epoch: 18/20... Training loss: 0.1004\n",
      "Epoch: 18/20... Training loss: 0.1026\n",
      "Epoch: 18/20... Training loss: 0.1034\n",
      "Epoch: 18/20... Training loss: 0.1052\n",
      "Epoch: 18/20... Training loss: 0.1038\n",
      "Epoch: 18/20... Training loss: 0.1046\n",
      "Epoch: 18/20... Training loss: 0.0987\n",
      "Epoch: 18/20... Training loss: 0.1016\n",
      "Epoch: 18/20... Training loss: 0.0977\n",
      "Epoch: 18/20... Training loss: 0.1049\n",
      "Epoch: 18/20... Training loss: 0.1032\n",
      "Epoch: 18/20... Training loss: 0.1028\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.1050\n",
      "Epoch: 18/20... Training loss: 0.1063\n",
      "Epoch: 18/20... Training loss: 0.1069\n",
      "Epoch: 18/20... Training loss: 0.1009\n",
      "Epoch: 18/20... Training loss: 0.1023\n",
      "Epoch: 18/20... Training loss: 0.0972\n",
      "Epoch: 18/20... Training loss: 0.1038\n",
      "Epoch: 18/20... Training loss: 0.1029\n",
      "Epoch: 18/20... Training loss: 0.0996\n",
      "Epoch: 18/20... Training loss: 0.0997\n",
      "Epoch: 18/20... Training loss: 0.1031\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.1006\n",
      "Epoch: 18/20... Training loss: 0.1060\n",
      "Epoch: 18/20... Training loss: 0.1008\n",
      "Epoch: 18/20... Training loss: 0.0991\n",
      "Epoch: 18/20... Training loss: 0.1026\n",
      "Epoch: 18/20... Training loss: 0.1052\n",
      "Epoch: 18/20... Training loss: 0.1064\n",
      "Epoch: 18/20... Training loss: 0.1036\n",
      "Epoch: 18/20... Training loss: 0.1043\n",
      "Epoch: 18/20... Training loss: 0.1042\n",
      "Epoch: 18/20... Training loss: 0.1078\n",
      "Epoch: 18/20... Training loss: 0.1046\n",
      "Epoch: 18/20... Training loss: 0.1005\n",
      "Epoch: 18/20... Training loss: 0.1119\n",
      "Epoch: 18/20... Training loss: 0.1046\n",
      "Epoch: 18/20... Training loss: 0.1079\n",
      "Epoch: 18/20... Training loss: 0.1051\n",
      "Epoch: 18/20... Training loss: 0.1008\n",
      "Epoch: 18/20... Training loss: 0.1036\n",
      "Epoch: 19/20... Training loss: 0.0999\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.1025\n",
      "Epoch: 19/20... Training loss: 0.1036\n",
      "Epoch: 19/20... Training loss: 0.1017\n",
      "Epoch: 19/20... Training loss: 0.1042\n",
      "Epoch: 19/20... Training loss: 0.1015\n",
      "Epoch: 19/20... Training loss: 0.1048\n",
      "Epoch: 19/20... Training loss: 0.1015\n",
      "Epoch: 19/20... Training loss: 0.1004\n",
      "Epoch: 19/20... Training loss: 0.0984\n",
      "Epoch: 19/20... Training loss: 0.1057\n",
      "Epoch: 19/20... Training loss: 0.1029\n",
      "Epoch: 19/20... Training loss: 0.1049\n",
      "Epoch: 19/20... Training loss: 0.1020\n",
      "Epoch: 19/20... Training loss: 0.1063\n",
      "Epoch: 19/20... Training loss: 0.0977\n",
      "Epoch: 19/20... Training loss: 0.1004\n",
      "Epoch: 19/20... Training loss: 0.1113\n",
      "Epoch: 19/20... Training loss: 0.1040\n",
      "Epoch: 19/20... Training loss: 0.0982\n",
      "Epoch: 19/20... Training loss: 0.1043\n",
      "Epoch: 19/20... Training loss: 0.1006\n",
      "Epoch: 19/20... Training loss: 0.1066\n",
      "Epoch: 19/20... Training loss: 0.1043\n",
      "Epoch: 19/20... Training loss: 0.1060\n",
      "Epoch: 19/20... Training loss: 0.1054\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.1024\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.1028\n",
      "Epoch: 19/20... Training loss: 0.0975\n",
      "Epoch: 19/20... Training loss: 0.0997\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.1038\n",
      "Epoch: 19/20... Training loss: 0.1030\n",
      "Epoch: 19/20... Training loss: 0.1065\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.1030\n",
      "Epoch: 19/20... Training loss: 0.1027\n",
      "Epoch: 19/20... Training loss: 0.0999\n",
      "Epoch: 19/20... Training loss: 0.1025\n",
      "Epoch: 19/20... Training loss: 0.0982\n",
      "Epoch: 19/20... Training loss: 0.1029\n",
      "Epoch: 19/20... Training loss: 0.0971\n",
      "Epoch: 19/20... Training loss: 0.1045\n",
      "Epoch: 19/20... Training loss: 0.1040\n",
      "Epoch: 19/20... Training loss: 0.1052\n",
      "Epoch: 19/20... Training loss: 0.1064\n",
      "Epoch: 19/20... Training loss: 0.1036\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.0986\n",
      "Epoch: 19/20... Training loss: 0.1026\n",
      "Epoch: 19/20... Training loss: 0.1037\n",
      "Epoch: 19/20... Training loss: 0.0964\n",
      "Epoch: 19/20... Training loss: 0.1000\n",
      "Epoch: 19/20... Training loss: 0.0968\n",
      "Epoch: 19/20... Training loss: 0.0982\n",
      "Epoch: 19/20... Training loss: 0.0963\n",
      "Epoch: 19/20... Training loss: 0.0975\n",
      "Epoch: 19/20... Training loss: 0.0974\n",
      "Epoch: 19/20... Training loss: 0.1021\n",
      "Epoch: 19/20... Training loss: 0.1064\n",
      "Epoch: 19/20... Training loss: 0.1061\n",
      "Epoch: 19/20... Training loss: 0.1070\n",
      "Epoch: 19/20... Training loss: 0.1029\n",
      "Epoch: 19/20... Training loss: 0.1050\n",
      "Epoch: 19/20... Training loss: 0.1034\n",
      "Epoch: 19/20... Training loss: 0.1013\n",
      "Epoch: 19/20... Training loss: 0.1060\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.1015\n",
      "Epoch: 19/20... Training loss: 0.1036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/20... Training loss: 0.1052\n",
      "Epoch: 19/20... Training loss: 0.0991\n",
      "Epoch: 19/20... Training loss: 0.1044\n",
      "Epoch: 19/20... Training loss: 0.1034\n",
      "Epoch: 19/20... Training loss: 0.1034\n",
      "Epoch: 19/20... Training loss: 0.1106\n",
      "Epoch: 19/20... Training loss: 0.1009\n",
      "Epoch: 19/20... Training loss: 0.1003\n",
      "Epoch: 19/20... Training loss: 0.0978\n",
      "Epoch: 19/20... Training loss: 0.1017\n",
      "Epoch: 19/20... Training loss: 0.1046\n",
      "Epoch: 19/20... Training loss: 0.1037\n",
      "Epoch: 19/20... Training loss: 0.1040\n",
      "Epoch: 19/20... Training loss: 0.1081\n",
      "Epoch: 19/20... Training loss: 0.1068\n",
      "Epoch: 19/20... Training loss: 0.1037\n",
      "Epoch: 19/20... Training loss: 0.0965\n",
      "Epoch: 19/20... Training loss: 0.0939\n",
      "Epoch: 19/20... Training loss: 0.0962\n",
      "Epoch: 19/20... Training loss: 0.1019\n",
      "Epoch: 19/20... Training loss: 0.1085\n",
      "Epoch: 19/20... Training loss: 0.0996\n",
      "Epoch: 19/20... Training loss: 0.0993\n",
      "Epoch: 19/20... Training loss: 0.1085\n",
      "Epoch: 19/20... Training loss: 0.0980\n",
      "Epoch: 19/20... Training loss: 0.0997\n",
      "Epoch: 19/20... Training loss: 0.1051\n",
      "Epoch: 19/20... Training loss: 0.1027\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.0988\n",
      "Epoch: 19/20... Training loss: 0.0980\n",
      "Epoch: 19/20... Training loss: 0.1029\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.1054\n",
      "Epoch: 19/20... Training loss: 0.1028\n",
      "Epoch: 19/20... Training loss: 0.1008\n",
      "Epoch: 19/20... Training loss: 0.1006\n",
      "Epoch: 19/20... Training loss: 0.1128\n",
      "Epoch: 19/20... Training loss: 0.1055\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.1018\n",
      "Epoch: 19/20... Training loss: 0.1029\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.0973\n",
      "Epoch: 19/20... Training loss: 0.1015\n",
      "Epoch: 19/20... Training loss: 0.1077\n",
      "Epoch: 19/20... Training loss: 0.1073\n",
      "Epoch: 19/20... Training loss: 0.0950\n",
      "Epoch: 19/20... Training loss: 0.0983\n",
      "Epoch: 19/20... Training loss: 0.1051\n",
      "Epoch: 19/20... Training loss: 0.0977\n",
      "Epoch: 19/20... Training loss: 0.0948\n",
      "Epoch: 19/20... Training loss: 0.1032\n",
      "Epoch: 19/20... Training loss: 0.1030\n",
      "Epoch: 19/20... Training loss: 0.0969\n",
      "Epoch: 19/20... Training loss: 0.0994\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.0992\n",
      "Epoch: 19/20... Training loss: 0.1009\n",
      "Epoch: 19/20... Training loss: 0.1026\n",
      "Epoch: 19/20... Training loss: 0.1036\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.1102\n",
      "Epoch: 19/20... Training loss: 0.1078\n",
      "Epoch: 19/20... Training loss: 0.1024\n",
      "Epoch: 19/20... Training loss: 0.1040\n",
      "Epoch: 19/20... Training loss: 0.1019\n",
      "Epoch: 19/20... Training loss: 0.0973\n",
      "Epoch: 19/20... Training loss: 0.1020\n",
      "Epoch: 19/20... Training loss: 0.0976\n",
      "Epoch: 19/20... Training loss: 0.1021\n",
      "Epoch: 19/20... Training loss: 0.1066\n",
      "Epoch: 19/20... Training loss: 0.1122\n",
      "Epoch: 19/20... Training loss: 0.1024\n",
      "Epoch: 19/20... Training loss: 0.0968\n",
      "Epoch: 19/20... Training loss: 0.1028\n",
      "Epoch: 19/20... Training loss: 0.0985\n",
      "Epoch: 19/20... Training loss: 0.1039\n",
      "Epoch: 19/20... Training loss: 0.1027\n",
      "Epoch: 19/20... Training loss: 0.1046\n",
      "Epoch: 19/20... Training loss: 0.1045\n",
      "Epoch: 19/20... Training loss: 0.1031\n",
      "Epoch: 19/20... Training loss: 0.1029\n",
      "Epoch: 19/20... Training loss: 0.1001\n",
      "Epoch: 19/20... Training loss: 0.1037\n",
      "Epoch: 19/20... Training loss: 0.1065\n",
      "Epoch: 19/20... Training loss: 0.1011\n",
      "Epoch: 19/20... Training loss: 0.1041\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.1064\n",
      "Epoch: 19/20... Training loss: 0.1019\n",
      "Epoch: 19/20... Training loss: 0.0996\n",
      "Epoch: 19/20... Training loss: 0.1038\n",
      "Epoch: 19/20... Training loss: 0.1023\n",
      "Epoch: 19/20... Training loss: 0.0965\n",
      "Epoch: 19/20... Training loss: 0.0965\n",
      "Epoch: 19/20... Training loss: 0.1035\n",
      "Epoch: 19/20... Training loss: 0.1021\n",
      "Epoch: 19/20... Training loss: 0.1009\n",
      "Epoch: 19/20... Training loss: 0.1053\n",
      "Epoch: 19/20... Training loss: 0.1010\n",
      "Epoch: 19/20... Training loss: 0.1050\n",
      "Epoch: 19/20... Training loss: 0.0997\n",
      "Epoch: 19/20... Training loss: 0.1048\n",
      "Epoch: 19/20... Training loss: 0.1031\n",
      "Epoch: 19/20... Training loss: 0.1051\n",
      "Epoch: 19/20... Training loss: 0.1031\n",
      "Epoch: 19/20... Training loss: 0.1050\n",
      "Epoch: 19/20... Training loss: 0.1056\n",
      "Epoch: 19/20... Training loss: 0.1031\n",
      "Epoch: 19/20... Training loss: 0.1028\n",
      "Epoch: 19/20... Training loss: 0.0976\n",
      "Epoch: 19/20... Training loss: 0.1029\n",
      "Epoch: 19/20... Training loss: 0.1084\n",
      "Epoch: 19/20... Training loss: 0.1068\n",
      "Epoch: 19/20... Training loss: 0.1025\n",
      "Epoch: 19/20... Training loss: 0.1039\n",
      "Epoch: 19/20... Training loss: 0.1037\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.1068\n",
      "Epoch: 19/20... Training loss: 0.1015\n",
      "Epoch: 19/20... Training loss: 0.0971\n",
      "Epoch: 19/20... Training loss: 0.1020\n",
      "Epoch: 19/20... Training loss: 0.0944\n",
      "Epoch: 19/20... Training loss: 0.1018\n",
      "Epoch: 19/20... Training loss: 0.1056\n",
      "Epoch: 19/20... Training loss: 0.1021\n",
      "Epoch: 19/20... Training loss: 0.1011\n",
      "Epoch: 19/20... Training loss: 0.1030\n",
      "Epoch: 19/20... Training loss: 0.1019\n",
      "Epoch: 19/20... Training loss: 0.1013\n",
      "Epoch: 19/20... Training loss: 0.1049\n",
      "Epoch: 19/20... Training loss: 0.1080\n",
      "Epoch: 19/20... Training loss: 0.1035\n",
      "Epoch: 19/20... Training loss: 0.0999\n",
      "Epoch: 19/20... Training loss: 0.0995\n",
      "Epoch: 19/20... Training loss: 0.0962\n",
      "Epoch: 19/20... Training loss: 0.1016\n",
      "Epoch: 19/20... Training loss: 0.1031\n",
      "Epoch: 19/20... Training loss: 0.1030\n",
      "Epoch: 19/20... Training loss: 0.1057\n",
      "Epoch: 19/20... Training loss: 0.0974\n",
      "Epoch: 19/20... Training loss: 0.1005\n",
      "Epoch: 19/20... Training loss: 0.1043\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.1018\n",
      "Epoch: 19/20... Training loss: 0.1095\n",
      "Epoch: 19/20... Training loss: 0.1057\n",
      "Epoch: 19/20... Training loss: 0.1021\n",
      "Epoch: 19/20... Training loss: 0.1052\n",
      "Epoch: 19/20... Training loss: 0.1041\n",
      "Epoch: 19/20... Training loss: 0.1008\n",
      "Epoch: 19/20... Training loss: 0.1035\n",
      "Epoch: 19/20... Training loss: 0.1061\n",
      "Epoch: 19/20... Training loss: 0.1071\n",
      "Epoch: 19/20... Training loss: 0.1067\n",
      "Epoch: 19/20... Training loss: 0.1030\n",
      "Epoch: 19/20... Training loss: 0.1067\n",
      "Epoch: 19/20... Training loss: 0.1033\n",
      "Epoch: 19/20... Training loss: 0.1047\n",
      "Epoch: 19/20... Training loss: 0.1033\n",
      "Epoch: 19/20... Training loss: 0.1015\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.1075\n",
      "Epoch: 19/20... Training loss: 0.1066\n",
      "Epoch: 19/20... Training loss: 0.1000\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.1028\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.1057\n",
      "Epoch: 19/20... Training loss: 0.1013\n",
      "Epoch: 19/20... Training loss: 0.1097\n",
      "Epoch: 19/20... Training loss: 0.1022\n",
      "Epoch: 19/20... Training loss: 0.1087\n",
      "Epoch: 19/20... Training loss: 0.1064\n",
      "Epoch: 19/20... Training loss: 0.1054\n",
      "Epoch: 19/20... Training loss: 0.1005\n",
      "Epoch: 19/20... Training loss: 0.1037\n",
      "Epoch: 19/20... Training loss: 0.1049\n",
      "Epoch: 19/20... Training loss: 0.1012\n",
      "Epoch: 19/20... Training loss: 0.0972\n",
      "Epoch: 19/20... Training loss: 0.0999\n",
      "Epoch: 19/20... Training loss: 0.1021\n",
      "Epoch: 19/20... Training loss: 0.1028\n",
      "Epoch: 19/20... Training loss: 0.1047\n",
      "Epoch: 19/20... Training loss: 0.1034\n",
      "Epoch: 19/20... Training loss: 0.1040\n",
      "Epoch: 19/20... Training loss: 0.0981\n",
      "Epoch: 19/20... Training loss: 0.1012\n",
      "Epoch: 19/20... Training loss: 0.0972\n",
      "Epoch: 19/20... Training loss: 0.1044\n",
      "Epoch: 19/20... Training loss: 0.1028\n",
      "Epoch: 19/20... Training loss: 0.1023\n",
      "Epoch: 19/20... Training loss: 0.0996\n",
      "Epoch: 19/20... Training loss: 0.1047\n",
      "Epoch: 19/20... Training loss: 0.1058\n",
      "Epoch: 19/20... Training loss: 0.1064\n",
      "Epoch: 19/20... Training loss: 0.1005\n",
      "Epoch: 19/20... Training loss: 0.1018\n",
      "Epoch: 19/20... Training loss: 0.0968\n",
      "Epoch: 19/20... Training loss: 0.1033\n",
      "Epoch: 19/20... Training loss: 0.1024\n",
      "Epoch: 19/20... Training loss: 0.0992\n",
      "Epoch: 19/20... Training loss: 0.0992\n",
      "Epoch: 19/20... Training loss: 0.1027\n",
      "Epoch: 19/20... Training loss: 0.1028\n",
      "Epoch: 19/20... Training loss: 0.1015\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.1055\n",
      "Epoch: 19/20... Training loss: 0.1005\n",
      "Epoch: 19/20... Training loss: 0.0987\n",
      "Epoch: 19/20... Training loss: 0.1021\n",
      "Epoch: 19/20... Training loss: 0.1047\n",
      "Epoch: 19/20... Training loss: 0.1060\n",
      "Epoch: 19/20... Training loss: 0.1031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/20... Training loss: 0.1038\n",
      "Epoch: 19/20... Training loss: 0.1038\n",
      "Epoch: 19/20... Training loss: 0.1073\n",
      "Epoch: 19/20... Training loss: 0.1042\n",
      "Epoch: 19/20... Training loss: 0.0999\n",
      "Epoch: 19/20... Training loss: 0.1114\n",
      "Epoch: 19/20... Training loss: 0.1042\n",
      "Epoch: 19/20... Training loss: 0.1075\n",
      "Epoch: 19/20... Training loss: 0.1047\n",
      "Epoch: 19/20... Training loss: 0.1005\n",
      "Epoch: 19/20... Training loss: 0.1030\n",
      "Epoch: 20/20... Training loss: 0.0995\n",
      "Epoch: 20/20... Training loss: 0.0995\n",
      "Epoch: 20/20... Training loss: 0.1021\n",
      "Epoch: 20/20... Training loss: 0.1032\n",
      "Epoch: 20/20... Training loss: 0.1013\n",
      "Epoch: 20/20... Training loss: 0.1038\n",
      "Epoch: 20/20... Training loss: 0.1011\n",
      "Epoch: 20/20... Training loss: 0.1044\n",
      "Epoch: 20/20... Training loss: 0.1010\n",
      "Epoch: 20/20... Training loss: 0.0997\n",
      "Epoch: 20/20... Training loss: 0.0978\n",
      "Epoch: 20/20... Training loss: 0.1052\n",
      "Epoch: 20/20... Training loss: 0.1024\n",
      "Epoch: 20/20... Training loss: 0.1044\n",
      "Epoch: 20/20... Training loss: 0.1016\n",
      "Epoch: 20/20... Training loss: 0.1059\n",
      "Epoch: 20/20... Training loss: 0.0972\n",
      "Epoch: 20/20... Training loss: 0.0999\n",
      "Epoch: 20/20... Training loss: 0.1108\n",
      "Epoch: 20/20... Training loss: 0.1035\n",
      "Epoch: 20/20... Training loss: 0.0977\n",
      "Epoch: 20/20... Training loss: 0.1038\n",
      "Epoch: 20/20... Training loss: 0.1002\n",
      "Epoch: 20/20... Training loss: 0.1060\n",
      "Epoch: 20/20... Training loss: 0.1038\n",
      "Epoch: 20/20... Training loss: 0.1056\n",
      "Epoch: 20/20... Training loss: 0.1048\n",
      "Epoch: 20/20... Training loss: 0.1010\n",
      "Epoch: 20/20... Training loss: 0.1019\n",
      "Epoch: 20/20... Training loss: 0.1010\n",
      "Epoch: 20/20... Training loss: 0.1022\n",
      "Epoch: 20/20... Training loss: 0.0970\n",
      "Epoch: 20/20... Training loss: 0.0991\n",
      "Epoch: 20/20... Training loss: 0.0999\n",
      "Epoch: 20/20... Training loss: 0.1032\n",
      "Epoch: 20/20... Training loss: 0.1026\n",
      "Epoch: 20/20... Training loss: 0.1060\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.1025\n",
      "Epoch: 20/20... Training loss: 0.1021\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.1019\n",
      "Epoch: 20/20... Training loss: 0.0978\n",
      "Epoch: 20/20... Training loss: 0.1022\n",
      "Epoch: 20/20... Training loss: 0.0966\n",
      "Epoch: 20/20... Training loss: 0.1039\n",
      "Epoch: 20/20... Training loss: 0.1037\n",
      "Epoch: 20/20... Training loss: 0.1047\n",
      "Epoch: 20/20... Training loss: 0.1059\n",
      "Epoch: 20/20... Training loss: 0.1031\n",
      "Epoch: 20/20... Training loss: 0.0993\n",
      "Epoch: 20/20... Training loss: 0.0981\n",
      "Epoch: 20/20... Training loss: 0.1022\n",
      "Epoch: 20/20... Training loss: 0.1032\n",
      "Epoch: 20/20... Training loss: 0.0959\n",
      "Epoch: 20/20... Training loss: 0.0995\n",
      "Epoch: 20/20... Training loss: 0.0964\n",
      "Epoch: 20/20... Training loss: 0.0979\n",
      "Epoch: 20/20... Training loss: 0.0958\n",
      "Epoch: 20/20... Training loss: 0.0971\n",
      "Epoch: 20/20... Training loss: 0.0970\n",
      "Epoch: 20/20... Training loss: 0.1016\n",
      "Epoch: 20/20... Training loss: 0.1060\n",
      "Epoch: 20/20... Training loss: 0.1056\n",
      "Epoch: 20/20... Training loss: 0.1066\n",
      "Epoch: 20/20... Training loss: 0.1024\n",
      "Epoch: 20/20... Training loss: 0.1045\n",
      "Epoch: 20/20... Training loss: 0.1029\n",
      "Epoch: 20/20... Training loss: 0.1008\n",
      "Epoch: 20/20... Training loss: 0.1054\n",
      "Epoch: 20/20... Training loss: 0.1010\n",
      "Epoch: 20/20... Training loss: 0.1012\n",
      "Epoch: 20/20... Training loss: 0.1031\n",
      "Epoch: 20/20... Training loss: 0.1049\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.1039\n",
      "Epoch: 20/20... Training loss: 0.1030\n",
      "Epoch: 20/20... Training loss: 0.1028\n",
      "Epoch: 20/20... Training loss: 0.1103\n",
      "Epoch: 20/20... Training loss: 0.1004\n",
      "Epoch: 20/20... Training loss: 0.0999\n",
      "Epoch: 20/20... Training loss: 0.0973\n",
      "Epoch: 20/20... Training loss: 0.1012\n",
      "Epoch: 20/20... Training loss: 0.1043\n",
      "Epoch: 20/20... Training loss: 0.1032\n",
      "Epoch: 20/20... Training loss: 0.1035\n",
      "Epoch: 20/20... Training loss: 0.1076\n",
      "Epoch: 20/20... Training loss: 0.1064\n",
      "Epoch: 20/20... Training loss: 0.1031\n",
      "Epoch: 20/20... Training loss: 0.0961\n",
      "Epoch: 20/20... Training loss: 0.0934\n",
      "Epoch: 20/20... Training loss: 0.0958\n",
      "Epoch: 20/20... Training loss: 0.1014\n",
      "Epoch: 20/20... Training loss: 0.1079\n",
      "Epoch: 20/20... Training loss: 0.0992\n",
      "Epoch: 20/20... Training loss: 0.0988\n",
      "Epoch: 20/20... Training loss: 0.1079\n",
      "Epoch: 20/20... Training loss: 0.0975\n",
      "Epoch: 20/20... Training loss: 0.0993\n",
      "Epoch: 20/20... Training loss: 0.1045\n",
      "Epoch: 20/20... Training loss: 0.1022\n",
      "Epoch: 20/20... Training loss: 0.1010\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.0975\n",
      "Epoch: 20/20... Training loss: 0.1024\n",
      "Epoch: 20/20... Training loss: 0.1011\n",
      "Epoch: 20/20... Training loss: 0.1049\n",
      "Epoch: 20/20... Training loss: 0.1023\n",
      "Epoch: 20/20... Training loss: 0.1004\n",
      "Epoch: 20/20... Training loss: 0.1002\n",
      "Epoch: 20/20... Training loss: 0.1123\n",
      "Epoch: 20/20... Training loss: 0.1050\n",
      "Epoch: 20/20... Training loss: 0.1009\n",
      "Epoch: 20/20... Training loss: 0.1013\n",
      "Epoch: 20/20... Training loss: 0.1024\n",
      "Epoch: 20/20... Training loss: 0.1009\n",
      "Epoch: 20/20... Training loss: 0.0969\n",
      "Epoch: 20/20... Training loss: 0.1011\n",
      "Epoch: 20/20... Training loss: 0.1071\n",
      "Epoch: 20/20... Training loss: 0.1068\n",
      "Epoch: 20/20... Training loss: 0.0946\n",
      "Epoch: 20/20... Training loss: 0.0979\n",
      "Epoch: 20/20... Training loss: 0.1047\n",
      "Epoch: 20/20... Training loss: 0.0973\n",
      "Epoch: 20/20... Training loss: 0.0944\n",
      "Epoch: 20/20... Training loss: 0.1027\n",
      "Epoch: 20/20... Training loss: 0.1025\n",
      "Epoch: 20/20... Training loss: 0.0963\n",
      "Epoch: 20/20... Training loss: 0.0990\n",
      "Epoch: 20/20... Training loss: 0.1009\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.1005\n",
      "Epoch: 20/20... Training loss: 0.1021\n",
      "Epoch: 20/20... Training loss: 0.1032\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.1097\n",
      "Epoch: 20/20... Training loss: 0.1074\n",
      "Epoch: 20/20... Training loss: 0.1020\n",
      "Epoch: 20/20... Training loss: 0.1036\n",
      "Epoch: 20/20... Training loss: 0.1016\n",
      "Epoch: 20/20... Training loss: 0.0968\n",
      "Epoch: 20/20... Training loss: 0.1017\n",
      "Epoch: 20/20... Training loss: 0.0973\n",
      "Epoch: 20/20... Training loss: 0.1017\n",
      "Epoch: 20/20... Training loss: 0.1061\n",
      "Epoch: 20/20... Training loss: 0.1117\n",
      "Epoch: 20/20... Training loss: 0.1020\n",
      "Epoch: 20/20... Training loss: 0.0965\n",
      "Epoch: 20/20... Training loss: 0.1023\n",
      "Epoch: 20/20... Training loss: 0.0981\n",
      "Epoch: 20/20... Training loss: 0.1034\n",
      "Epoch: 20/20... Training loss: 0.1022\n",
      "Epoch: 20/20... Training loss: 0.1040\n",
      "Epoch: 20/20... Training loss: 0.1040\n",
      "Epoch: 20/20... Training loss: 0.1026\n",
      "Epoch: 20/20... Training loss: 0.1024\n",
      "Epoch: 20/20... Training loss: 0.0996\n",
      "Epoch: 20/20... Training loss: 0.1033\n",
      "Epoch: 20/20... Training loss: 0.1060\n",
      "Epoch: 20/20... Training loss: 0.1006\n",
      "Epoch: 20/20... Training loss: 0.1037\n",
      "Epoch: 20/20... Training loss: 0.1010\n",
      "Epoch: 20/20... Training loss: 0.0995\n",
      "Epoch: 20/20... Training loss: 0.1059\n",
      "Epoch: 20/20... Training loss: 0.1014\n",
      "Epoch: 20/20... Training loss: 0.0993\n",
      "Epoch: 20/20... Training loss: 0.1034\n",
      "Epoch: 20/20... Training loss: 0.1019\n",
      "Epoch: 20/20... Training loss: 0.0962\n",
      "Epoch: 20/20... Training loss: 0.0960\n",
      "Epoch: 20/20... Training loss: 0.1031\n",
      "Epoch: 20/20... Training loss: 0.1018\n",
      "Epoch: 20/20... Training loss: 0.1004\n",
      "Epoch: 20/20... Training loss: 0.1049\n",
      "Epoch: 20/20... Training loss: 0.1006\n",
      "Epoch: 20/20... Training loss: 0.1045\n",
      "Epoch: 20/20... Training loss: 0.0993\n",
      "Epoch: 20/20... Training loss: 0.1043\n",
      "Epoch: 20/20... Training loss: 0.1027\n",
      "Epoch: 20/20... Training loss: 0.1046\n",
      "Epoch: 20/20... Training loss: 0.1026\n",
      "Epoch: 20/20... Training loss: 0.1045\n",
      "Epoch: 20/20... Training loss: 0.1051\n",
      "Epoch: 20/20... Training loss: 0.1027\n",
      "Epoch: 20/20... Training loss: 0.1023\n",
      "Epoch: 20/20... Training loss: 0.0972\n",
      "Epoch: 20/20... Training loss: 0.1025\n",
      "Epoch: 20/20... Training loss: 0.1079\n",
      "Epoch: 20/20... Training loss: 0.1064\n",
      "Epoch: 20/20... Training loss: 0.1020\n",
      "Epoch: 20/20... Training loss: 0.1035\n",
      "Epoch: 20/20... Training loss: 0.1033\n",
      "Epoch: 20/20... Training loss: 0.0986\n",
      "Epoch: 20/20... Training loss: 0.1063\n",
      "Epoch: 20/20... Training loss: 0.1011\n",
      "Epoch: 20/20... Training loss: 0.0967\n",
      "Epoch: 20/20... Training loss: 0.1017\n",
      "Epoch: 20/20... Training loss: 0.0941\n",
      "Epoch: 20/20... Training loss: 0.1014\n",
      "Epoch: 20/20... Training loss: 0.1051\n",
      "Epoch: 20/20... Training loss: 0.1017\n",
      "Epoch: 20/20... Training loss: 0.1007\n",
      "Epoch: 20/20... Training loss: 0.1025\n",
      "Epoch: 20/20... Training loss: 0.1015\n",
      "Epoch: 20/20... Training loss: 0.1008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/20... Training loss: 0.1045\n",
      "Epoch: 20/20... Training loss: 0.1075\n",
      "Epoch: 20/20... Training loss: 0.1031\n",
      "Epoch: 20/20... Training loss: 0.0995\n",
      "Epoch: 20/20... Training loss: 0.0990\n",
      "Epoch: 20/20... Training loss: 0.0957\n",
      "Epoch: 20/20... Training loss: 0.1012\n",
      "Epoch: 20/20... Training loss: 0.1026\n",
      "Epoch: 20/20... Training loss: 0.1026\n",
      "Epoch: 20/20... Training loss: 0.1051\n",
      "Epoch: 20/20... Training loss: 0.0968\n",
      "Epoch: 20/20... Training loss: 0.1001\n",
      "Epoch: 20/20... Training loss: 0.1039\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.1013\n",
      "Epoch: 20/20... Training loss: 0.1090\n",
      "Epoch: 20/20... Training loss: 0.1051\n",
      "Epoch: 20/20... Training loss: 0.1016\n",
      "Epoch: 20/20... Training loss: 0.1047\n",
      "Epoch: 20/20... Training loss: 0.1037\n",
      "Epoch: 20/20... Training loss: 0.1002\n",
      "Epoch: 20/20... Training loss: 0.1030\n",
      "Epoch: 20/20... Training loss: 0.1057\n",
      "Epoch: 20/20... Training loss: 0.1066\n",
      "Epoch: 20/20... Training loss: 0.1063\n",
      "Epoch: 20/20... Training loss: 0.1026\n",
      "Epoch: 20/20... Training loss: 0.1063\n",
      "Epoch: 20/20... Training loss: 0.1028\n",
      "Epoch: 20/20... Training loss: 0.1043\n",
      "Epoch: 20/20... Training loss: 0.1028\n",
      "Epoch: 20/20... Training loss: 0.1012\n",
      "Epoch: 20/20... Training loss: 0.1010\n",
      "Epoch: 20/20... Training loss: 0.1071\n",
      "Epoch: 20/20... Training loss: 0.1062\n",
      "Epoch: 20/20... Training loss: 0.0996\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.1023\n",
      "Epoch: 20/20... Training loss: 0.1009\n",
      "Epoch: 20/20... Training loss: 0.1051\n",
      "Epoch: 20/20... Training loss: 0.1009\n",
      "Epoch: 20/20... Training loss: 0.1092\n",
      "Epoch: 20/20... Training loss: 0.1017\n",
      "Epoch: 20/20... Training loss: 0.1083\n",
      "Epoch: 20/20... Training loss: 0.1060\n",
      "Epoch: 20/20... Training loss: 0.1050\n",
      "Epoch: 20/20... Training loss: 0.1002\n",
      "Epoch: 20/20... Training loss: 0.1033\n",
      "Epoch: 20/20... Training loss: 0.1044\n",
      "Epoch: 20/20... Training loss: 0.1008\n",
      "Epoch: 20/20... Training loss: 0.0967\n",
      "Epoch: 20/20... Training loss: 0.0995\n",
      "Epoch: 20/20... Training loss: 0.1016\n",
      "Epoch: 20/20... Training loss: 0.1023\n",
      "Epoch: 20/20... Training loss: 0.1043\n",
      "Epoch: 20/20... Training loss: 0.1028\n",
      "Epoch: 20/20... Training loss: 0.1035\n",
      "Epoch: 20/20... Training loss: 0.0976\n",
      "Epoch: 20/20... Training loss: 0.1007\n",
      "Epoch: 20/20... Training loss: 0.0968\n",
      "Epoch: 20/20... Training loss: 0.1040\n",
      "Epoch: 20/20... Training loss: 0.1023\n",
      "Epoch: 20/20... Training loss: 0.1018\n",
      "Epoch: 20/20... Training loss: 0.0992\n",
      "Epoch: 20/20... Training loss: 0.1043\n",
      "Epoch: 20/20... Training loss: 0.1053\n",
      "Epoch: 20/20... Training loss: 0.1060\n",
      "Epoch: 20/20... Training loss: 0.1001\n",
      "Epoch: 20/20... Training loss: 0.1014\n",
      "Epoch: 20/20... Training loss: 0.0963\n",
      "Epoch: 20/20... Training loss: 0.1028\n",
      "Epoch: 20/20... Training loss: 0.1020\n",
      "Epoch: 20/20... Training loss: 0.0988\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.1022\n",
      "Epoch: 20/20... Training loss: 0.1024\n",
      "Epoch: 20/20... Training loss: 0.1011\n",
      "Epoch: 20/20... Training loss: 0.0998\n",
      "Epoch: 20/20... Training loss: 0.1050\n",
      "Epoch: 20/20... Training loss: 0.1001\n",
      "Epoch: 20/20... Training loss: 0.0982\n",
      "Epoch: 20/20... Training loss: 0.1017\n",
      "Epoch: 20/20... Training loss: 0.1043\n",
      "Epoch: 20/20... Training loss: 0.1055\n",
      "Epoch: 20/20... Training loss: 0.1027\n",
      "Epoch: 20/20... Training loss: 0.1033\n",
      "Epoch: 20/20... Training loss: 0.1035\n",
      "Epoch: 20/20... Training loss: 0.1068\n",
      "Epoch: 20/20... Training loss: 0.1038\n",
      "Epoch: 20/20... Training loss: 0.0993\n",
      "Epoch: 20/20... Training loss: 0.1108\n",
      "Epoch: 20/20... Training loss: 0.1037\n",
      "Epoch: 20/20... Training loss: 0.1069\n",
      "Epoch: 20/20... Training loss: 0.1041\n",
      "Epoch: 20/20... Training loss: 0.1000\n",
      "Epoch: 20/20... Training loss: 0.1024\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "batch = get_batch(mnist.train.images, batch_size)\n",
    "for e in range(epochs):\n",
    "    for i in range(batch.shape[0]):\n",
    "        batch_reshape = batch[i].reshape((-1, 28, 28 ,1))\n",
    "        feed = {inputs: batch_reshape, targets: batch_reshape, lr: learn_rate}\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict=feed)\n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Training loss: {:.4f}\".format(batch_cost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n",
    "in_imgs = mnist.test.images[:10]\n",
    "reconstructed = sess.run(decoded, feed_dict={inputs: in_imgs.reshape((10, 28, 28, 1))})\n",
    "\n",
    "for images, row in zip([in_imgs, reconstructed], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "fig.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加入噪声"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
